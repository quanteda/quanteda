---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "images/"
)
```

**Development branch** ![Build Status](https://travis-ci.org/kbenoit/quanteda.svg?branch=dev) [![codecov.io](https://codecov.io/github/kbenoit/quanteda/coverage.svg?branch=dev)][1]

**Master branch** ![Build Status](https://travis-ci.org/kbenoit/quanteda.svg?branch=master) [![codecov.io](https://codecov.io/github/kbenoit/quanteda/coverage.svg?branch=master)][2]


[1]: https://codecov.io/gh/kbenoit/quanteda/branch/dev
[2]: https://codecov.io/gh/kbenoit/quanteda/branch/master


See the [Getting Started Vignette](http://htmlpreview.github.com/?https://github.com/kbenoit/quanteda/blob/master/vignettes/quickstart.html).

quanteda: Quantitative Analysis of Textual Data
===============================================

An R package for managing and analyzing text, by Ken Benoit and Paul Nulty.

**quanteda** makes it easy to manage texts in the form of a
corpus, defined as a collection of texts that includes document-level
variables specific to each text, as well as meta-data for documents
and for the collection as a whole.  **quanteda** includes tools to make it
easy and fast to manuipulate the texts in a corpus, by performing the most common
natural language processing tasks simply and quickly, such as tokenizing,
stemming, or forming ngrams.  **quanteda**'s functions for tokenizing texts
and forming multiple tokenized documents into a *document-feature matrix* are
both extremely fast and extremely simple to use.  **quanteda** can segment texts
easily by words, paragraphs, sentences, or even user-supplied delimiters and tags.

Built on the text processing
functions in the **stringi** package,
which is in turn built on C++ implementation of the [ICU](http://www.icu-project.org/)
libraries for Unicode text handling, **quanteda** pays special attention to fast and correct
implementation of Unicode and the handling of text in any character set, following conversion
internally to UTF-8.


**quanteda** is built for efficiency and speed, through its design around three infrastructures: the **stringi** package for text processing, the **data.table** package for indexing large documents efficiently, and the **Matrix** package for sparse matrix objects.  If you can fit it into memory, **quanteda** will handle it quickly.  (And eventually, we will make it possible to process objects even larger than available memory.)

**quanteda** is principally designed to allow users a fast and convenient method to go from 
a corpus of texts to a selected matrix of documents by features, after defining and selecting
the documents and features.  The package makes it easy to redefine documents, for instance by splitting them into sentences or paragraphs, or by tags, as well as to group them into larger documents by document variables, or to subset them based on logical conditions or combinations of document variables.  The package also implements common NLP feature selection functions, such as removing stopwords and stemming in numerous languages, selecting words found in dictionaries, treating words as equivalent based on a user-defined "thesaurus", and trimming and weighting features based on document frequency, feature frequency, and related measures such as *tf-idf*.
 
Once constructed, a **quanteda** "dfm"" can be easily analyzed using either quanteda's built-in tools for scaling document positions, or used with a number of other text analytic tools, such as:

*  topic models (including converters for direct use with the **topicmodels**, **LDA**, and **stm** packages)

*  document scaling (using **quanteda**'s own functions for the "wordfish" and "Wordscores" models, direct use with the **ca** package for correspondence analysis, or scaling with the **austin** package)

*  machine learning through a variety of other packages that take matrix or matrix-like inputs.


**Additional features** of quanteda include:

*  the ability to explore texts using *key-words-in-context*;

*  fast computation of a variety of readability indexes;

*  fast computation of a variety of lexical diversity measures;

*  quick computation of word or document association measures, for clustering or to compute similarity scores for other purposes; and

*  a comprehensive suite of descriptive statistics on text such as the number of sentences, words, characters, or syllables per document.


**Planned features** coming soon to **quanteda** are:

*  bootstrapping methods for texts that makes it easy to resample texts
   from pre-defined units, to facilitate computation of confidence
   intervals on textual statistics using techniques of non-parametric
   bootstrapping, but applied to the original texts as data. 
   
*  expansion of predictive and analytic methods called through the standard 
   interface called `textmodel()`.  Current model types include correspondence analysis, "Wordscores", "Wordfish", and Naive Bayes.

*  Addition of settings to corpus projects, that will propogate through downstream objects.

*  Addition of a history that will propogate through downstream objects.

**Acknowledgements**:  This research was supported by the European Research Council grant ERC-2011-StG 283794-QUANTESS.

How to Install
--------------

As of version 0.8.0, the GitHub master repository will always contain the development version of quanteda, while the CRAN version will contain the latest "stable" version.  You therefore have two options for installing the package:

1.  From CRAN, using your R package installer, or simply

    ```
    install.packages("quanteda")
    ```

2.  (For the development version) From GitHub, using

    ```
    devtools::install_github("kbenoit/quanteda")
    ```

    Because this compiles some C++ source code, you will need a compiler installed.  If you are using a Windows platform, this means you will need also to install the [Rtools](http://cran.r-project.org/bin/windows/Rtools/) software available from CRAN.  If you are using OS X, you will probably need to install XCode, available for free from the App Store.

3.  (Optional) You can install some additional corpus data from **quantedaData** using

    ```S
    ## devtools required to install quanteda from Github
    devtools::install_github("kbenoit/quantedaData")
    ```


Documentation
-------------

In-depth tutorials in the form of a gitbook will be available here [here](http://kbenoit.github.io/quanteda).

Examples for any function can also be seen using (for instance, for `corpus()`):
```S
example(corpus)
```
There are also some demo functions that show off some of the package capabilities, such 
as `demo(quanteda)`.


Example
-------

```{r quanteda_example, fig.width=7, fig.height=7}
library(quanteda)
# create a corpus from the immigration texts from UK party platforms
uk2010immigCorpus <- corpus(ukimmigTexts,
                            docvars=data.frame(party=names(ukimmigTexts)),
                            notes="Immigration-related sections of 2010 UK party manifestos",
                            enc="UTF-8")
uk2010immigCorpus
summary(uk2010immigCorpus, showmeta=TRUE)

# key words in context for "deport", 3 words of context
kwic(uk2010immigCorpus, "deport", 3)

# create a dfm, removing stopwords
mydfm <- dfm(uk2010immigCorpus, ignoredFeatures=c("will", stopwords("english")))
dim(mydfm)              # basic dimensions of the dfm
topfeatures(mydfm, 20)  # 20 top words
plot(mydfm, min.freq = 6, random.order = FALSE)             # word cloud     
```

