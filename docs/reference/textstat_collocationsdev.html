<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>identify and score multi-word expressions — textstat_collocationsdev • quanteda</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  <link href="../extra.css" rel="stylesheet">
  
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


<!-- Google analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-144616-24', 'auto');
  ga('send', 'pageview');

</script>

  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">Overview</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/quickstart.html">Quick Start</a>
</li>
<li>
  <a href="../articles/comparison.html">Features</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/examples/lsa.html">Latent Semantic Analysis (LSA)</a>
    </li>
    <li>
      <a href="../articles/examples/text2vec.html">Word embedding (word2vec)</a>
    </li>
    <li>
      <a href="../articles/examples/plotting.html">Textual data visualization</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Replication
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/replication/digital-humanities.html">Text Analysis with R for Students of Literature</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/design.html">Design</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/kbenoit/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>identify and score multi-word expressions</h1>
    </div>

    
    <p>Identify and score multi-word expressions, or adjacent fixed-length collocations, from text.</p>
    

    <pre class="usage"><span class='fu'>textstat_collocationsdev</span>(<span class='no'>x</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"all"</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>min_count</span> <span class='kw'>=</span> <span class='fl'>2</span>,
  <span class='kw'>smoothing</span> <span class='kw'>=</span> <span class='fl'>0.5</span>, <span class='kw'>tolower</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>show_counts</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='no'>...</span>)

<span class='fu'>is.collocationsdev</span>(<span class='no'>x</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>a character, <a href='corpus.html'>corpus</a>, or <a href='tokens.html'>tokens</a> object whose
collocations will be scored.  The tokens object should include punctuation,
and if any words have been removed, these should have been removed with
<code>padding = TRUE</code>.  While identifying collocations for tokens objects is 
supported, you will get better results with character or corpus objects due
to relatively imperfect detection of sentence boundaries from texts already 
tokenized.</p></td>
    </tr>
    <tr>
      <th>method</th>
      <td><p>association measure for detecting collocations: <code>"all"</code>,
<code>"lambda"</code>, <code>"lambda1"</code>, <code>"lr"</code>, <code>"chi2"</code>, and
<code>"dice"</code>.  See Details.</p></td>
    </tr>
    <tr>
      <th>size</th>
      <td><p>integer; the length of the collocations
to be scored</p></td>
    </tr>
    <tr>
      <th>min_count</th>
      <td><p>numeric; minimum frequency of collocations that will be scored</p></td>
    </tr>
    <tr>
      <th>smoothing</th>
      <td><p>numeric; a smoothing parameter added to the observed counts
(default is 0.5)</p></td>
    </tr>
    <tr>
      <th>tolower</th>
      <td><p>logical; if <code>TRUE</code>, form collocations as lower-cased combinations</p></td>
    </tr>
    <tr>
      <th>show_counts</th>
      <td><p>logical; if <code>TRUE</code>, output observed and expected counts</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>additional arguments passed to <code><a href='tokens.html'>tokens</a></code>, if <code>x</code>
is not a <a href='tokens.html'>tokens</a> object already</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p><code>textstat_collocationsdev</code> returns a data.frame of collocations and their
  scores and statistsics.

<code>is.collocationdev</code> returns <code>TRUE</code> if the object is of class
  <code>collocationsdev</code>, <code>FALSE</code> otherwise.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Documents are grouped for the purposes of scoring, but collocations will not span sentences.
If <code>x</code> is a <a href='tokens.html'>tokens</a> object and some tokens have been removed, this should be done
using <code><a href='tokens_select.html'>tokens_remove</a>(x, pattern, padding = TRUE)</code> so that counts will still be
accurate, but the pads will prevent those collocations from being scored.</p>
    <p>The <code>lambda</code> computed for a size = \(K\)-word target multi-word
expression the coefficient for the  \(K\)-way interaction parameter in the
saturated log-linear model fitted to the counts of the terms forming the set
of eligible multi-word expressions. This is the same as the "lambda" computed
in Blaheta and Johnson's (2001), where all multi-word expressions are
considered (rather than just verbs, as in that paper). The <code>z</code> is the 
Wald \(z\)-statistic computed as the quotient of <code>lambda</code> and the Wald
statistic for <code>lambda</code> as described below.</p>
<p>In detail:</p>
<p>Consider a \(K\)-word target expression \(x\), and let \(z\) be any
\(K\)-word expression. Define a comparison function \(c(x,z)=(j_{1},
\dots, j_{K})=c\) such that the \(k\)th element of \(c\) is 1 if the
\(k\)th word in \(z\) is equal to the \(k\)th word in \(x\), and 0
otherwise. Let \(c_{i}=(j_{i1}, \dots, j_{iK})\), \(i=1, \dots,
2^{K}=M\), be the possible values of \(c(x,z)\), with \(c_{M}=(1,1,
\dots, 1)\). Consider the set of \(c(x,z_{r})\) across all expressions
\(z_{r}\) in a corpus of text, and let \(n_{i}\), for \(i=1,\dots,M\),
denote the number of the \(c(x,z_{r})\) which equal \(c_{i}\), plus the
smoothing constant <code>smoothing</code>. The \(n_{i}\) are the counts in a
\(2^{K}\) contingency table whose dimensions are defined by the
\(c_{i}\).
    \(\lambda\): The \(K\)-way interaction parameter in the saturated
loglinear model fitted to the \(n_{i}\). It can be calculated as
    $$\lambda  = \sum_{i=1}^{M} (-1)^{K-b_{i}} \log n_{i}$$</p>
<p>where \(b_{i}\) is the number of the elements of \(c_{i}\) which are
equal to 1.</p>
<p>Wald test \(z\)-statistic \(z\) is calculated as:
    $$z = \frac{\lambda}{[\sum_{i=1}^{M} n_{i}^{-1}]^{(1/2)}}$$</p>
    
    <h2 class="hasAnchor" id="note"><a class="anchor" href="#note"></a>Note</h2>

    <p>This function is under active development, with more measures to be added in the 
the next release of <span class="pkg">quanteda</span>.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Blaheta, D., &amp; Johnson, M. (2001). 
  <a href='http://web.science.mq.edu.au/~mjohnson/papers/2001/dpb-colloc01.pdf'>Unsupervised
  learning of multi-word verbs</a>. Presented at the ACLEACL Workshop on the 
  Computational Extraction, Analysis and Exploitation of Collocations.</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='no'>txts</span> <span class='kw'>&lt;-</span> <span class='no'>data_corpus_inaugural</span>[<span class='fl'>1</span>:<span class='fl'>2</span>]
<span class='fu'>head</span>(<span class='no'>cols</span> <span class='kw'>&lt;-</span> <span class='fu'>textstat_collocationsdev</span>(<span class='no'>txts</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>min_count</span> <span class='kw'>=</span> <span class='fl'>2</span>), <span class='fl'>10</span>)</div><div class='output co'>#&gt;    collocation count length   lambda        z       G2      chi2      pmi
#&gt; 1        , and    17      2 2.643957 8.170237 49.47743 108.46212 2.927463
#&gt; 2    have been     5      2 5.731000 7.487958 43.20136 399.03760 6.200685
#&gt; 3       of the    24      2 1.781820 6.830093 37.22476  58.28699 1.935835
#&gt; 4     has been     3      2 5.717327 6.584944 28.52046 323.74321 6.548608
#&gt; 5       i have     5      2 3.772416 6.461199 26.86011 113.55789 4.463719
#&gt; 6          , i    10      2 2.570085 6.377237 29.25016  65.92607 2.956032
#&gt; 7      will be     4      2 3.974267 6.109305 23.64307 112.94349 4.728587
#&gt; 8    less than     2      2 6.431212 5.663496 23.15338 373.56773 7.233106
#&gt; 9  public good     2      2 6.431212 5.663496 23.15338 373.56773 7.233106
#&gt; 10     which i     6      2 2.657154 5.555529 19.98871  52.21109 3.264154
#&gt;         LFMD
#&gt; 1  11.186029
#&gt; 2  11.119548
#&gt; 3  11.165255
#&gt; 4  10.163318
#&gt; 5   9.382582
#&gt; 6   9.740667
#&gt; 7   9.068437
#&gt; 8   9.876962
#&gt; 9   9.876962
#&gt; 10  8.665034</div><div class='input'><span class='fu'>head</span>(<span class='no'>cols</span> <span class='kw'>&lt;-</span> <span class='fu'>textstat_collocationsdev</span>(<span class='no'>txts</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>3</span>, <span class='kw'>min_count</span> <span class='kw'>=</span> <span class='fl'>2</span>), <span class='fl'>10</span>)</div><div class='output co'>#&gt;     collocation count length   lambda         z         G2       chi2       pmi
#&gt; 1  of which the     2      3 6.179554 2.8579715 13.4611112 23.7539935 3.2516278
#&gt; 2      , and of     2      3 3.066282 1.7161287  4.0540624  3.9852233 1.2377281
#&gt; 3    in which i     3      3 2.907704 1.5893955  3.4809716  3.0412877 0.7012360
#&gt; 4       , or by     2      3 3.086502 1.3263061  2.2762489  1.9886129 0.5716844
#&gt; 5     i have in     2      3 2.484260 1.1250830  1.6346876  1.4070556 0.4984132
#&gt; 6     me by the     2      3 2.362269 1.0839184  1.5158738  1.3075711 0.4867261
#&gt; 7     , and the     3      3 1.017118 1.0243655  1.0678760  1.0779195 0.5158313
#&gt; 8    and of the     2      3 1.057485 0.8988065  0.8416763  0.8445156 0.5606277
#&gt; 9     , i shall     3      3 1.661358 0.7605286  0.6951628  0.6084811 0.1996503
#&gt; 10     . on the     2      3 1.014510 0.5884358  0.3960617  0.3629160 0.2626685
#&gt;        LFMD
#&gt; 1  5.895484
#&gt; 2  3.881584
#&gt; 3  4.315946
#&gt; 4  3.215541
#&gt; 5  3.142269
#&gt; 6  3.130582
#&gt; 7  4.130541
#&gt; 8  3.204484
#&gt; 9  3.814360
#&gt; 10 2.906525</div><div class='input'>
<span class='co'># extracting multi-part proper nouns (capitalized terms)</span>
<span class='no'>toks2</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='tokens.html'>tokens</a></span>(<span class='no'>data_corpus_inaugural</span>)
<span class='no'>toks2</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='tokens_select.html'>tokens_remove</a></span>(<span class='no'>toks2</span>, <span class='fu'><a href='stopwords.html'>stopwords</a></span>(<span class='st'>"english"</span>), <span class='kw'>padding</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)
<span class='no'>toks2</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='tokens_select.html'>tokens_select</a></span>(<span class='no'>toks2</span>, <span class='st'>"^([A-Z][a-z\\-]{2,})"</span>, <span class='kw'>valuetype</span> <span class='kw'>=</span> <span class='st'>"regex"</span>,
                       <span class='kw'>case_insensitive</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>padding</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)
<span class='no'>seqs</span> <span class='kw'>&lt;-</span> <span class='fu'>textstat_collocationsdev</span>(<span class='no'>toks2</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>3</span>, <span class='kw'>tolower</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)
<span class='fu'>head</span>(<span class='no'>seqs</span>, <span class='fl'>10</span>)</div><div class='output co'>#&gt;              collocation count length     lambda         z        G2
#&gt; 1 United States Congress     2      3  -2.152404 -1.014623 0.7972545
#&gt; 2    Vice President Bush     2      3 -11.582818 -4.471125 9.6364697
#&gt;          chi2        pmi     LFMD
#&gt; 1    1.182867 -0.1873977 2.456458
#&gt; 2 9474.743454 -0.2634959 2.380360</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#note">Note</a></li>

      <li><a href="#references">References</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    
Kenneth Benoit, Jouni Kuha, Haiyan Wang, and Kohei Watanabe

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Kenneth Benoit.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
