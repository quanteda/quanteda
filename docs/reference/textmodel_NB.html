<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Naive Bayes classifier for texts — textmodel_NB • quanteda</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">quanteda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="http://github.com/kbenoit/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Naive Bayes classifier for texts</h1>
    </div>

    
    <p>Currently working for vectors of texts -- not specially defined for a dfm.</p>
    

    <pre><span class='fu'>textmodel_NB</span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='kw'>smooth</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>prior</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"uniform"</span>, <span class='st'>"docfreq"</span>, <span class='st'>"termfreq"</span>),
  <span class='kw'>distribution</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"multinomial"</span>, <span class='st'>"Bernoulli"</span>), <span class='no'>...</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <dl class="dl-horizontal">
      <dt>x</dt>
      <dd>the dfm on which the model will be fit.  Does not need to contain 
only the training documents.</dd>
      <dt>y</dt>
      <dd>vector of training labels associated with each document identified 
in <code>train</code>.  (These will be converted to factors if not already 
factors.)</dd>
      <dt>smooth</dt>
      <dd>smoothing parameter for feature counts by class</dd>
      <dt>prior</dt>
      <dd>prior distribution on texts, see details</dd>
      <dt>distribution</dt>
      <dd>count model for text features, can be <code>multinomial</code> 
or <code>Bernoulli</code></dd>
      <dt>...</dt>
      <dd>more arguments passed through</dd>
    </dl>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A list of return values, consisting of:</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>This naive Bayes model works on word counts, with smoothing.</p>
    
    <h2 class="hasAnchor" id="predict-methods"><a class="anchor" href="#predict-methods"></a>Predict Methods</h2>

    <p>A <code>predict</code> method is also available for a 
  fitted Naive Bayes object, see <code><a href='predict.textmodel_NB_fitted.html'>predict.textmodel_NB_fitted</a></code>.</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'>## Example from 13.1 of _An Introduction to Information Retrieval_</span>
<span class='no'>trainingset</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='is.dfm.html'>as.dfm</a></span>(<span class='fu'>matrix</span>(<span class='fu'>c</span>(<span class='fl'>1</span>, <span class='fl'>2</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>0</span>,
                        <span class='fl'>0</span>, <span class='fl'>2</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>0</span>,
                        <span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>0</span>,
                        <span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>1</span>,
                        <span class='fl'>0</span>, <span class='fl'>3</span>, <span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>1</span>),
                      <span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>6</span>, <span class='kw'>nrow</span><span class='kw'>=</span><span class='fl'>5</span>, <span class='kw'>byrow</span><span class='kw'>=</span><span class='fl'>TRUE</span>,
                      <span class='kw'>dimnames</span> <span class='kw'>=</span> <span class='fu'>list</span>(<span class='kw'>docs</span> <span class='kw'>=</span> <span class='fu'>paste</span>(<span class='st'>"d"</span>, <span class='fl'>1</span>:<span class='fl'>5</span>, <span class='kw'>sep</span> <span class='kw'>=</span> <span class='st'>""</span>),
                                      <span class='kw'>features</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"Beijing"</span>, <span class='st'>"Chinese"</span>,  <span class='st'>"Japan"</span>, <span class='st'>"Macao"</span>,
                                                   <span class='st'>"Shanghai"</span>, <span class='st'>"Tokyo"</span>))))
<span class='no'>trainingclass</span> <span class='kw'>&lt;-</span> <span class='fu'>factor</span>(<span class='fu'>c</span>(<span class='st'>"Y"</span>, <span class='st'>"Y"</span>, <span class='st'>"Y"</span>, <span class='st'>"N"</span>, <span class='fl'>NA</span>), <span class='kw'>ordered</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)
<span class='co'>## replicate IIR p261 prediction for test set (document 5)</span>
(<span class='no'>nb.p261</span> <span class='kw'>&lt;-</span> <span class='fu'>textmodel_NB</span>(<span class='no'>trainingset</span>, <span class='no'>trainingclass</span>))</div><div class='output co'>#&gt; Fitted Naive Bayes model:
#&gt; Call:
#&gt; 	textmodel_NB(x = trainingset, y = trainingclass)
#&gt; 
#&gt; 
#&gt; Training classes and priors:
#&gt;   Y   N 
#&gt; 0.5 0.5 
#&gt; 
#&gt; 		  Likelihoods:		Class Posteriors:
#&gt; 6 x 4 Matrix of class &quot;dgeMatrix&quot;
#&gt;                   Y         N         Y         N
#&gt; Beijing  0.14285714 0.1111111 0.5625000 0.4375000
#&gt; Chinese  0.42857143 0.2222222 0.6585366 0.3414634
#&gt; Japan    0.07142857 0.2222222 0.2432432 0.7567568
#&gt; Macao    0.14285714 0.1111111 0.5625000 0.4375000
#&gt; Shanghai 0.14285714 0.1111111 0.5625000 0.4375000
#&gt; Tokyo    0.07142857 0.2222222 0.2432432 0.7567568
#&gt; </div><div class='input'><span class='fu'>predict</span>(<span class='no'>nb.p261</span>, <span class='kw'>newdata</span> <span class='kw'>=</span> <span class='no'>trainingset</span>[<span class='fl'>5</span>, ])</div><div class='output co'>#&gt; Predicted textmodel of type: Naive Bayes
#&gt; 
#&gt;        lp(Y)     lp(N)     Pr(Y)  Pr(N) Predicted
#&gt; d5 -8.513155 -8.213534    0.4257 0.5743         N
#&gt; </div><div class='input'>
<span class='co'># contrast with other priors</span>
<span class='fu'>predict</span>(<span class='fu'>textmodel_NB</span>(<span class='no'>trainingset</span>, <span class='no'>trainingclass</span>, <span class='kw'>prior</span> <span class='kw'>=</span> <span class='st'>"docfreq"</span>))</div><div class='output co'>#&gt; Predicted textmodel of type: Naive Bayes
#&gt; 
#&gt;        lp(Y)     lp(N)     Pr(Y)  Pr(N) Predicted
#&gt; d1 -3.928188 -6.591674    0.9348 0.0652         Y
#&gt; d2 -3.928188 -6.591674    0.9348 0.0652         Y
#&gt; d3 -3.080890 -5.087596    0.8815 0.1185         Y
#&gt; d4 -6.413095 -5.898527    0.3741 0.6259         N
#&gt; d5 -8.107690 -8.906681    0.6898 0.3102         Y
#&gt; </div><div class='input'><span class='fu'>predict</span>(<span class='fu'>textmodel_NB</span>(<span class='no'>trainingset</span>, <span class='no'>trainingclass</span>, <span class='kw'>prior</span> <span class='kw'>=</span> <span class='st'>"termfreq"</span>))</div><div class='output co'>#&gt; Predicted textmodel of type: Naive Bayes
#&gt; 
#&gt;        lp(Y)     lp(N)     Pr(Y)  Pr(N) Predicted
#&gt; d1 -3.958960 -6.504662    0.9273 0.0727         Y
#&gt; d2 -3.958960 -6.504662    0.9273 0.0727         Y
#&gt; d3 -3.111662 -5.000585    0.8686 0.1314         Y
#&gt; d4 -6.443866 -5.811515    0.3470 0.6530         N
#&gt; d5 -8.138462 -8.819670    0.6640 0.3360         Y
#&gt; </div><div class='input'>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#predict-methods">Predict Methods</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    
Kenneth Benoit

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Kenneth Benoit.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
