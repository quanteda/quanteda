<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Construct a tokens object — tokens • quanteda</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous"><link href="../docsearch.css" rel="stylesheet"><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><link href="../extra.css" rel="stylesheet"><script src="../extra.js"></script><meta property="og:title" content="Construct a tokens object — tokens"><meta property="og:description" content="Construct a tokens object, either by importing a named list of
characters from an external tokenizer, or by calling the internal
quanteda tokenizer.
tokens() can also be applied to tokens class objects, which
means that the removal rules can be applied post-tokenization, although it
should be noted that it will not be possible to remove things that are not
present.  For instance, if the tokens object has already had punctuation
removed, then tokens(x, remove_punct = TRUE) will have no additional
effect."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-0F398Z98L1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0F398Z98L1');
</script></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">quanteda</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">4.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Quick Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/quickstart.html">Quick Start Guide</a>
    </li>
    <li>
      <a href="../articles/pkgdown/quickstart_es.html">Guía de Inicio Rápido</a>
    </li>
    <li>
      <a href="../articles/pkgdown/quickstart_cn.html">快速入门指南</a>
    </li>
    <li>
      <a href="../articles/pkgdown/quickstart_ja.html">クイック・スタートガイド</a>
    </li>
    <li>
      <a href="../articles/pkgdown/quickstart_hi.html">त्वरित आरंभ </a>
    </li>
  </ul></li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Features
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/pkgdown/tokens_xptr.html">External pointer tokens objects</a>
    </li>
    <li>
      <a href="../articles/pkgdown/benchmarks_xptr.html">Performance benchmarks for v4</a>
    </li>
    <li>
      <a href="../articles/pkgdown/design.html">Package design</a>
    </li>
    <li>
      <a href="../news/index.html">Changelog</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/pkgdown/examples/phrase.html">Multi-word expressions</a>
    </li>
    <li>
      <a href="../articles/pkgdown/examples/plotting.html">Textual data visualization</a>
    </li>
    <li>
      <a href="../articles/pkgdown/examples/lsa.html">Latent Semantic Analysis (LSA)</a>
    </li>
    <li>
      <a href="../articles/pkgdown/examples/chinese.html">Chinese text analysis</a>
    </li>
    <li>
      <a href="../articles/pkgdown/examples/twitter.html">Social media analysis</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Replications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/pkgdown/replication/digital-humanities.html">Text Analysis with R for Students of Literature</a>
    </li>
    <li>
      <a href="../articles/pkgdown/replication/text2vec.html">Word embedding (word2vec)</a>
    </li>
    <li>
      <a href="../articles/pkgdown/replication/qss.html">Quantitative Social Science Ch. 5.1</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/quanteda/quanteda" class="external-link">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul><form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off"></div>
      </form>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Construct a tokens object</h1>
    <small class="dont-index">Source: <a href="https://github.com/quanteda/quanteda/blob/HEAD/R/tokens.R" class="external-link"><code>R/tokens.R</code></a></small>
    <div class="hidden name"><code>tokens.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Construct a tokens object, either by importing a named list of
characters from an external tokenizer, or by calling the internal
<span class="pkg">quanteda</span> tokenizer.</p>
<p><code>tokens()</code> can also be applied to tokens class objects, which
means that the removal rules can be applied post-tokenization, although it
should be noted that it will not be possible to remove things that are not
present.  For instance, if the <code>tokens</code> object has already had punctuation
removed, then <code>tokens(x, remove_punct = TRUE)</code> will have no additional
effect.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">tokens</span><span class="op">(</span></span>
<span>  <span class="va">x</span>,</span>
<span>  what <span class="op">=</span> <span class="st">"word"</span>,</span>
<span>  remove_punct <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  remove_symbols <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  remove_numbers <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  remove_url <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  remove_separators <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  split_hyphens <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  split_tags <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  include_docvars <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  padding <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  concatenator <span class="op">=</span> <span class="st">"_"</span>,</span>
<span>  verbose <span class="op">=</span> <span class="fu"><a href="quanteda_options.html">quanteda_options</a></span><span class="op">(</span><span class="st">"verbose"</span><span class="op">)</span>,</span>
<span>  <span class="va">...</span>,</span>
<span>  xptr <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>x</dt>
<dd><p>the input object to the tokens constructor; a tokens, <a href="corpus.html">corpus</a> or
<a href="https://rdrr.io/r/base/character.html" class="external-link">character</a> object to tokenize.</p></dd>


<dt>what</dt>
<dd><p>character; which tokenizer to use.  The default <code>what = "word"</code>
is the current version of the <span class="pkg">quanteda</span> tokenizer, set by
<code>quanteda_options(okens_tokenizer_word)</code>. Legacy tokenizers (version &lt; 2)
are also supported, including the default <code>what = "word1"</code>. See the Details
and quanteda Tokenizers below.</p></dd>


<dt>remove_punct</dt>
<dd><p>logical; if <code>TRUE</code> remove all characters in the Unicode
"Punctuation" <code>[P]</code> class, with exceptions for those used as prefixes for
valid social media tags if <code>preserve_tags = TRUE</code></p></dd>


<dt>remove_symbols</dt>
<dd><p>logical; if <code>TRUE</code> remove all characters in the Unicode
"Symbol" <code>[S]</code> class</p></dd>


<dt>remove_numbers</dt>
<dd><p>logical; if <code>TRUE</code> remove tokens that consist only of
numbers, but not words that start with digits, e.g. <code>2day</code></p></dd>


<dt>remove_url</dt>
<dd><p>logical; if <code>TRUE</code> removes URLs (http, https, ftp, sftp)
and email addresses.</p></dd>


<dt>remove_separators</dt>
<dd><p>logical; if <code>TRUE</code> remove separators and separator
characters (Unicode "Separator" <code>[Z]</code> and "Control" <code>[C]</code> categories)</p></dd>


<dt>split_hyphens</dt>
<dd><p>logical; if <code>FALSE</code>, do not split words that are
connected by hyphenation and hyphenation-like characters in between words,
e.g. <code>"self-aware"</code> becomes <code>c("self", "-", "aware")</code></p></dd>


<dt>split_tags</dt>
<dd><p>logical; if <code>FALSE</code>, do not split social media tags defined
in <code><a href="quanteda_options.html">quanteda_options()</a></code>. The default patterns are <code>pattern_hashtag = "#\\w+#?"</code> and <code>pattern_username = "@[a-zA-Z0-9_]+"</code>.</p></dd>


<dt>include_docvars</dt>
<dd><p>if <code>TRUE</code>, pass docvars through to the tokens object.
Does not apply when the input is a character data or a list of characters.</p></dd>


<dt>padding</dt>
<dd><p>if <code>TRUE</code>, leave an empty string where the removed tokens
previously existed.  This is useful if a positional match is needed between
the pre- and post-selected tokens, for instance if a window of adjacency
needs to be computed.</p></dd>


<dt>concatenator</dt>
<dd><p>character; the concatenation character that will connect
the tokens making up a multi-token sequence.</p></dd>


<dt>verbose</dt>
<dd><p>if <code>TRUE</code>, print timing messages to the console</p></dd>


<dt>...</dt>
<dd><p>used to pass arguments among the functions</p></dd>


<dt>xptr</dt>
<dd><p>if <code>TRUE</code>, returns a <code>tokens_xptr</code> class object</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    

<p><span class="pkg">quanteda</span></p>
<p></p>
<p><code>tokens</code> class object, by default a serialized list of
integers corresponding to a vector of types.</p>
    </div>
    <div id="details">
    <h2>Details</h2>
    <p>As of version 2, the choice of tokenizer is left more to
the user, and <code>tokens()</code> is treated more as a constructor (from a named
list) than a tokenizer. This allows users to use any other tokenizer that
returns a named list, and to use this as an input to <code>tokens()</code>, with
removal and splitting rules applied after this has been constructed (passed
as arguments).  These removal and splitting rules are conservative and will
not remove or split anything, however, unless the user requests it.</p>
<p>You usually do not want to split hyphenated words or social media tags, but
extra steps required to preserve such special tokens. If there are many
random characters in your texts, you should <code>split_hyphens = TRUE</code> and
<code>split_tags = TRUE</code> to avoid a slowdown in tokenization.</p>
<p>Using external tokenizers is best done by piping the output from these
other tokenizers into the <code>tokens()</code> constructor, with additional removal
and splitting options applied at the construction stage.  These will only
have an effect, however, if the tokens exist for which removal is specified
at in the <code>tokens()</code> call.  For instance, it is impossible to remove
punctuation if the input list to <code>tokens()</code> already had its punctuation
tokens removed at the external tokenization stage.</p>
<p>To construct a tokens object from a list with no additional processing,
call <code><a href="as.tokens.html">as.tokens()</a></code> instead of <code>tokens()</code>.</p>
<p>Recommended tokenizers are those from the <span class="pkg">tokenizers</span> package, which
are generally faster than the default (built-in) tokenizer but always
splits infix hyphens, or <span class="pkg">spacyr</span>.  The default tokenizer in
<strong>quanteda</strong> is very smart, however, and if you do not have special
requirements, it works extremely well for most languages as well as text
from social media (including hashtags and usernames).</p>
    </div>
    <div id="quanteda-tokenizers">
    <h2>quanteda Tokenizers</h2>
    <p>The default word tokenizer <code>what = "word"</code> is
updated in major version 4.  It is even smarter than the v3 and v4
versions, with additional options for customization.  See
<code><a href="tokenize_internal.html">tokenize_word4()</a></code> for full details.</p>
<p>The default tokenizer splits tokens using <a href="https://rdrr.io/pkg/stringi/man/stri_split_boundaries.html" class="external-link">stri_split_boundaries(x, type = "word")</a> but by default preserves infix
hyphens (e.g. "self-funding"), URLs, and social media "tag" characters
(#hashtags and @usernames), and email addresses.  The rules defining a
valid "tag" can be found at
https://www.hashtags.org/featured/what-characters-can-a-hashtag-include/
for hashtags and at
https://help.twitter.com/en/managing-your-account/twitter-username-rules
for usernames.</p>
<p>For backward compatibility, the following older tokenizers are also
supported through <code>what</code>:</p><dl><dt><code>"word1"</code></dt>
<dd><p>(legacy) implements
similar behaviour to the version of <code>what = "word"</code> found in pre-version 2.
(It preserves social media tags and infix hyphens, but splits URLs.)
"word1" is also slower than "word2" and "word4".  In "word1",
the argument <code>remove_twitter</code> controlled whether social
media tags were preserved or removed, even when <code>remove_punct = TRUE</code>. This
argument is not longer functional in versions &gt;= 2, but equivalent control
can be had using the <code>split_tags</code> argument and selective tokens removals.</p></dd>

<dt><code>"word2", "word3"</code></dt>
<dd><p>(legacy) implements
similar behaviour to the versions of "word" found in <span class="pkg">quanteda</span> versions
3 and 4.</p></dd>

<dt><code>"fasterword"</code></dt>
<dd><p>(legacy) splits
on whitespace and control characters, using
<code>stringi::stri_split_charclass(x, "[\\p{Z}\\p{C}]+")</code></p></dd>

<dt><code>"fastestword"</code></dt>
<dd><p>(legacy) splits on the space character, using
<code>stringi::stri_split_fixed(x, " ")</code></p></dd>
 <dt><code>"character"</code></dt>
<dd><p>tokenization into
individual characters</p></dd>
 <dt><code>"sentence"</code></dt>
<dd><p>sentence segmenter based on
<a href="https://rdrr.io/pkg/stringi/man/stri_split_boundaries.html" class="external-link">stri_split_boundaries</a>, but with
additional rules to avoid splits on words like "Mr." that would otherwise
incorrectly be detected as sentence boundaries.  For better sentence
tokenization, consider using <span class="pkg">spacyr</span>.</p></dd>
 
</dl></div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="tokens_ngrams.html">tokens_ngrams()</a></code>, <code><a href="tokens_ngrams.html">tokens_skipgrams()</a></code>, <code><a href="tokens_compound.html">tokens_compound()</a></code>,
<code><a href="tokens_lookup.html">tokens_lookup()</a></code>, <code><a href="concat.html">concat()</a></code>, <code><a href="as.tokens.html">as.list.tokens()</a></code>, <code><a href="as.tokens.html">as.tokens()</a></code></p></div>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">txt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>doc1 <span class="op">=</span> <span class="st">"A sentence, showing how tokens() works."</span>,</span></span>
<span class="r-in"><span>         doc2 <span class="op">=</span> <span class="st">"@quantedainit and #textanalysis https://example.com?p=123."</span>,</span></span>
<span class="r-in"><span>         doc3 <span class="op">=</span> <span class="st">"Self-documenting code??"</span>,</span></span>
<span class="r-in"><span>         doc4 <span class="op">=</span> <span class="st">"£1,000,000 for 50¢ is gr8 4ever \U0001f600"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 4 documents.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc1 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "A"        "sentence" ","        "showing"  "how"      "tokens"  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7] "("        ")"        "works"    "."       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc2 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "@quantedainit"              "and"                       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3] "#textanalysis"              "https://example.com?p=123."</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc3 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Self-documenting" "code"             "?"                "?"               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc4 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "£"         "1,000,000" "for"       "50"        "¢"         "is"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] "gr8"       "4ever"     "😀"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span>, what <span class="op">=</span> <span class="st">"word1"</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 4 documents.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc1 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "A"        "sentence" ","        "showing"  "how"      "tokens"  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7] "("        ")"        "works"    "."       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc2 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "@quantedainit" "and"           "#textanalysis" "https"        </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [5] ":"             "/"             "/"             "example.com"  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [9] "?"             "p"             "="             "123"          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ ... and 1 more ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc3 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Self-documenting" "code"             "?"                "?"               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc4 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "£"         "1,000,000" "for"       "50"        "¢"         "is"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] "gr8"       "4ever"     "😀"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># removing punctuation marks but keeping tags and URLs</span></span></span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, remove_punct <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 2 documents.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc1 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "A"        "sentence" "showing"  "how"      "tokens"   "works"   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc2 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "@quantedainit"              "and"                       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [3] "#textanalysis"              "https://example.com?p=123."</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># splitting hyphenated words</span></span></span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc3 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Self-documenting" "code"             "?"                "?"               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, split_hyphens <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc3 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Self"        "-"           "documenting" "code"        "?"          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6] "?"          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># symbols and numbers</span></span></span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc4 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "£"         "1,000,000" "for"       "50"        "¢"         "is"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [7] "gr8"       "4ever"     "😀"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span>, remove_numbers <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc4 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "£"     "for"   "¢"     "is"    "gr8"   "4ever" "😀"   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span>, remove_numbers <span class="op">=</span> <span class="cn">TRUE</span>, remove_symbols <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc4 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "for"   "is"    "gr8"   "4ever"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="co"># using other tokenizers</span></span></span>
<span class="r-in"><span><span class="fu">tokens</span><span class="op">(</span><span class="fu">tokenizers</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html" class="external-link">tokenize_words</a></span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>, remove_symbols <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu">tokenizers</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html" class="external-link">tokenize_words</a></span><span class="op">(</span><span class="va">txt</span>, lowercase <span class="op">=</span> <span class="cn">FALSE</span>, strip_punct <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="fu">tokens</span><span class="op">(</span>remove_symbols <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 4 documents.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc1 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "A"        "sentence" ","        "showing"  "how"      "tokens"  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7] "("        ")"        "works"    "."       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc2 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "@"            "quantedainit" "and"          "#"            "textanalysis"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [6] "https"        ":"            "/"            "/"            "example.com" </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [11] "?"            "p"           </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ ... and 2 more ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc3 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Self"        "-"           "documenting" "code"        "?"          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [6] "?"          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc4 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "1,000,000" "for"       "50"        "is"        "gr8"       "4ever"    </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">tokenizers</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html" class="external-link">tokenize_characters</a></span><span class="op">(</span><span class="va">txt</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, strip_non_alphanum <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="fu">tokens</span><span class="op">(</span>remove_punct <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> doc3 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "s" "e" "l" "f" "d" "o" "c" "u" "m" "e" "n" "t"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [ ... and 7 more ]</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="fu">tokenizers</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html" class="external-link">tokenize_sentences</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>    <span class="st">"The quick brown fox.  It jumped over the lazy dog."</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="fu">tokens</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Tokens consisting of 1 document.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> text1 :</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "The quick brown fox."         "It jumped over the lazy dog."</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Kenneth Benoit, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng, Stefan Müller, Akitaka Matsuo, William Lowe, European Research Council.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer></div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: '9b4ef7fd791dc6075154d3ebd7b12acf',
    indexName: 'quanteda',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script></body></html>

