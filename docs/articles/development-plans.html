<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Quanteda Structure and Design &bull; quanteda</title><!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">quanteda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="http://github.com/kbenoit/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Quanteda Structure and Design</h1>
                        <h4 class="author">Ken Benoit</h4>
            
            <h4 class="date">2016-12-06</h4>
          </div>

    
    
<div class="contents">
<div id="introduction" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#introduction" class="anchor"> </a></body></html>Introduction</h1>
<div id="changes-in-v0-9-9" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#changes-in-v0-9-9" class="anchor"> </a></body></html>Changes in v0.9.9</h2>
<p>In v0.9.9, we have made some major changes to the <strong>quanteda</strong>&rsquo;s API. While this &ldquo;breaks&rdquo; some of the commands used previously, it has the advantage going forward of making the function names much more consistent. As a consequence, we hope that the new API will be easier to learn, as well as easier to extend. The changes follow long discussions with the core contributors, reflections on user experiences following many training sessions, classes taught using the package, and feedback received through various on-line forums. This document explains the new, more consistent overall logic and grammar of the package.</p>
</div>
<div id="why-did-the-api-need-changing" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#why-did-the-api-need-changing" class="anchor"> </a></body></html>Why did the API need changing?</h2>
<p>As of 0.9.8.5, <strong>quanteda</strong> started to get a bit haphazard in terms of names and functionality, defeating some of the purposes for which it was designed (to be simple to use and intuitive). In addition, renaming and reorganizing makes it easier:</p>
<ol style="list-style-type: decimal"><li>To comply more with <a href="https://github.com/ropensci/onboarding/blob/master/packaging_guide.md#funvar">standards recommended by ROpenSci</a>, the functions and their operation have been renamed.<br></li>
<li>To interface more easily with other packages, such as <strong>tokenizers</strong>, to do some of the lower-level work without reinventing it.<br></li>
<li>To make the package easier to extend, for instance by writing companion packages that depend on <strong>quanteda</strong>, such as <strong>readtext</strong>.</li>
</ol></div>
</div>
<div id="the-new-logic-of-quantedas-design" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#the-new-logic-of-quantedas-design" class="anchor"> </a></body></html>The new logic of <strong>quanteda</strong>&rsquo;s design</h1>
<div id="grammatical-rules" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#grammatical-rules" class="anchor"> </a></body></html>Grammatical rules</h2>
<p>The new &ldquo;grammar&rdquo; of the package is split between three basic types of functions and data objects:</p>
<ul><li><p><em>object</em>: a constructor function named <code>object()</code> that returns an object of class <em>object</em>. Example: <code><a href="../reference/corpus.html">corpus()</a></code> constructs a <code>corpus</code> class object.</p></li>
<li><p><em>object</em><code>_</code><em>verb</em>: a function that inputs an object of class <em>object</em>, and returns a a modified <em>object</em> class object. There are no exceptions to this naming rule, so that even functions that operate on character objects following this convention, such as <code><a href="../reference/char_tolower.html">char_tolower()</a></code>. (Ok, so there is a slight exception: we abbreviated <code>character</code> to <code>char</code>!)</p></li>
<li><p><code>data_</code><em>class</em><code>_</code><em>descriptor</em>: data objects are named this way to clearly distinguish them and to make them easy to identify in the index. The first part identifies them as data, the second names their object class, and the third component is a descriptor. Example: <code>data_corpus_inaugural</code> is the <strong>quanteda</strong> <code>corpus</code> class object consisting of the US presidents&rsquo; inaugural addresses.</p></li>
<li><p><code>text</code><em>general</em><code>_</code><em>specific</em>: functions that input a <strong>quanteda</strong> object and return the result of an analysis. Only the underscored functions that begin with <code>text</code> break the previous rule about the first part of the name identifying the object class that is input and output. Examples: <code><a href="../reference/textstat_readability.html">textstat_readability()</a></code> takes a character or corpus as input, and returns a data.frame; <code><a href="../reference/textplot_xray.html">textplot_xray()</a></code> takes a <code>kwic</code> object as input, and generates a dispersion plot (named &ldquo;x-ray&rdquo; because of its similarity to the plot produced by Kindle).</p></li>
<li><p>Extensions of R functions: These are commonly used R functions, such as <code>head()</code>, that are also defined for <strong>quanteda</strong> objects. Examples: <code><a href="../reference/head.dfm.html">head.dfm()</a></code>, coercion functions such as <code>as.list.tokens</code>, and Boolean class type checking functions such as <code><a href="../reference/is.dfm.html">is.dfm()</a></code>.</p></li>
<li><p>R-like functions. These are functions for <strong>quanteda</strong> objects that follow naming conventions and functionality that should be very familiar to users of R. Example: <code><a href="../reference/ndoc.html">ndoc()</a></code> returns the number of documents in a corpus, tokens, or dfm object, similar to <code>base::nrow()</code>. Note that like <code>nrow()</code>, <code><a href="../reference/ndoc.html">ndoc()</a></code> is not plural. Other examples include <code><a href="../reference/docnames.html">docnames()</a></code> and <code><a href="../reference/featnames.html">featnames()</a></code> &ndash; similar to <code>rownames()</code> and <code>colnames()</code>.</p></li>
<li><p>Grammatical exceptions: Every language has these, usually due to path dependency from historical development, and <strong>quanteda</strong> is no exception. The list, however, is short:</p>
<ul><li><code>convert</code>: converts from a dfm to foreign package formats<br></li>
<li><code>sparsity</code>: returns the sparsity (as a proportion) of a dfm<br></li>
<li><code>topfeatures</code>: returns a named vector of the counts of the most frequently occurring features in a <code>dfm</code>.</li>
</ul></li>
</ul></div>
<div id="constructors-for-core-data-types" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#constructors-for-core-data-types" class="anchor"> </a></body></html>Constructors for core data types</h2>
<p>The <strong>quanteda</strong> package consists of a few core data types, created by calling constructors with identical names. These are all &ldquo;nouns&rdquo; in the sense of declaring what they construct. This follows very similar R behaviour in many of the core R objects, such as <code>data.frame()</code>, <code>list()</code>, etc.</p>
<p>Core object types and their constructor functions:</p>
<ul><li><code>corpus</code><br></li>
<li><code>tokens</code> (in &lt;= 0.9.8.5, <code>tokenize</code> to produce a <code>tokenizedTexts</code> class object)</li>
<li><code>dfm</code><br></li>
<li><code>fcm</code></li>
<li><code>kwic</code></li>
<li><code>dictionary</code><br></li>
<li><code>collocations</code></li>
</ul><p>Note that a core object class in <strong>quanteda</strong> is also the <code>character</code> atomic type, for which there is no constructor function, and is abbreviated as <code>char</code> in the function nomenclature.</p>
</div>
<div id="functions-for-manipulating-core-data-types" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#functions-for-manipulating-core-data-types" class="anchor"> </a></body></html>Functions for manipulating core data types</h2>
<div id="naming-convention" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#naming-convention" class="anchor"> </a></body></html>Naming convention</h3>
<p>All functions that begin with the name of a core object class will both <em>input</em> and <em>output</em> an object of this class, without exception.</p>
<p>This replaces the approach in versions up to 0.9.8.5 where a general methods such as <code><a href="../reference/selectFeatures.dfm.html">selectFeatures()</a></code> was defined for each applicable class of core object. This approach made the specific function behaviour unpredictable from the description of the general behaviour. It also made it difficult to get an overview of the functionality available for each object class. By renaming these functions following the convention of object class, followed by an underscore, followed by a verb (or verb-like statement), we could both separate the behaviours into specific functions, as well as clearly describe through the function name what action is taken on what type of object.</p>
</div>
<div id="advantages" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#advantages" class="anchor"> </a></body></html>Advantages</h3>
<p>In our view, the advantages of this clarity outweigh whatever advantages might be found from overloading a generic function. The functions <code>corpus_sample</code>, <code>tokens_sample</code>, and <code>dfm_sample</code>, for instance, are clearer to understand and read from a package&rsquo;s function index, than the previously overloaded version of <code><a href="../reference/sample.html">sample()</a></code> that could be dispatched on a corpus, tokenized text, or dfm object. Additionally, in the case of <code><a href="../reference/sample.html">sample()</a></code>, we avoid the namespace &ldquo;conflict&rdquo; caused by redefining the function as a generic, so that it could be overloaded. Our new, more specific naming conventions therefore reduce the likelihood of namespace conflicts with other packages.</p>
</div>
<div id="why-are-some-operations-unavailable-for-specific-object-types" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#why-are-some-operations-unavailable-for-specific-object-types" class="anchor"> </a></body></html>Why are some operations unavailable for specific object types?</h3>
<p>Because not every operation makes sense for every object type. Take the example of a &ldquo;feature co-occurrence matrix&rdquo;, or <code>fcm</code>. Construction of a feature co-occurrence matrix is be slightly different from constructing a dfm. Unlike the &ldquo;Swiss-army&rdquo; knife approach of <code><a href="../reference/dfm.html">dfm()</a></code>, which can operate directly on texts, <code><a href="../reference/fcm.html">fcm()</a></code> works only on tokens, since the definition of how the context of co-occurrence is defined is dependent on token sequences and therefore highly dependent on tokenization options. In addition, <code><a href="../reference/fcm.html">fcm()</a></code> is likely to be used a lot less frequently, and primarily by more expert users.</p>
<p>Futhermore, many functions defined for <code>fcm</code> objects <em>should</em> be unavailable, because they violate the principles of the object. For instance, <code>fcm_wordstem</code> and <code>fcm_tolower</code> should not be applied to <code>fcm</code> objects, because collapsing these and treating them as equivalent (as for a dfm object) is incorrect for the context in which co-occurrence is defined, such as a +/- 5 token window.</p>
</div>
</div>
<div id="extensions-of-core-r-functions" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#extensions-of-core-r-functions" class="anchor"> </a></body></html>Extensions of core R functions</h2>
<p>Many simple base R functions &ndash; simpler at least than the example of <code><a href="../reference/sample.html">sample()</a></code> cited above &ndash; are still extended to quanteda objects through overloading. The logic of allowing is that these functions, e.g. <code>cbind()</code> for a dfm, are very simple and very common, and therefore are well-known to users. Furthermore, they can operate in only one fashion on the object for which they are defined, such as <code>cbind()</code> combining two dfm objects by joining columns. Similar functions extended in this way include <code>print</code>, <code>head</code>, <code>tail</code>, and <code>t()</code>. Most of these functions are so natural that their documentation is not included in the package index.</p>
</div>
<div id="additions-to-core-r-like-functions" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#additions-to-core-r-like-functions" class="anchor"> </a></body></html>Additions to core R(-like) functions</h2>
<p>Additional functions have been defined for <strong>quanteda</strong> objects that are <a href="#r-like-functions">very similar to simple base R functions</a>, but are not named using the <code>class_action</code> format because they do not return a modified object of the same class. These follow as closely as possible the naming conventions found in the base R functions that are similar. For instance, <code><a href="../reference/docnames.html">docnames()</a></code> and <code><a href="../reference/featnames.html">featnames()</a></code> return the document names of various <strong>quanteda</strong> objects, in the same way that <code>rownames()</code> does for matrix-like objects (a matrix, data.frame, data.table, etc.). The abbreviation of <code><a href="../reference/featnames.html">featnames()</a></code> is intentionally modeled on <code>colnames()</code>. Likewise, <code><a href="../reference/ndoc.html">ndoc()</a></code> returns the number of documents, using the singular form similar to <code>nrow()</code> and <code>ncol()</code>.</p>
</div>
</div>
<div id="workflow-principles" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#workflow-principles" class="anchor"> </a></body></html>Workflow principles</h1>
<p><strong>quanteda</strong> is designed both to facilitate and to enforce a &ldquo;best-practice&rdquo; workflow. This includes the following basic principles.</p>
<ol style="list-style-type: decimal"><li><p><strong>Corpus texts should remain <em>unchanged</em> during subsequent analysis and processing.</strong> In other words, after <em>loading</em> and <em>encoding</em>, we should discourage users from modifying a corpus of texts as a form of processing, so that the corpus can act as a library and record of the original texts, prior to any downstream processing. This not only aids in replication, but also means that a corpus presents the unmodified texts to which any processing, feature selection, transformations, or sampling may be applied or reapplied, without hard-coding any changes made as part of the process of analyzing the texts. The only exception is to reshape the units of text in a corpus, but we will record the details of this reshaping to make it relatively easy to reverse unit changes. Since the definition of a &ldquo;document&rdquo; is part of the process of loading texts into a corpus, however, rather than processing, we will take a less stringent line on this aspect of changing a corpus.</p></li>
<li><p><strong>A corpus should be capable of holding additional objects that will be associated with the corpus, such as dictionaries, stopword, and phrase lists.</strong> These will be named objects, that can be invoked when using (for instance) <code><a href="../reference/dfm.html">dfm()</a></code>. This allows a corpus to contain all of the additional objects that would normally be associated with it, rather than requiring a set of separate, extra-corpus objects.</p></li>
<li><p><strong>Objects should record histories of the operations applied to them.</strong> This is for purposes of analytic transparency. A tokens object and a dfm object, for instance, should have settings that record the processing options applied to the texts or corpus from which they were created. These provide a record of what was done to the text, and where it came from. Examples are <code>tokens_tolower</code>, <code>dfm_wordstem</code>, and settings such as <code>removeTwitter</code>. They also include any objects used in feature selection, such as dictionaries or stopword lists.</p></li>
<li><p><strong>A dfm should always be a <em>documents</em> (or document groups) in rows by <em>features</em> in columns.</strong> Period.</p></li>
<li><p><strong>Encoding of texts</strong> should always be UTF-8. Period.</p></li>
</ol></div>
<div id="basic-text-analysis-workflow" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#basic-text-analysis-workflow" class="anchor"> </a></body></html>Basic text analysis workflow</h1>
<div id="working-with-a-corpus-documents-and-features" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#working-with-a-corpus-documents-and-features" class="anchor"> </a></body></html>Working with a corpus, documents, and features</h2>
<ol style="list-style-type: decimal"><li><p><strong>Creating the corpus</strong></p>
<p>Reading files, probably using <code><a href="../reference/textfile.html">textfile()</a></code>, then creating a corpus using <code><a href="../reference/corpus.html">corpus()</a></code>, making sure the texts have a common encoding, and adding document variables (<code>docvars</code>) and metadata (<code>metadoc</code> and <code>metacorpus</code>).</p></li>
<li><p><strong>Defining and delimiting documents</strong></p>
<p>Defining what are &ldquo;texts&rdquo;, for instance using <code>changeunits</code> or grouping.</p>
<p>Suggestion: add a <code>groups=</code> option to <code><a href="../reference/texts.html">texts()</a></code>, to extract texts from a corpus concatenated by groups of document variables. (This functionality is currently only available through <code>dfm</code>.)</p></li>
<li><p><strong>Defining and delimiting textual features</strong></p>
This step involves defining and extracting the relevant features from each document, using <code>tokens</code>, the main function for this step, involves indentifying instances of defined features (&ldquo;tokens&rdquo;) and extracting them as vectors. Usually these will consist of words, but may also consist of:
<ul><li><code>ngrams</code>: adjacent sequences of words, not separated by punctuation marks or sentence boundaries; including</li>
<li>multi-word expressions, through <code>tokens_compound</code>, for selected word ngrams as identified in selected lists rather than simply using all adjacent word pairs or n-sequences.</li>
</ul><p><code>tokens</code> returns a new object class of tokenized texts, a hashed list of index types, with each element in the list corresponding to a document, and each hash vector representing the tokens in that document.</p>
By defining the broad class of tokens we wish to extract, in this step we also apply rules that will keep or ignore elements such as punctuation or digits, or special aggregations of word and other characters that make up URLS, Twitter tags, or currency-prefixed digits. This will involve adding the following options to <code>tokenize</code>:
<ul><li><code>removeDigits</code></li>
<li><code>removePunct</code></li>
<li><code>removeAdditional</code></li>
<li><code>removeTwitter</code></li>
<li><code>removeURL</code></li>
</ul><p><strong>By default</strong>, <code><a href="../reference/tokens.html">tokens()</a></code> extracts word tokens, and only <code>removeSeparators</code> is <code>TRUE</code>, meaning that <code><a href="../reference/tokens.html">tokens()</a></code> will return a list including punctuation as tokens. This follows a philosophy of minimal intervention, and one requiring that additional decisions be made explicit by the user when invoking <code><a href="../reference/tokenize.html">tokenize()</a></code>. Note that in the <code><a href="../reference/dfm.html">dfm()</a></code> method described below, however, we do turn on all of these options except <code>removeTwitter</code>, which is by default <code>FALSE</code>.</p>
For converting to lowercase, it is actually <em>faster</em> to perform this step <em>before</em> tokenization, but logically it falls under the next workflow step. However for efficiency, <code>*_tolower()</code> functions are defined for:
<ul><li>a character vector</li>
<li>a tokens object</li>
<li>a dfm object</li>
</ul><p>Since the tokenizer we will use may not distinguish the puncutation characters used in constructs such as URLs, email addresses, Twitter handles, or digits prefixed by currency symbols, we will mostly need to use a substitution strategy to replace these with alternative characters prior to tokenization, and then replace the substitutions with the original characters. This will slow down processing but will only be active by explicit user request for this type of handling to take place.</p>
<p>Note that that defining and delimiting features may alao include their <em>parts of speech</em>, meaning we will need to add functionality for POS tagging and extraction in this step.</p></li>
<li><p><strong>Further feature selection</strong></p>
Once features have been identified and separated from the texts in the tokenization step, features may be removed from token lists, or handled as part of <code>dfm</code> construction. Features may be:
<ul><li><em>eliminated</em> through use of predefined lists or patterns of <em>stop words</em>, using <code>removeFeatures</code> or <code>ignoredFeatures</code> (<code>dfm</code> option)</li>
<li><em>kept</em> through through use of predefined lists or patterns of <em>stop words</em>, using <code>removeFeatures</code> or <code>keptFeatures</code> (<code>dfm</code> option)</li>
<li><em>collapsed</em> by:
<ul><li>considering morphological variations as equivalent to a stem or lemma, through <code>stem</code> option in <code>dfm</code> (or <code>dfm_wordstem</code>)</li>
<li>considering lists of features as equivalent to a <em>dictionary</em> key, either exclusively (<code>dfm</code> option <code>dictionary</code>) or as a supplement to uncollapsed features (<code>dfm</code> option <code>thesaurus</code>)</li>
<li><code>tolower</code> to consider as equivalent the same word features despite having different cases, by converting all features to lower case</li>
</ul></li>
</ul><p>It will be sometimes possible to perform these steps separately from the <code>dfm</code> creating stage, but in most cases these steps will be performed as options to the <code>dfm</code> function.</p></li>
<li><p><strong>Analysis of the documents and features</strong></p>
<ol style="list-style-type: decimal"><li><p>From a corpus.</p>
These steps don&rsquo;t necessarily require the processing steps above.
<ul><li><code>kwic</code></li>
<li><code>textstat_readability</code></li>
<li><code>summary</code></li>
</ul></li>
<li><p>From a dfm &ndash; after <code>dfm</code> on the processed document and features.</p></li>
</ol></li>
</ol></div>
<div id="dfm-the-swiss-army-knife" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#dfm-the-swiss-army-knife" class="anchor"> </a></body></html><code>dfm</code>, the Swiss Army knife</h2>
<pre><code>In most cases, users will use the default settings to create a dfm straight from a corpus.  `dfm` will combine steps 3--4, even though basic functions will be available to perform these separately.  All options shown in steps 3--4 will be available in `dfm`.

`dfm` objects can always be built up using constituent steps, through tokenizing and then selecting on the tokens.  **quanteda** works well with `%&gt;%` pipes, if that is your thing:


```r
mydfm &lt;- texts(mycorpus, group = "party") %&gt;% toLower %&gt;% tokenize %&gt;% wordstem %&gt;%
                                removeFeatures(stopwords("english")) %&gt;% dfm
```

We recognize however that not all sequences will make sense, for instance `wordstem` will only work *after* tokenization, and will try to catch these errors and make the proper sequence clear to users.</code></pre>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked"><li><a href="#introduction">Introduction</a><ul class="nav nav-pills nav-stacked"><li><a href="#changes-in-v0.9.9">Changes in v0.9.9</a></li>
      <li><a href="#why-did-the-api-need-changing">Why did the API need changing?</a></li>
      </ul></li>
      <li><a href="#the-new-logic-of-quantedas-design">The new logic of <strong>quanteda</strong>&rsquo;s design</a><ul class="nav nav-pills nav-stacked"><li><a href="#grammatical-rules">Grammatical rules</a></li>
      <li><a href="#constructors-for-core-data-types">Constructors for core data types</a></li>
      <li><a href="#functions-for-manipulating-core-data-types">Functions for manipulating core data types</a></li>
      <li><a href="#extensions-of-core-r-functions">Extensions of core R functions</a></li>
      <li><a href="#additions-to-core-r-like-functions">Additions to core R(-like) functions</a></li>
      </ul></li>
      <li><a href="#workflow-principles">Workflow principles</a></li>
      <li><a href="#basic-text-analysis-workflow">Basic text analysis workflow</a><ul class="nav nav-pills nav-stacked"><li><a href="#working-with-a-corpus-documents-and-features">Working with a corpus, documents, and features</a></li>
      <li><a href="#dfm-the-swiss-army-knife"><code>dfm</code>, the Swiss Army knife</a></li>
      </ul></li>
      </ul></div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Kenneth Benoit.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer></div>

  </body></html>
