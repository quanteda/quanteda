<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Getting Started with quanteda &bull; quanteda</title><!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">quanteda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="http://github.com/kbenoit/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Getting Started with quanteda</h1>
            
          </div>

    
    
<div class="contents">
<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Quickstart}
-->
<div id="introduction" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#introduction" class="anchor"> </a></body></html>Introduction</h1>
<p>An R package for managing and analyzing text.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p><strong>quanteda</strong> makes it easy to manage texts in the form of a corpus, defined as a collection of texts that includes document-level variables specific to each text, as well as meta-data for documents and for the collection as a whole. <strong>quanteda</strong> includes tools to make it easy and fast to manuipulate the texts in a corpus, by performing the most common natural language processing tasks simply and quickly, such as tokenizing, stemming, or forming ngrams. <strong>quanteda</strong>&rsquo;s functions for tokenizing texts and forming multiple tokenized documents into a <em>document-feature matrix</em> are both extremely fast and extremely simple to use. <strong>quanteda</strong> can segment texts easily by words, paragraphs, sentences, or even user-supplied delimiters and tags.</p>
<p>Built on the text processing functions in the <strong>stringi</strong> package, which is in turn built on C++ implementation of the <a href="http://www.icu-project.org/">ICU</a> libraries for Unicode text handling, <strong>quanteda</strong> pays special attention to fast and correct implementation of Unicode and the handling of text in any character set, following conversion internally to UTF-8.</p>
<p><strong>quanteda</strong> is built for efficiency and speed, through its design around three infrastructures: the <strong>string</strong> package for text processing, the <strong>data.table</strong> package for indexing large documents efficiently, and the <strong>Matrix</strong> package for sparse matrix objects. If you can fit it into memory, <strong>quanteda</strong> will handle it quickly. (And eventually, we will make it possible to process objects even larger than available memory.)</p>
<p><strong>quanteda</strong> is principally designed to allow users a fast and convenient method to go from a corpus of texts to a selected matrix of documents by features, after defining what the documents and features. The package makes it easy to redefine documents, for instance by splitting them into sentences or paragraphs, or by tags, as well as to group them into larger documents by document variables, or to subset them based on logical conditions or combinations of document variables. The package also implements common NLP feature selection functions, such as removing stopwords and stemming in numerous languages, selecting words found in dictionaries, treating words as equivalent based on a user-defined &ldquo;thesaurus&rdquo;, and trimming and weighting features based on document frequency, feature frequency, and related measures such as <em>tf-idf</em>.</p>
</div>
<div id="quanteda-features" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#quanteda-features" class="anchor"> </a></body></html>quanteda Features</h1>
<div id="corpus-management-tools" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#corpus-management-tools" class="anchor"> </a></body></html>Corpus management tools</h2>
<p>The tools for getting texts into a corpus object include:</p>
<ul><li>loading texts from directories of individual files</li>
<li>loading texts ``manually&rsquo;&rsquo; by inserting them into a corpus using helper functions</li>
<li>managing text encodings and conversions from source files into corpus texts</li>
<li>attaching variables to each text that can be used for grouping, reorganizing a corpus, or simply recording additional information to supplement quantitative analyses with non-textual data</li>
<li>recording meta-data about the sources and creation details for the corpus.</li>
</ul><p>The tools for working with a corpus include:</p>
<ul><li>summarizing the corpus in terms of its language units</li>
<li>reshaping the corpus into smaller units or more aggregated units</li>
<li>adding to or extracting subsets of a corpus</li>
<li>resampling texts of the corpus, for example for use in non-parametric bootstrapping of the texts</li>
<li>Easy extraction and saving, as a new data frame or corpus, key words in context (KWIC)</li>
</ul></div>
<div id="natural-language-processing-tools" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#natural-language-processing-tools" class="anchor"> </a></body></html>Natural-Language Processing tools</h2>
<p>For extracting features from a corpus, <code>quanteda</code> provides the following tools:</p>
<ul><li>extraction of word types</li>
<li>extraction of word n-grams</li>
<li>extraction of dictionary entries from user-defined dictionaries</li>
<li>feature selection through
<ul><li>stemming</li>
<li>random selection</li>
<li>document frequency</li>
<li>word frequency</li>
</ul></li>
<li>and a variety of options for cleaning word types, such as capitalization and rules for handling punctuation.</li>
</ul></div>
<div id="document-feature-matrix-analysis-tools" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#document-feature-matrix-analysis-tools" class="anchor"> </a></body></html>Document-Feature Matrix analysis tools</h2>
<p>For analyzing the resulting <em>document-feature</em> matrix created when features are abstracted from a corpus, <code>quanteda</code> provides:</p>
<ul><li>scaling methods, such as correspondence analysis, Wordfish, and Wordscores</li>
<li>topic models, such as LDA</li>
<li>classifiers, such as Naive Bayes or k-nearest neighbour</li>
<li>sentiment analysis, using dictionaries</li>
</ul></div>
<div id="additional-and-planned-features" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#additional-and-planned-features" class="anchor"> </a></body></html>Additional and planned features</h2>
<p><strong>Additional features</strong> of quanteda include:</p>
<ul><li><p>the ability to explore texts using <em>key-words-in-context</em>;</p></li>
<li><p>fast computation of a variety of readability indexes;</p></li>
<li><p>fast computation of a variety of lexical diversity measures;</p></li>
<li><p>quick computation of word or document association measures, for clustering or to compute similarity scores for other purposes; and</p></li>
<li><p>a comprehensive suite of descriptive statistics on text such as the number of sentences, words, characters, or syllables per document.</p></li>
</ul><p><strong>Planned features</strong> coming soon to <strong>quanteda</strong> are:</p>
<ul><li><p>bootstrapping methods for texts that makes it easy to resample texts from pre-defined units, to facilitate computation of confidence intervals on textual statistics using techniques of non-parametric bootstrapping, but applied to the original texts as data.</p></li>
<li><p>expansion of the document-feature matrix structure through a standard interface called <code><a href="../reference/textmodel.html">textmodel()</a></code>. (As of version 0.8.0, textmodel works in a basic fashion only for the &ldquo;Wordscores&rdquo; and &ldquo;wordfish&rdquo; scaling models.)</p></li>
</ul></div>
<div id="working-with-other-text-analysis-packages" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#working-with-other-text-analysis-packages" class="anchor"> </a></body></html>Working with other text analysis packages</h2>
<p><code>quanteda</code> is hardly unique in providing facilities for working with text &ndash; the excellent <em>tm</em> package already provides many of the features we have described. <code>quanteda</code> is designed to complement those packages, as well to simplify the implementation of the text-to-analysis workflow. <code>quanteda</code> corpus structures are simpler objects than in <em>tm</em>s, as are the document-feature matrix objects from <code>quanteda</code>, compared to the sparse matrix implementation found in <em>tm</em>. However, there is no need to choose only one package, since we provide translator functions from one matrix or corpus object to the other in <code>quanteda</code>.</p>
<p>Once constructed, a <strong>quanteda</strong> &ldquo;dfm&rdquo;" can be easily passed to other text-analysis packages for additional analysis of topic models or scaling, such as:</p>
<ul><li><p>topic models (including converters for direct use with the <strong>topicmodels</strong>, <strong>LDA</strong>, and <strong>stm</strong> packages)</p></li>
<li><p>document scaling (using <strong>quanteda</strong>&rsquo;s own functions for the &ldquo;wordfish&rdquo; and &ldquo;Wordscores&rdquo; models, direct use with the <strong>ca</strong> package for correspondence analysis, or scaling with the <strong>austin</strong> package)</p></li>
<li><p>document classification methods, using (for example) Naive Bayes, k-nearest neighbour, or Support Vector Machines</p></li>
<li><p>more sophisticated machine learning through a variety of other packages that take matrix or matrix-like inputs.</p></li>
<li><p>graphical analysis, including word clouds and strip plots for selected themes or words.</p></li>
</ul></div>
</div>
<div id="how-to-install" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#how-to-install" class="anchor"> </a></body></html>How to Install</h1>
<p>Through a normal installation of the package from CRAN, or for the GitHub version, see the installation instructions at <a href="https://github.com/kbenoit/quanteda" class="uri">https://github.com/kbenoit/quanteda</a>.</p>
</div>
<div id="creating-and-working-with-a-corpus" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#creating-and-working-with-a-corpus" class="anchor"> </a></body></html>Creating and Working with a Corpus</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(quanteda)</code></pre></div>
<div id="currently-available-corpus-sources" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#currently-available-corpus-sources" class="anchor"> </a></body></html>Currently available corpus sources</h2>
<p><strong>quanteda</strong> has a simple and powerful companion package for loading texts: <a href="https://github.com/kbenoit/readtext"><strong>readtext</strong></a>. The main function in this package, <code>readtext()</code>, takes a file or fileset from disk or a URL, and returns a type of data.frame that can be used directly with the <code><a href="../reference/corpus.html">corpus()</a></code> constructor function, to create a <strong>quanteda</strong> corpus object.</p>
<p><code>readtext()</code> works on:</p>
<ul><li>text (<code>.txt</code>) files;</li>
<li>comma-separated-value (<code>.csv</code>) files;</li>
<li>XML formatted data;</li>
<li>data from the Facebook API, in JSON format;</li>
<li>data from the Twitter API, in JSON format; and</li>
<li>generic JSON data.</li>
</ul><p>The corpus constructor command <code><a href="../reference/corpus.html">corpus()</a></code> works directly on:</p>
<ul><li>a vector of character objects, for instance that you have already loaded into the workspace using other tools;</li>
<li>a <code>VCorpus</code> corpus object from the <strong>tm</strong> package.</li>
<li>a data.frame containing a text column and any other document-level metadata.</li>
</ul><div id="example-building-a-corpus-from-a-character-vector" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#example-building-a-corpus-from-a-character-vector" class="anchor"> </a></body></html>Example: building a corpus from a character vector</h3>
<p>The simplest case is to create a corpus from a vector of texts already in memory in R. This gives the advanced R user complete flexbility with his or her choice of text inputs, as there are almost endless ways to get a vector of texts into R.</p>
<p>If we already have the texts in this form, we can call the corpus constructor function directly. We can demonstrate this on the built-in character vector of 57 US president inaugural speeches called <code>data_char_inaugural</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(data_char_inaugural)  <span class="co"># this gives us some information about the object</span>
<span class="co">#&gt;  Named chr [1:57] "Fellow-Citizens of the Senate and of the House of Representatives:\n\nAmong the vicissitudes incident to life no event could ha"| __truncated__ ...</span>
<span class="co">#&gt;  - attr(*, "names")= chr [1:57] "1789-Washington" "1793-Washington" "1797-Adams" "1801-Jefferson" ...</span>
myCorpus &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus.html">corpus</a></span>(data_char_inaugural)  <span class="co"># build the corpus</span>
<span class="kw">summary</span>(myCorpus, <span class="dt">n =</span> <span class="dv">5</span>)
<span class="co">#&gt; Corpus consisting of 57 documents, showing 5 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             Text Types Tokens Sentences</span>
<span class="co">#&gt;  1789-Washington   626   1540        23</span>
<span class="co">#&gt;  1793-Washington    96    147         4</span>
<span class="co">#&gt;       1797-Adams   826   2584        37</span>
<span class="co">#&gt;   1801-Jefferson   716   1935        41</span>
<span class="co">#&gt;   1805-Jefferson   804   2381        45</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /Users/akitaka/Dropbox/KB_Projects/r_package_development/quanteda/docs/articles/* on x86_64 by akitaka</span>
<span class="co">#&gt; Created: Fri Dec  2 17:00:47 2016</span>
<span class="co">#&gt; Notes:</span></code></pre></div>
<p>If we wanted, we could add some document-level variables &ndash; what quanteda calls <code>docvars</code> &ndash; to this corpus.</p>
<p>We can do this using the R&rsquo;s <code>substring()</code> function to extract characters from a name &ndash; in this case, the name of the character vector <code>data_char_inaugural</code>. This works using our fixed starting and ending positions with <code>substring()</code> because these names are a very regular format of <code>YYYY-PresidentName</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/docvars.html">docvars</a></span>(myCorpus, <span class="st">"President"</span>) &lt;-<span class="st"> </span><span class="kw">substring</span>(<span class="kw">names</span>(data_char_inaugural), <span class="dv">6</span>)
<span class="kw"><a href="../reference/docvars.html">docvars</a></span>(myCorpus, <span class="st">"Year"</span>) &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">substring</span>(<span class="kw">names</span>(data_char_inaugural), <span class="dv">1</span>, <span class="dv">4</span>))
<span class="kw">summary</span>(myCorpus, <span class="dt">n=</span><span class="dv">5</span>)
<span class="co">#&gt; Corpus consisting of 57 documents, showing 5 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             Text Types Tokens Sentences  President Year</span>
<span class="co">#&gt;  1789-Washington   626   1540        23 Washington 1789</span>
<span class="co">#&gt;  1793-Washington    96    147         4 Washington 1793</span>
<span class="co">#&gt;       1797-Adams   826   2584        37      Adams 1797</span>
<span class="co">#&gt;   1801-Jefferson   716   1935        41  Jefferson 1801</span>
<span class="co">#&gt;   1805-Jefferson   804   2381        45  Jefferson 1805</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /Users/akitaka/Dropbox/KB_Projects/r_package_development/quanteda/docs/articles/* on x86_64 by akitaka</span>
<span class="co">#&gt; Created: Fri Dec  2 17:00:47 2016</span>
<span class="co">#&gt; Notes:</span></code></pre></div>
<p>If we wanted to tag each document with additional meta-data not considered a document variable of interest for analysis, but rather something that we need to know as an attribute of the document, we could also add those to our corpus.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/metadoc.html">metadoc</a></span>(myCorpus, <span class="st">"language"</span>) &lt;-<span class="st"> "english"</span>
<span class="kw"><a href="../reference/metadoc.html">metadoc</a></span>(myCorpus, <span class="st">"docsource"</span>)  &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">"data_char_inaugural"</span>, <span class="dv">1</span>:<span class="kw"><a href="../reference/ndoc.html">ndoc</a></span>(myCorpus), <span class="dt">sep =</span> <span class="st">"_"</span>)
<span class="kw">summary</span>(myCorpus, <span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">showmeta =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Corpus consisting of 57 documents, showing 5 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             Text Types Tokens Sentences  President Year _language</span>
<span class="co">#&gt;  1789-Washington   626   1540        23 Washington 1789   english</span>
<span class="co">#&gt;  1793-Washington    96    147         4 Washington 1793   english</span>
<span class="co">#&gt;       1797-Adams   826   2584        37      Adams 1797   english</span>
<span class="co">#&gt;   1801-Jefferson   716   1935        41  Jefferson 1801   english</span>
<span class="co">#&gt;   1805-Jefferson   804   2381        45  Jefferson 1805   english</span>
<span class="co">#&gt;             _docsource</span>
<span class="co">#&gt;  data_char_inaugural_1</span>
<span class="co">#&gt;  data_char_inaugural_2</span>
<span class="co">#&gt;  data_char_inaugural_3</span>
<span class="co">#&gt;  data_char_inaugural_4</span>
<span class="co">#&gt;  data_char_inaugural_5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /Users/akitaka/Dropbox/KB_Projects/r_package_development/quanteda/docs/articles/* on x86_64 by akitaka</span>
<span class="co">#&gt; Created: Fri Dec  2 17:00:47 2016</span>
<span class="co">#&gt; Notes:</span></code></pre></div>
<p>The last command, <code>metadoc</code>, allows you to define your own document meta-data fields. Note that in assiging just the single value of <code>"english"</code>, R has recycled the value until it matches the number of documents in the corpus. In creating a simple tag for our custom metadoc field <code>docsource</code>, we used the quanteda function <code><a href="../reference/ndoc.html">ndoc()</a></code> to retrieve the number of documents in our corpus. This function is deliberately designed to work in a way similar to functions you may already use in R, such as <code>nrow()</code> and <code>ncol()</code>.</p>
</div>
<div id="example-loading-in-files-using-the-readtext-package" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#example-loading-in-files-using-the-readtext-package" class="anchor"> </a></body></html>Example: loading in files using the <strong>readtext</strong> package</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(readtext)

<span class="co"># Twitter json</span>
mytf1 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"~/Dropbox/QUANTESS/social media/zombies/tweets.json"</span>)
myCorpusTwitter &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf1)
<span class="kw">summary</span>(myCorpusTwitter, <span class="dv">5</span>)
<span class="co"># generic json - needs a textField specifier</span>
mytf2 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"~/Dropbox/QUANTESS/Manuscripts/collocations/Corpora/sotu/sotu.json"</span>,
                  <span class="dt">textField =</span> <span class="st">"text"</span>)
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf2), <span class="dv">5</span>)
<span class="co"># text file</span>
mytf3 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"~/Dropbox/QUANTESS/corpora/project_gutenberg/pg2701.txt"</span>, <span class="dt">cache =</span> <span class="ot">FALSE</span>)
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf3), <span class="dv">5</span>)
<span class="co"># multiple text files</span>
mytf4 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"~/Dropbox/QUANTESS/corpora/inaugural/*.txt"</span>, <span class="dt">cache =</span> <span class="ot">FALSE</span>)
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf4), <span class="dv">5</span>)
<span class="co"># multiple text files with docvars from filenames</span>
mytf5 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"~/Dropbox/QUANTESS/corpora/inaugural/*.txt"</span>, 
                  <span class="dt">docvarsfrom=</span><span class="st">"filenames"</span>, <span class="dt">sep=</span><span class="st">"-"</span>, <span class="dt">docvarnames=</span><span class="kw">c</span>(<span class="st">"Year"</span>, <span class="st">"President"</span>))
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf5), <span class="dv">5</span>)
<span class="co"># XML data</span>
mytf6 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"~/Dropbox/QUANTESS/quanteda_working_files/xmlData/plant_catalog.xml"</span>, 
                  <span class="dt">textField =</span> <span class="st">"COMMON"</span>)
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf6), <span class="dv">5</span>)
<span class="co"># csv file</span>
<span class="kw">write.csv</span>(<span class="kw">data.frame</span>(<span class="dt">inaugSpeech =</span> <span class="kw"><a href="../reference/texts.html">texts</a></span>(data_corpus_inaugural), <span class="kw"><a href="../reference/docvars.html">docvars</a></span>(data_corpus_inaugural)), 
          <span class="dt">file =</span> <span class="st">"/tmp/inaug_texts.csv"</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)
mytf7 &lt;-<span class="st"> </span><span class="kw">readtext</span>(<span class="st">"/tmp/inaug_texts.csv"</span>, <span class="dt">textField =</span> <span class="st">"inaugSpeech"</span>)
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus.html">corpus</a></span>(mytf7), <span class="dv">5</span>)</code></pre></div>
</div>
</div>
<div id="how-a-quanteda-corpus-works" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#how-a-quanteda-corpus-works" class="anchor"> </a></body></html>How a quanteda corpus works</h2>
<div id="corpus-principles" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#corpus-principles" class="anchor"> </a></body></html>Corpus principles</h3>
<p>A corpus is designed to be a &ldquo;library&rdquo; of original documents that have been converted to plain, UTF-8 encoded text, and stored along with meta-data at the corpus level and at the document-level. We have a special name for document-level meta-data: <em>docvars</em>. These are variables or features that describe attributes of each document.</p>
<p>A corpus is designed to be a more or less static container of texts with respect to processing and analysis. This means that the texts in corpus are not designed to be changed internally through (for example) cleaning or pre-processing steps, such as stemming or removing punctuation. Rather, texts can be extracted from the corpus as part of processing, and assigned to new objects, but the idea is that the corpus will remain as an original reference copy so that other analyses &ndash; for instance those in which stems and punctuation were required, such as analyzing a reading ease index &ndash; can be performed on the same corpus.</p>
<p>To extract texts from a a corpus, we use an extractor, called <code><a href="../reference/texts.html">texts()</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/texts.html">texts</a></span>(data_corpus_inaugural)[<span class="dv">2</span>]
<span class="co">#&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1793-Washington </span>
<span class="co">#&gt; "Fellow citizens, I am again called upon by the voice of my country to execute the functions of its Chief Magistrate. When the occasion proper for it shall arrive, I shall endeavor to express the high sense I entertain of this distinguished honor, and of the confidence which has been reposed in me by the people of united America.\n\nPrevious to the execution of any official act of the President the Constitution requires an oath of office. This oath I am now about to take, and in your presence: That if it shall be found during my administration of the Government I have in any instance violated willingly or knowingly the injunctions thereof, I may (besides incurring constitutional punishment) be subject to the upbraidings of all who are now witnesses of the present solemn ceremony.\n\n "</span></code></pre></div>
<p>To summarize the texts from a corpus, we can call a <code>summary()</code> method defined for a corpus.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(data_corpus_irishbudget2010)
<span class="co">#&gt; Corpus consisting of 14 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                                   Text Types Tokens Sentences year debate</span>
<span class="co">#&gt;        2010_BUDGET_01_Brian_Lenihan_FF  1949   8733       374 2010 BUDGET</span>
<span class="co">#&gt;       2010_BUDGET_02_Richard_Bruton_FG  1042   4478       217 2010 BUDGET</span>
<span class="co">#&gt;         2010_BUDGET_03_Joan_Burton_LAB  1621   6429       307 2010 BUDGET</span>
<span class="co">#&gt;        2010_BUDGET_04_Arthur_Morgan_SF  1589   7185       343 2010 BUDGET</span>
<span class="co">#&gt;          2010_BUDGET_05_Brian_Cowen_FF  1618   6697       250 2010 BUDGET</span>
<span class="co">#&gt;           2010_BUDGET_06_Enda_Kenny_FG  1151   4254       153 2010 BUDGET</span>
<span class="co">#&gt;      2010_BUDGET_07_Kieran_ODonnell_FG   681   2309       133 2010 BUDGET</span>
<span class="co">#&gt;       2010_BUDGET_08_Eamon_Gilmore_LAB  1183   4217       201 2010 BUDGET</span>
<span class="co">#&gt;     2010_BUDGET_09_Michael_Higgins_LAB   490   1288        44 2010 BUDGET</span>
<span class="co">#&gt;        2010_BUDGET_10_Ruairi_Quinn_LAB   442   1290        59 2010 BUDGET</span>
<span class="co">#&gt;      2010_BUDGET_11_John_Gormley_Green   404   1036        49 2010 BUDGET</span>
<span class="co">#&gt;        2010_BUDGET_12_Eamon_Ryan_Green   512   1651        90 2010 BUDGET</span>
<span class="co">#&gt;      2010_BUDGET_13_Ciaran_Cuffe_Green   444   1248        45 2010 BUDGET</span>
<span class="co">#&gt;  2010_BUDGET_14_Caoimhghin_OCaolain_SF  1188   4094       176 2010 BUDGET</span>
<span class="co">#&gt;  number      foren     name party</span>
<span class="co">#&gt;      01      Brian  Lenihan    FF</span>
<span class="co">#&gt;      02    Richard   Bruton    FG</span>
<span class="co">#&gt;      03       Joan   Burton   LAB</span>
<span class="co">#&gt;      04     Arthur   Morgan    SF</span>
<span class="co">#&gt;      05      Brian    Cowen    FF</span>
<span class="co">#&gt;      06       Enda    Kenny    FG</span>
<span class="co">#&gt;      07     Kieran ODonnell    FG</span>
<span class="co">#&gt;      08      Eamon  Gilmore   LAB</span>
<span class="co">#&gt;      09    Michael  Higgins   LAB</span>
<span class="co">#&gt;      10     Ruairi    Quinn   LAB</span>
<span class="co">#&gt;      11       John  Gormley Green</span>
<span class="co">#&gt;      12      Eamon     Ryan Green</span>
<span class="co">#&gt;      13     Ciaran    Cuffe Green</span>
<span class="co">#&gt;      14 Caoimhghin OCaolain    SF</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /home/paul/Dropbox/code/quantedaData/* on x86_64 by paul</span>
<span class="co">#&gt; Created: Tue Sep 16 15:58:21 2014</span>
<span class="co">#&gt; Notes:</span></code></pre></div>
<p>We can save the output from the summary command as a data frame, and plot some basic descriptive statistics with this information:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tokenInfo &lt;-<span class="st"> </span><span class="kw">summary</span>(data_corpus_inaugural)
<span class="co">#&gt; Corpus consisting of 57 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             Text Types Tokens Sentences Year  President       FirstName</span>
<span class="co">#&gt;  1789-Washington   626   1540        23 1789 Washington          George</span>
<span class="co">#&gt;  1793-Washington    96    147         4 1793 Washington          George</span>
<span class="co">#&gt;       1797-Adams   826   2584        37 1797      Adams            John</span>
<span class="co">#&gt;   1801-Jefferson   716   1935        41 1801  Jefferson          Thomas</span>
<span class="co">#&gt;   1805-Jefferson   804   2381        45 1805  Jefferson          Thomas</span>
<span class="co">#&gt;     1809-Madison   536   1267        21 1809    Madison           James</span>
<span class="co">#&gt;     1813-Madison   542   1304        33 1813    Madison           James</span>
<span class="co">#&gt;      1817-Monroe  1040   3696       121 1817     Monroe           James</span>
<span class="co">#&gt;      1821-Monroe  1262   4898       129 1821     Monroe           James</span>
<span class="co">#&gt;       1825-Adams  1004   3154        74 1825      Adams     John Quincy</span>
<span class="co">#&gt;     1829-Jackson   517   1210        25 1829    Jackson          Andrew</span>
<span class="co">#&gt;     1833-Jackson   499   1271        29 1833    Jackson          Andrew</span>
<span class="co">#&gt;    1837-VanBuren  1315   4175        95 1837  Van Buren          Martin</span>
<span class="co">#&gt;    1841-Harrison  1893   9178       210 1841   Harrison   William Henry</span>
<span class="co">#&gt;        1845-Polk  1330   5211       153 1845       Polk      James Knox</span>
<span class="co">#&gt;      1849-Taylor   497   1185        22 1849     Taylor         Zachary</span>
<span class="co">#&gt;      1853-Pierce  1166   3657       104 1853     Pierce        Franklin</span>
<span class="co">#&gt;    1857-Buchanan   945   3106        89 1857   Buchanan           James</span>
<span class="co">#&gt;     1861-Lincoln  1075   4016       135 1861    Lincoln         Abraham</span>
<span class="co">#&gt;     1865-Lincoln   362    780        26 1865    Lincoln         Abraham</span>
<span class="co">#&gt;       1869-Grant   486   1243        40 1869      Grant      Ulysses S.</span>
<span class="co">#&gt;       1873-Grant   552   1479        43 1873      Grant      Ulysses S.</span>
<span class="co">#&gt;       1877-Hayes   829   2730        59 1877      Hayes   Rutherford B.</span>
<span class="co">#&gt;    1881-Garfield  1018   3240       111 1881   Garfield        James A.</span>
<span class="co">#&gt;   1885-Cleveland   674   1828        44 1885  Cleveland          Grover</span>
<span class="co">#&gt;    1889-Harrison  1355   4744       157 1889   Harrison        Benjamin</span>
<span class="co">#&gt;   1893-Cleveland   823   2135        58 1893  Cleveland          Grover</span>
<span class="co">#&gt;    1897-McKinley  1236   4383       130 1897   McKinley         William</span>
<span class="co">#&gt;    1901-McKinley   857   2449       100 1901   McKinley         William</span>
<span class="co">#&gt;   1905-Roosevelt   404   1089        33 1905  Roosevelt        Theodore</span>
<span class="co">#&gt;        1909-Taft  1436   5844       159 1909       Taft  William Howard</span>
<span class="co">#&gt;      1913-Wilson   661   1896        68 1913     Wilson         Woodrow</span>
<span class="co">#&gt;      1917-Wilson   549   1656        59 1917     Wilson         Woodrow</span>
<span class="co">#&gt;     1921-Harding  1172   3743       148 1921    Harding       Warren G.</span>
<span class="co">#&gt;    1925-Coolidge  1221   4442       196 1925   Coolidge          Calvin</span>
<span class="co">#&gt;      1929-Hoover  1086   3895       158 1929     Hoover         Herbert</span>
<span class="co">#&gt;   1933-Roosevelt   744   2064        85 1933  Roosevelt     Franklin D.</span>
<span class="co">#&gt;   1937-Roosevelt   729   2027        96 1937  Roosevelt     Franklin D.</span>
<span class="co">#&gt;   1941-Roosevelt   527   1552        68 1941  Roosevelt     Franklin D.</span>
<span class="co">#&gt;   1945-Roosevelt   276    651        26 1945  Roosevelt     Franklin D.</span>
<span class="co">#&gt;      1949-Truman   781   2531       116 1949     Truman        Harry S.</span>
<span class="co">#&gt;  1953-Eisenhower   903   2765       119 1953 Eisenhower       Dwight D.</span>
<span class="co">#&gt;  1957-Eisenhower   621   1933        92 1957 Eisenhower       Dwight D.</span>
<span class="co">#&gt;     1961-Kennedy   566   1568        52 1961    Kennedy         John F.</span>
<span class="co">#&gt;     1965-Johnson   569   1725        93 1965    Johnson   Lyndon Baines</span>
<span class="co">#&gt;       1969-Nixon   743   2437       103 1969      Nixon Richard Milhous</span>
<span class="co">#&gt;       1973-Nixon   545   2018        68 1973      Nixon Richard Milhous</span>
<span class="co">#&gt;      1977-Carter   528   1380        52 1977     Carter           Jimmy</span>
<span class="co">#&gt;      1981-Reagan   904   2798       128 1981     Reagan          Ronald</span>
<span class="co">#&gt;      1985-Reagan   925   2935       123 1985     Reagan          Ronald</span>
<span class="co">#&gt;        1989-Bush   795   2683       141 1989       Bush          George</span>
<span class="co">#&gt;     1993-Clinton   644   1837        81 1993    Clinton            Bill</span>
<span class="co">#&gt;     1997-Clinton   773   2451       111 1997    Clinton            Bill</span>
<span class="co">#&gt;        2001-Bush   622   1810        97 2001       Bush       George W.</span>
<span class="co">#&gt;        2005-Bush   772   2325       100 2005       Bush       George W.</span>
<span class="co">#&gt;       2009-Obama   939   2729       110 2009      Obama          Barack</span>
<span class="co">#&gt;       2013-Obama   814   2335        88 2013      Obama          Barack</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /home/paul/Dropbox/code/quanteda/* on x86_64 by paul</span>
<span class="co">#&gt; Created: Fri Sep 12 12:41:17 2014</span>
<span class="co">#&gt; Notes:</span>
if (<span class="kw">require</span>(ggplot2))
    <span class="kw">ggplot</span>(<span class="dt">data=</span>tokenInfo, <span class="kw">aes</span>(<span class="dt">x=</span>Year, <span class="dt">y=</span>Tokens, <span class="dt">group=</span><span class="dv">1</span>)) +<span class="st"> </span><span class="kw">geom_line</span>() +<span class="st"> </span><span class="kw">geom_point</span>() +
<span class="st">        </span><span class="kw">scale_x_discrete</span>(<span class="dt">labels=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">1789</span>,<span class="dv">2012</span>,<span class="dv">12</span>)), <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">1789</span>,<span class="dv">2012</span>,<span class="dv">12</span>) ) </code></pre></div>
<p><img src="quickstart_files/figure-html/unnamed-chunk-9-1.png" width="768"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="co"># Longest inaugural address: William Henry Harrison</span>
tokenInfo[<span class="kw">which.max</span>(tokenInfo$Tokens),] 
<span class="co">#&gt;                        Text Types Tokens Sentences Year President</span>
<span class="co">#&gt; 1841-Harrison 1841-Harrison  1893   9178       210 1841  Harrison</span>
<span class="co">#&gt;                   FirstName</span>
<span class="co">#&gt; 1841-Harrison William Henry</span></code></pre></div>
</div>
</div>
<div id="tools-for-handling-corpus-objects" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#tools-for-handling-corpus-objects" class="anchor"> </a></body></html>Tools for handling corpus objects</h2>
<div id="adding-two-corpus-objects-together" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#adding-two-corpus-objects-together" class="anchor"> </a></body></html>Adding two corpus objects together</h3>
<p>The <code>+</code> operator provides a simple method for concatenating two corpus objects. If they contain different sets of document-level variables, these will be stitched together in a fashion that guarantees that no information is lost. Corpus-level medata data is also concatenated.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(quanteda)
mycorpus1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus.html">corpus</a></span>(data_char_inaugural[<span class="dv">1</span>:<span class="dv">5</span>], <span class="dt">note =</span> <span class="st">"First five inaug speeches."</span>)
mycorpus2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus.html">corpus</a></span>(data_char_inaugural[<span class="dv">53</span>:<span class="dv">57</span>], <span class="dt">note =</span> <span class="st">"Last five inaug speeches."</span>)
mycorpus3 &lt;-<span class="st"> </span>mycorpus1 +<span class="st"> </span>mycorpus2
<span class="kw">summary</span>(mycorpus3)
<span class="co">#&gt; Corpus consisting of 10 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;             Text Types Tokens Sentences</span>
<span class="co">#&gt;  1789-Washington   626   1540        23</span>
<span class="co">#&gt;  1793-Washington    96    147         4</span>
<span class="co">#&gt;       1797-Adams   826   2584        37</span>
<span class="co">#&gt;   1801-Jefferson   716   1935        41</span>
<span class="co">#&gt;   1805-Jefferson   804   2381        45</span>
<span class="co">#&gt;     1997-Clinton   773   2451       111</span>
<span class="co">#&gt;        2001-Bush   622   1810        97</span>
<span class="co">#&gt;        2005-Bush   772   2325       100</span>
<span class="co">#&gt;       2009-Obama   939   2729       110</span>
<span class="co">#&gt;       2013-Obama   814   2335        88</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  Combination of corpuses mycorpus1 and mycorpus2</span>
<span class="co">#&gt; Created: Fri Dec  2 17:00:48 2016</span>
<span class="co">#&gt; Notes:   First five inaug speeches. Last five inaug speeches.</span></code></pre></div>
</div>
<div id="subsetting-corpus-objects" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#subsetting-corpus-objects" class="anchor"> </a></body></html>subsetting corpus objects</h3>
<p>There is a method of the <code><a href="../reference/corpus_subset.html">corpus_subset()</a></code> function defined for corpus objects, where a new corpus can be extracted based on logical conditions applied to docvars:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus_subset.html">corpus_subset</a></span>(data_corpus_inaugural, Year &gt;<span class="st"> </span><span class="dv">1990</span>))
<span class="co">#&gt; Corpus consisting of 6 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;          Text Types Tokens Sentences Year President FirstName</span>
<span class="co">#&gt;  1993-Clinton   644   1837        81 1993   Clinton      Bill</span>
<span class="co">#&gt;  1997-Clinton   773   2451       111 1997   Clinton      Bill</span>
<span class="co">#&gt;     2001-Bush   622   1810        97 2001      Bush George W.</span>
<span class="co">#&gt;     2005-Bush   772   2325       100 2005      Bush George W.</span>
<span class="co">#&gt;    2009-Obama   939   2729       110 2009     Obama    Barack</span>
<span class="co">#&gt;    2013-Obama   814   2335        88 2013     Obama    Barack</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /home/paul/Dropbox/code/quanteda/* on x86_64 by paul</span>
<span class="co">#&gt; Created: Fri Sep 12 12:41:17 2014</span>
<span class="co">#&gt; Notes:</span>
<span class="kw">summary</span>(<span class="kw"><a href="../reference/corpus_subset.html">corpus_subset</a></span>(data_corpus_inaugural, President ==<span class="st"> "Adams"</span>))
<span class="co">#&gt; Corpus consisting of 2 documents.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;        Text Types Tokens Sentences Year President   FirstName</span>
<span class="co">#&gt;  1797-Adams   826   2584        37 1797     Adams        John</span>
<span class="co">#&gt;  1825-Adams  1004   3154        74 1825     Adams John Quincy</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Source:  /home/paul/Dropbox/code/quanteda/* on x86_64 by paul</span>
<span class="co">#&gt; Created: Fri Sep 12 12:41:17 2014</span>
<span class="co">#&gt; Notes:</span></code></pre></div>
</div>
</div>
<div id="exploring-corpus-texts" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#exploring-corpus-texts" class="anchor"> </a></body></html>Exploring corpus texts</h2>
<p>The <code>kwic</code> function (KeyWord In Context) performs a search for a word and allows us to view the contexts in which it occurs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">width =</span> <span class="dv">200</span>)
<span class="kw"><a href="../reference/kwic.html">kwic</a></span>(data_corpus_inaugural, <span class="st">"terror"</span>)
<span class="co">#&gt;                                                 contextPre keyword                         contextPost</span>
<span class="co">#&gt;    [1797-Adams, 1327]              fraud or violence, by [  terror ] , intrigue, or venality          </span>
<span class="co">#&gt; [1933-Roosevelt, 112] nameless, unreasoning, unjustified [  terror ] which paralyzes needed efforts to</span>
<span class="co">#&gt; [1941-Roosevelt, 289]      seemed frozen by a fatalistic [  terror ] , we proved that this            </span>
<span class="co">#&gt;   [1961-Kennedy, 868]    alter that uncertain balance of [  terror ] that stays the hand of           </span>
<span class="co">#&gt;    [1981-Reagan, 821]     freeing all Americans from the [  terror ] of runaway living costs.         </span>
<span class="co">#&gt;  [1997-Clinton, 1055]        They fuel the fanaticism of [  terror ] . And they torment the           </span>
<span class="co">#&gt;  [1997-Clinton, 1655]  maintain a strong defense against [  terror ] and destruction. Our children    </span>
<span class="co">#&gt;    [2009-Obama, 1646]     advance their aims by inducing [  terror ] and slaughtering innocents, we</span>
<span class="kw"><a href="../reference/kwic.html">kwic</a></span>(data_corpus_inaugural, <span class="st">"terror"</span>, <span class="dt">valuetype =</span> <span class="st">"regex"</span>)
<span class="co">#&gt;                                                 contextPre   keyword                         contextPost</span>
<span class="co">#&gt;    [1797-Adams, 1327]              fraud or violence, by [  terror   ] , intrigue, or venality          </span>
<span class="co">#&gt; [1933-Roosevelt, 112] nameless, unreasoning, unjustified [  terror   ] which paralyzes needed efforts to</span>
<span class="co">#&gt; [1941-Roosevelt, 289]      seemed frozen by a fatalistic [  terror   ] , we proved that this            </span>
<span class="co">#&gt;   [1961-Kennedy, 868]    alter that uncertain balance of [  terror   ] that stays the hand of           </span>
<span class="co">#&gt;   [1961-Kennedy, 992]          of science instead of its [  terrors  ] . Together let us explore        </span>
<span class="co">#&gt;    [1981-Reagan, 821]     freeing all Americans from the [  terror   ] of runaway living costs.         </span>
<span class="co">#&gt;   [1981-Reagan, 2204]   understood by those who practice [ terrorism ] and prey upon their neighbors    </span>
<span class="co">#&gt;  [1997-Clinton, 1055]        They fuel the fanaticism of [  terror   ] . And they torment the           </span>
<span class="co">#&gt;  [1997-Clinton, 1655]  maintain a strong defense against [  terror   ] and destruction. Our children    </span>
<span class="co">#&gt;    [2009-Obama, 1646]     advance their aims by inducing [  terror   ] and slaughtering innocents, we</span>
<span class="kw"><a href="../reference/kwic.html">kwic</a></span>(data_corpus_inaugural, <span class="st">"communist*"</span>)
<span class="co">#&gt;                                           contextPre    keyword                  contextPost</span>
<span class="co">#&gt;  [1949-Truman, 838] the actions resulting from the [ Communist  ] philosophy are a threat to</span>
<span class="co">#&gt; [1961-Kennedy, 519]             -- not because the [ Communists ] may be doing it,</span></code></pre></div>
<p>In the above summary, <code>Year</code> and <code>President</code> are variables associated with each document. We can access such variables with the <code><a href="../reference/docvars.html">docvars()</a></code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># inspect the document-level variables</span>
<span class="kw">head</span>(<span class="kw"><a href="../reference/docvars.html">docvars</a></span>(data_corpus_inaugural))
<span class="co">#&gt;                 Year  President FirstName</span>
<span class="co">#&gt; 1789-Washington 1789 Washington    George</span>
<span class="co">#&gt; 1793-Washington 1793 Washington    George</span>
<span class="co">#&gt; 1797-Adams      1797      Adams      John</span>
<span class="co">#&gt; 1801-Jefferson  1801  Jefferson    Thomas</span>
<span class="co">#&gt; 1805-Jefferson  1805  Jefferson    Thomas</span>
<span class="co">#&gt; 1809-Madison    1809    Madison     James</span>

<span class="co"># inspect the corpus-level metadata</span>
<span class="kw"><a href="../reference/metacorpus.html">metacorpus</a></span>(data_corpus_inaugural)
<span class="co">#&gt; $source</span>
<span class="co">#&gt; [1] "/home/paul/Dropbox/code/quanteda/* on x86_64 by paul"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $created</span>
<span class="co">#&gt; [1] "Fri Sep 12 12:41:17 2014"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $notes</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $citation</span>
<span class="co">#&gt; NULL</span></code></pre></div>
<p>More corpora are available from the <a href="http://github.com/kbenoit/quantedaData">quantedaData</a> package.</p>
</div>
</div>
<div id="extracting-features-from-a-corpus" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#extracting-features-from-a-corpus" class="anchor"> </a></body></html>Extracting Features from a Corpus</h1>
<p>In order to perform statistical analysis such as document scaling, we must extract a matrix associating values for certain features with each document. In quanteda, we use the <code>dfm</code> function to produce such a matrix. &ldquo;dfm&rdquo; is short for <em>document-feature matrix</em>, and always refers to documents in rows and &ldquo;features&rdquo; as columns. We fix this dimensional orientation because is is standard in data analysis to have a unit of analysis as a row, and features or variables pertaining to each unit as columns. We call them &ldquo;features&rdquo; rather than terms, because features are more general than terms: they can be defined as raw terms, stemmed terms, the parts of speech of terms, terms after stopwords have been removed, or a dictionary class to which a term belongs. Features can be entirely general, such as ngrams or syntactic dependencies, and we leave this open-ended.</p>
<div id="tokenizing-texts" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#tokenizing-texts" class="anchor"> </a></body></html>Tokenizing texts</h2>
<p>To simply tokenize a text, quanteda provides a powerful command called <code><a href="../reference/tokenize.html">tokenize()</a></code>. This produces an intermediate object, consisting of a list of tokens in the form of character vectors, where each element of the list corresponds to an input document.</p>
<p><code><a href="../reference/tokenize.html">tokenize()</a></code> is deliberately conservative, meaning that it does not remove anything from the text unless told to do so.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">txt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">text1 =</span> <span class="st">"This is $10 in 999 different ways,</span><span class="ch">\n</span><span class="st"> up and down; left and right!"</span>, 
         <span class="dt">text2 =</span> <span class="st">"@kenbenoit working: on #quanteda 2day</span><span class="ch">\t</span><span class="st">4ever, http://textasdata.com?page=123."</span>)
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(txt)
<span class="co">#&gt; tokenizedTexts from 2 documents.</span>
<span class="co">#&gt; text1 :</span>
<span class="co">#&gt;  [1] "This"      "is"        "$"         "10"        "in"        "999"       "different" "ways"      ","         "up"        "and"       "down"      ";"         "left"      "and"       "right"    </span>
<span class="co">#&gt; [17] "!"        </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; text2 :</span>
<span class="co">#&gt;  [1] "@kenbenoit"     "working"        ":"              "on"             "#quanteda"      "2day"           "4ever"          ","              "http"           ":"              "/"             </span>
<span class="co">#&gt; [12] "/"              "textasdata.com" "?"              "page"           "="              "123"            "."</span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(txt, <span class="dt">removeNumbers =</span> <span class="ot">TRUE</span>, <span class="dt">removePunct =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; tokenizedTexts from 2 documents.</span>
<span class="co">#&gt; text1 :</span>
<span class="co">#&gt;  [1] "This"      "is"        "in"        "different" "ways"      "up"        "and"       "down"      "left"      "and"       "right"    </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; text2 :</span>
<span class="co">#&gt; [1] "@kenbenoit"     "working"        "on"             "#quanteda"      "2day"           "4ever"          "http"           "textasdata.com" "page"</span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(txt, <span class="dt">removeNumbers =</span> <span class="ot">FALSE</span>, <span class="dt">removePunct =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; tokenizedTexts from 2 documents.</span>
<span class="co">#&gt; text1 :</span>
<span class="co">#&gt;  [1] "This"      "is"        "10"        "in"        "999"       "different" "ways"      "up"        "and"       "down"      "left"      "and"       "right"    </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; text2 :</span>
<span class="co">#&gt;  [1] "@kenbenoit"     "working"        "on"             "#quanteda"      "2day"           "4ever"          "http"           "textasdata.com" "page"           "123"</span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(txt, <span class="dt">removeNumbers =</span> <span class="ot">TRUE</span>, <span class="dt">removePunct =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; tokenizedTexts from 2 documents.</span>
<span class="co">#&gt; text1 :</span>
<span class="co">#&gt;  [1] "This"      "is"        "$"         "in"        "different" "ways"      ","         "up"        "and"       "down"      ";"         "left"      "and"       "right"     "!"        </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; text2 :</span>
<span class="co">#&gt;  [1] "@kenbenoit"     "working"        ":"              "on"             "#quanteda"      "2day"           "4ever"          ","              "http"           ":"              "/"             </span>
<span class="co">#&gt; [12] "/"              "textasdata.com" "?"              "page"           "="              "."</span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(txt, <span class="dt">removeNumbers =</span> <span class="ot">FALSE</span>, <span class="dt">removePunct =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; tokenizedTexts from 2 documents.</span>
<span class="co">#&gt; text1 :</span>
<span class="co">#&gt;  [1] "This"      "is"        "$"         "10"        "in"        "999"       "different" "ways"      ","         "up"        "and"       "down"      ";"         "left"      "and"       "right"    </span>
<span class="co">#&gt; [17] "!"        </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; text2 :</span>
<span class="co">#&gt;  [1] "@kenbenoit"     "working"        ":"              "on"             "#quanteda"      "2day"           "4ever"          ","              "http"           ":"              "/"             </span>
<span class="co">#&gt; [12] "/"              "textasdata.com" "?"              "page"           "="              "123"            "."</span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(txt, <span class="dt">removeNumbers =</span> <span class="ot">FALSE</span>, <span class="dt">removePunct =</span> <span class="ot">FALSE</span>, <span class="dt">removeSeparators =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; tokenizedTexts from 2 documents.</span>
<span class="co">#&gt; text1 :</span>
<span class="co">#&gt;  [1] "This"      " "         "is"        " "         "$"         "10"        " "         "in"        " "         "999"       " "         "different" " "         "ways"      ","         "\n"       </span>
<span class="co">#&gt; [17] " "         "up"        " "         "and"       " "         "down"      ";"         " "         "left"      " "         "and"       " "         "right"     "!"        </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; text2 :</span>
<span class="co">#&gt;  [1] "@kenbenoit"     " "              "working"        ":"              " "              "on"             " "              "#quanteda"      " "              "2day"           "\t"            </span>
<span class="co">#&gt; [12] "4ever"          ","              " "              "http"           ":"              "/"              "/"              "textasdata.com" "?"              "page"           "="             </span>
<span class="co">#&gt; [23] "123"            "."</span></code></pre></div>
<p>We also have the option to tokenize characters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(<span class="st">"Great website: http://textasdata.com?page=123."</span>, <span class="dt">what =</span> <span class="st">"character"</span>)
<span class="co">#&gt; tokenizedTexts from 1 document.</span>
<span class="co">#&gt; Component 1 :</span>
<span class="co">#&gt;  [1] "G" "r" "e" "a" "t" "w" "e" "b" "s" "i" "t" "e" ":" "h" "t" "t" "p" ":" "/" "/" "t" "e" "x" "t" "a" "s" "d" "a" "t" "a" "." "c" "o" "m" "?" "p" "a" "g" "e" "=" "1" "2" "3" "."</span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(<span class="st">"Great website: http://textasdata.com?page=123."</span>, <span class="dt">what =</span> <span class="st">"character"</span>, 
         <span class="dt">removeSeparators =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; tokenizedTexts from 1 document.</span>
<span class="co">#&gt; Component 1 :</span>
<span class="co">#&gt;  [1] "G" "r" "e" "a" "t" " " "w" "e" "b" "s" "i" "t" "e" ":" " " "h" "t" "t" "p" ":" "/" "/" "t" "e" "x" "t" "a" "s" "d" "a" "t" "a" "." "c" "o" "m" "?" "p" "a" "g" "e" "=" "1" "2" "3" "."</span></code></pre></div>
<p>and sentences:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># sentence level         </span>
<span class="kw"><a href="../reference/tokenize.html">tokenize</a></span>(<span class="kw">c</span>(<span class="st">"Kurt Vongeut said; only assholes use semi-colons."</span>, 
           <span class="st">"Today is Thursday in Canberra:  It is yesterday in London."</span>, 
           <span class="st">"En el caso de que no puedas ir con ellos, &iquest;quieres ir con nosotros?"</span>), 
          <span class="dt">what =</span> <span class="st">"sentence"</span>)
<span class="co">#&gt; tokenizedTexts from 3 documents.</span>
<span class="co">#&gt; Component 1 :</span>
<span class="co">#&gt; [1] "Kurt Vongeut said; only assholes use semi-colons."</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Component 2 :</span>
<span class="co">#&gt; [1] "Today is Thursday in Canberra:  It is yesterday in London."</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Component 3 :</span>
<span class="co">#&gt; [1] "En el caso de que no puedas ir con ellos, &iquest;quieres ir con nosotros?"</span></code></pre></div>
</div>
<div id="constructing-a-document-frequency-matrix" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#constructing-a-document-frequency-matrix" class="anchor"> </a></body></html>Constructing a document-frequency matrix</h2>
<p>Tokenizing texts is an intermediate option, and most users will want to skip straight to constructing a document-feature matrix. For this, we have a Swiss-army knife function, called <code><a href="../reference/dfm.html">dfm()</a></code>, which performs tokenization and tabulates the extracted features into a matrix of documents by features. Unlike the conservative approach taken by <code><a href="../reference/tokenize.html">tokenize()</a></code>, the <code><a href="../reference/dfm.html">dfm()</a></code> function applies certain options by default, such as <code><a href="../reference/toLower.html">toLower()</a></code> &ndash; a separate function for lower-casing texts &ndash; and removes punctuation. All of the options to <code><a href="../reference/tokenize.html">tokenize()</a></code> can be passed to <code><a href="../reference/dfm.html">dfm()</a></code>, however.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">myCorpus &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus_subset.html">corpus_subset</a></span>(data_corpus_inaugural, Year &gt;<span class="st"> </span><span class="dv">1990</span>)

<span class="co"># make a dfm</span>
myDfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(myCorpus)
myDfm[, <span class="dv">1</span>:<span class="dv">5</span>]
<span class="co">#&gt; Document-feature matrix of: 6 documents, 5 features (0% sparse).</span>
<span class="co">#&gt; 6 x 5 sparse Matrix of class "dfmSparse"</span>
<span class="co">#&gt;               features</span>
<span class="co">#&gt; docs           my fellow citizens   , today</span>
<span class="co">#&gt;   1993-Clinton  7      5        2 139    10</span>
<span class="co">#&gt;   1997-Clinton  6      7        7 131     5</span>
<span class="co">#&gt;   2001-Bush     3      1        9 110     2</span>
<span class="co">#&gt;   2005-Bush     2      3        6 120     3</span>
<span class="co">#&gt;   2009-Obama    2      1        1 130     6</span>
<span class="co">#&gt;   2013-Obama    3      3        6  99     4</span></code></pre></div>
<p>Other options for a <code><a href="../reference/dfm.html">dfm()</a></code> include removing stopwords, and stemming the tokens.</p>
<p><code>r # make a dfm, removing stopwords and applying stemming myStemMat &lt;- dfm(myCorpus, remove = stopwords("english"), stem = TRUE, removePunct = TRUE) #&gt;</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">myStemMat[, <span class="dv">1</span>:<span class="dv">5</span>]
<span class="co">#&gt; Document-feature matrix of: 6 documents, 5 features (20% sparse).</span>
<span class="co">#&gt; 6 x 5 sparse Matrix of class "dfmSparse"</span>
<span class="co">#&gt;               features</span>
<span class="co">#&gt; docs           fellow citizen today celebr mysteri</span>
<span class="co">#&gt;   1993-Clinton      5       2    10      4       1</span>
<span class="co">#&gt;   1997-Clinton      7       8     6      1       0</span>
<span class="co">#&gt;   2001-Bush         1      10     2      0       0</span>
<span class="co">#&gt;   2005-Bush         3       7     3      2       0</span>
<span class="co">#&gt;   2009-Obama        1       1     6      2       0</span>
<span class="co">#&gt;   2013-Obama        3       8     6      1       0</span></code></pre></div>
<p>The option <code>remove</code> provides a list of tokens to be ignored. Most users will supply a list of pre-defined &ldquo;stop words&rdquo;, defined for numerous languages, accessed through the <code><a href="../reference/stopwords.html">stopwords()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"english"</span>), <span class="dv">20</span>)
<span class="co">#&gt;  [1] "i"          "me"         "my"         "myself"     "we"         "our"        "ours"       "ourselves"  "you"        "your"       "yours"      "yourself"   "yourselves" "he"         "him"       </span>
<span class="co">#&gt; [16] "his"        "himself"    "she"        "her"        "hers"</span>
<span class="kw">head</span>(<span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"russian"</span>), <span class="dv">10</span>)
<span class="co">#&gt;  [1] "&#1080;"   "&#1074;"   "&#1074;&#1086;"  "&#1085;&#1077;"  "&#1095;&#1090;&#1086;" "&#1086;&#1085;"  "&#1085;&#1072;"  "&#1103;"   "&#1089;"   "&#1089;&#1086;"</span>
<span class="kw">head</span>(<span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"arabic"</span>), <span class="dv">10</span>)
<span class="co">#&gt;  [1] "&#1601;&#1609;"  "&#1601;&#1610;"  "&#1603;&#1604;"  "&#1604;&#1605;"  "&#1604;&#1606;"  "&#1604;&#1607;"  "&#1605;&#1606;"  "&#1607;&#1608;"  "&#1607;&#1610;"  "&#1602;&#1608;&#1577;"</span></code></pre></div>
<div id="viewing-the-document-frequency-matrix" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#viewing-the-document-frequency-matrix" class="anchor"> </a></body></html>Viewing the document-frequency matrix</h3>
<p>The dfm can be inspected in the Enviroment pane in RStudio, or by calling R&rsquo;s <code>View</code> function. Calling <code>plot</code> on a dfm will display a wordcloud using the <a href="link.">wordcloud package</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mydfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(data_char_ukimmig2010, <span class="dt">remove =</span> <span class="kw">c</span>(<span class="st">"will"</span>, <span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"english"</span>)), 
             <span class="dt">removePunct =</span> <span class="ot">TRUE</span>)
mydfm
<span class="co">#&gt; Document-feature matrix of: 9 documents, 1,547 features (83.8% sparse).</span></code></pre></div>
<p>To access a list of the most frequently occurring features, we can use <code><a href="../reference/topfeatures.html">topfeatures()</a></code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/topfeatures.html">topfeatures</a></span>(mydfm, <span class="dv">20</span>)  <span class="co"># 20 top words</span>
<span class="co">#&gt; immigration     british      people      asylum     britain          uk      system  population     country         new  immigrants      ensure       shall citizenship      social    national </span>
<span class="co">#&gt;          66          37          35          29          28          27          27          21          20          19          17          17          17          16          14          14 </span>
<span class="co">#&gt;         bnp     illegal        work     percent </span>
<span class="co">#&gt;          13          13          13          12</span></code></pre></div>
<p>Plotting a word cloud is done using <code><a href="../reference/textplot_wordcloud.html">textplot_wordcloud()</a></code>, for a <code>dfm</code> class object:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/textplot_wordcloud.html">textplot_wordcloud</a></span>(mydfm)</code></pre></div>
<p><img src="quickstart_files/figure-html/unnamed-chunk-22-1.png" width="768"></p>
<p>The <code><a href="../reference/plot-deprecated.html">plot.dfm()</a></code> method passes arguments through to <code>wordcloud()</code> from the <strong>wordcloud</strong> package, and can prettify the plot using the same arguments:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">if (<span class="kw">require</span>(RColorBrewer))
    <span class="kw"><a href="../reference/textplot_wordcloud.html">textplot_wordcloud</a></span>(mydfm, <span class="dt">max.words =</span> <span class="dv">100</span>, <span class="dt">colors =</span> <span class="kw">brewer.pal</span>(<span class="dv">6</span>, <span class="st">"Dark2"</span>), <span class="dt">scale =</span> <span class="kw">c</span>(<span class="dv">8</span>, .<span class="dv">5</span>))
<span class="co">#&gt; Loading required package: RColorBrewer</span></code></pre></div>
<p><img src="quickstart_files/figure-html/unnamed-chunk-23-1.png" width="672"></p>
</div>
<div id="grouping-documents-by-document-variable" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#grouping-documents-by-document-variable" class="anchor"> </a></body></html>Grouping documents by document variable</h3>
<p>Often, we are interested in analysing how texts differ according to substantive factors which may be encoded in the document variables, rather than simply by the boundaries of the document files. We can group documents which share the same value for a document variable when creating a dfm:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">byPartyDfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(data_corpus_irishbudget2010, <span class="dt">groups =</span> <span class="st">"party"</span>, <span class="dt">remove =</span> <span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"english"</span>), <span class="dt">removePunct =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>We can sort this dfm, and inspect it:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sort</span>(byPartyDfm)[, <span class="dv">1</span>:<span class="dv">10</span>]
<span class="co">#&gt; Warning: 'sort.dfm' is deprecated.</span>
<span class="co">#&gt; Use 'dfm_sort' instead.</span>
<span class="co">#&gt; See help("Deprecated")</span>
<span class="co">#&gt; Document-feature matrix of: 5 documents, 10 features (0% sparse).</span>
<span class="co">#&gt; 5 x 10 sparse Matrix of class "dfmSparse"</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    will people budget government public minister tax economy pay jobs</span>
<span class="co">#&gt;   FF     212     23     44         47     65       11  60      37  41   41</span>
<span class="co">#&gt;   FG      93     78     71         61     47       62  11      20  29   17</span>
<span class="co">#&gt;   Green   59     15     26         19      4        4  11      16   4   15</span>
<span class="co">#&gt;   LAB     89     69     66         36     32       54  47      37  24   20</span>
<span class="co">#&gt;   SF     104     81     53         73     31       39  34      50  24   27</span></code></pre></div>
<p>Note that the most frequently occurring feature is &ldquo;will&rdquo;, a word usually on English stop lists, but one that is not included in quanteda&rsquo;s built-in English stopword list.</p>
</div>
<div id="grouping-words-by-dictionary-or-equivalence-class" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#grouping-words-by-dictionary-or-equivalence-class" class="anchor"> </a></body></html>Grouping words by dictionary or equivalence class</h3>
<p>For some applications we have prior knowledge of sets of words that are indicative of traits we would like to measure from the text. For example, a general list of positive words might indicate positive sentiment in a movie review, or we might have a dictionary of political terms which are associated with a particular ideological stance. In these cases, it is sometimes useful to treat these groups of words as equivalent for the purposes of analysis, and sum their counts into classes.</p>
<p>For example, let&rsquo;s look at how words associated with terrorism and words associated with the economy vary by President in the inaugural speeches corpus. From the original corpus, we select Presidents since Clinton:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">recentCorpus &lt;-<span class="st"> </span><span class="kw"><a href="../reference/corpus_subset.html">corpus_subset</a></span>(data_corpus_inaugural, Year &gt;<span class="st"> </span><span class="dv">1991</span>)</code></pre></div>
<p>Now we define a demonstration dictionary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">myDict &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dictionary.html">dictionary</a></span>(<span class="kw">list</span>(<span class="dt">terror =</span> <span class="kw">c</span>(<span class="st">"terrorism"</span>, <span class="st">"terrorists"</span>, <span class="st">"threat"</span>),
                          <span class="dt">economy =</span> <span class="kw">c</span>(<span class="st">"jobs"</span>, <span class="st">"business"</span>, <span class="st">"grow"</span>, <span class="st">"work"</span>)))</code></pre></div>
<p>We can use the dictionary when making the dfm:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">byPresMat &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(recentCorpus, <span class="dt">dictionary =</span> myDict)
byPresMat
<span class="co">#&gt; Document-feature matrix of: 6 documents, 2 features (0% sparse).</span>
<span class="co">#&gt; 6 x 2 sparse Matrix of class "dfmSparse"</span>
<span class="co">#&gt;               features</span>
<span class="co">#&gt; docs           terror economy</span>
<span class="co">#&gt;   1993-Clinton      0       8</span>
<span class="co">#&gt;   1997-Clinton      1       8</span>
<span class="co">#&gt;   2001-Bush         0       4</span>
<span class="co">#&gt;   2005-Bush         1       6</span>
<span class="co">#&gt;   2009-Obama        1      10</span>
<span class="co">#&gt;   2013-Obama        1       6</span></code></pre></div>
<p>The constructor function <code><a href="../reference/dictionary.html">dictionary()</a></code> also works with two common &ldquo;foreign&rdquo; dictionary formats: the LIWC and Provalis Research&rsquo;s Wordstat format. For instance, we can load the LIWC and apply this to the Presidential inaugural speech corpus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">liwcdict &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dictionary.html">dictionary</a></span>(<span class="dt">file =</span> <span class="st">"~/Dropbox/QUANTESS/dictionaries/LIWC/LIWC2001_English.dic"</span>,
                       <span class="dt">format =</span> <span class="st">"LIWC"</span>)
liwcdfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(data_char_inaugural[<span class="dv">52</span>:<span class="dv">57</span>], <span class="dt">dictionary =</span> liwcdict, <span class="dt">verbose =</span> <span class="ot">FALSE</span>)
liwcdfm[, <span class="dv">1</span>:<span class="dv">10</span>]</code></pre></div>
</div>
</div>
</div>
<div id="further-examples" class="section level1">
<h1 class="hasAnchor"><html><body><a href="#further-examples" class="anchor"> </a></body></html>Further Examples</h1>
<div id="similarities-between-texts" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#similarities-between-texts" class="anchor"> </a></body></html>Similarities between texts</h2>
<p><code>r presDfm &lt;- dfm(corpus_subset(data_corpus_inaugural, Year&gt;1980),                 remove = stopwords("english"),                stem = TRUE, verbose = FALSE, removePunct = TRUE) #&gt;</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obamaSimil &lt;-<span class="st"> </span><span class="kw"><a href="../reference/similarity.html">similarity</a></span>(presDfm, <span class="kw">c</span>(<span class="st">"2009-Obama"</span> , <span class="st">"2013-Obama"</span>), <span class="dt">n =</span> <span class="ot">NULL</span>, 
                            <span class="dt">margin =</span> <span class="st">"documents"</span>, <span class="dt">method =</span> <span class="st">"cosine"</span>, <span class="dt">normalize =</span> <span class="ot">FALSE</span>)
<span class="kw">dotchart</span>(obamaSimil$<span class="st">`</span><span class="dt">2009-Obama</span><span class="st">`</span>, <span class="dt">xlab =</span> <span class="st">"Cosine similarity"</span>)</code></pre></div>
<p><img src="quickstart_files/figure-html/unnamed-chunk-30-1.png" width="576"></p>
<p>We can use these distances to plot a dendrogram, clustering presidents:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(SOTUCorpus, <span class="dt">package=</span><span class="st">"quantedaData"</span>)
presDfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(<span class="kw"><a href="../reference/corpus_subset.html">corpus_subset</a></span>(SOTUCorpus, Date &gt;<span class="st"> </span><span class="kw">as.Date</span>(<span class="st">"1960-01-01"</span>)), <span class="dt">verbose =</span> <span class="ot">FALSE</span>, <span class="dt">stem =</span> <span class="ot">TRUE</span>,
               <span class="dt">remove =</span> <span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"english"</span>), <span class="dt">removePunct =</span> <span class="ot">TRUE</span>)
presDfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm_trim.html">dfm_trim</a></span>(presDfm, <span class="dt">min_count=</span><span class="dv">5</span>, <span class="dt">min_docfreq=</span><span class="dv">3</span>)
<span class="co"># hierarchical clustering - get distances on normalized dfm</span>
presDistMat &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">as.matrix</span>(<span class="kw"><a href="../reference/weight.html">weight</a></span>(presDfm, <span class="st">"relFreq"</span>)))
<span class="co"># hiarchical clustering the distance object</span>
presCluster &lt;-<span class="st"> </span><span class="kw">hclust</span>(presDistMat)
<span class="co"># label with document names</span>
presCluster$labels &lt;-<span class="st"> </span><span class="kw"><a href="../reference/docnames.html">docnames</a></span>(presDfm)
<span class="co"># plot as a dendrogram</span>
<span class="kw">plot</span>(presCluster, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">sub =</span> <span class="st">""</span>, <span class="dt">main =</span> <span class="st">"Euclidean Distance on Normalized Token Frequency"</span>)</code></pre></div>
<p><img src="images/prescluster.png" alt="Presidential Cluster Dendrogram" style="width: 780px;"></p>
<p>We can also look at term similarities:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim &lt;-<span class="st"> </span><span class="kw"><a href="../reference/similarity.html">similarity</a></span>(presDfm, <span class="kw">c</span>(<span class="st">"fair"</span>, <span class="st">"health"</span>, <span class="st">"terror"</span>), <span class="dt">method =</span> <span class="st">"cosine"</span>, <span class="dt">margin =</span> <span class="st">"features"</span>, <span class="dt">n =</span> <span class="dv">10</span>)
<span class="kw">print</span>(sim, <span class="dt">digits =</span> <span class="dv">2</span>)
<span class="co">#&gt; similarity Matrix:</span>
<span class="co">#&gt; $fair</span>
<span class="co">#&gt;   economi     begin      mani jefferson    author     howev     faith       god   struggl      call </span>
<span class="co">#&gt;      0.91      0.91      0.90      0.90      0.89      0.89      0.89      0.87      0.87      0.86 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $terror</span>
<span class="co">#&gt;    factori  adversari commonplac     miracl     racial     bounti     martin   guarante       solv    potenti </span>
<span class="co">#&gt;       0.95       0.95       0.94       0.94       0.94       0.94       0.94       0.89       0.89       0.89 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $health</span>
<span class="co">#&gt; knowledg    shape  generat    wrong    defin   common    child     fear   demand   planet </span>
<span class="co">#&gt;     0.94     0.90     0.90     0.89     0.89     0.89     0.89     0.89     0.88     0.88</span></code></pre></div>
</div>
<div id="scaling-document-positions" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#scaling-document-positions" class="anchor"> </a></body></html>Scaling document positions</h2>
<p>We have a lot of development work to do on the <code><a href="../reference/textmodel.html">textmodel()</a></code> function, but here is a demonstration of unsupervised document scaling comparing the &ldquo;wordfish&rdquo; model to scaling from correspondence analysis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make prettier document names</span>
<span class="kw"><a href="../reference/docnames.html">docnames</a></span>(data_corpus_irishbudget2010) &lt;-<span class="st"> </span>
<span class="st">    </span><span class="kw">paste</span>(<span class="kw"><a href="../reference/docvars.html">docvars</a></span>(data_corpus_irishbudget2010, <span class="st">"name"</span>), <span class="kw"><a href="../reference/docvars.html">docvars</a></span>(data_corpus_irishbudget2010, <span class="st">"party"</span>))
ieDfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(data_corpus_irishbudget2010, <span class="dt">verbose =</span> <span class="ot">FALSE</span>)
wf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/textmodel.html">textmodel</a></span>(ieDfm, <span class="dt">model =</span> <span class="st">"wordfish"</span>, <span class="dt">dir=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>))
wca &lt;-<span class="st"> </span><span class="kw"><a href="../reference/textmodel.html">textmodel</a></span>(ieDfm, <span class="dt">model =</span> <span class="st">"ca"</span>)
<span class="co"># plot the results</span>
<span class="kw">plot</span>(wf@theta, -<span class="dv">1</span>*wca$rowcoord[,<span class="dv">1</span>], 
     <span class="dt">xlab=</span><span class="st">"Wordfish theta-hat"</span>, <span class="dt">ylab=</span><span class="st">"CA dim 1 coordinate"</span>, <span class="dt">pch=</span><span class="dv">19</span>)
<span class="kw">text</span>(wf@theta, -<span class="dv">1</span>*wca$rowcoord[,<span class="dv">1</span>], <span class="kw"><a href="../reference/docnames.html">docnames</a></span>(ieDfm), <span class="dt">cex=</span>.<span class="dv">8</span>, <span class="dt">pos=</span><span class="dv">1</span>)
<span class="kw">abline</span>(<span class="kw">lm</span>(-<span class="dv">1</span>*wca$rowcoord[,<span class="dv">1</span>] ~<span class="st"> </span>wf@theta), <span class="dt">col=</span><span class="st">"grey50"</span>, <span class="dt">lty=</span><span class="st">"dotted"</span>)</code></pre></div>
<p><img src="quickstart_files/figure-html/unnamed-chunk-33-1.png" width="576"></p>
</div>
<div id="topic-models" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#topic-models" class="anchor"> </a></body></html>Topic models</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">quantdfm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dfm.html">dfm</a></span>(data_corpus_irishbudget2010, <span class="dt">verbose =</span> <span class="ot">FALSE</span>, 
                <span class="dt">remove =</span> <span class="kw">c</span>(<span class="st">"will"</span>, <span class="kw"><a href="../reference/stopwords.html">stopwords</a></span>(<span class="st">"english"</span>)))

if (<span class="kw">require</span>(topicmodels)) {
    myLDAfit20 &lt;-<span class="st"> </span><span class="kw">LDA</span>(<span class="kw"><a href="../reference/convert.html">convert</a></span>(quantdfm, <span class="dt">to =</span> <span class="st">"topicmodels"</span>), <span class="dt">k =</span> <span class="dv">20</span>)
    <span class="kw">get_terms</span>(myLDAfit20, <span class="dv">5</span>)
    <span class="kw">topics</span>(myLDAfit20, <span class="dv">3</span>)
}
<span class="co">#&gt; Loading required package: topicmodels</span>
<span class="co">#&gt; Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, : there is no package called 'topicmodels'</span></code></pre></div>
</div>
</div>
<div class="footnotes">
<hr><ol><li id="fn1"><p>This research was supported by European Research Council grant ERC-2011-StG 283794-QUANTESS, Principal Investigator Kenneth Benoit. Core contributors to the project include Paul Nulty, Adam Obeng, Kohei Watanabe, Haiyan Wang, Ben Lauderdale, Will Lowe, and Pablo Barber&agrave;.<a href="#fnref1">&#8617;</a></p></li>
</ol></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked"><li><a href="#introduction">Introduction</a></li>
      <li><a href="#quanteda-features">quanteda Features</a><ul class="nav nav-pills nav-stacked"><li><a href="#corpus-management-tools">Corpus management tools</a></li>
      <li><a href="#natural-language-processing-tools">Natural-Language Processing tools</a></li>
      <li><a href="#document-feature-matrix-analysis-tools">Document-Feature Matrix analysis tools</a></li>
      <li><a href="#additional-and-planned-features">Additional and planned features</a></li>
      <li><a href="#working-with-other-text-analysis-packages">Working with other text analysis packages</a></li>
      </ul></li>
      <li><a href="#how-to-install">How to Install</a></li>
      <li><a href="#creating-and-working-with-a-corpus">Creating and Working with a Corpus</a><ul class="nav nav-pills nav-stacked"><li><a href="#currently-available-corpus-sources">Currently available corpus sources</a></li>
      <li><a href="#how-a-quanteda-corpus-works">How a quanteda corpus works</a></li>
      <li><a href="#tools-for-handling-corpus-objects">Tools for handling corpus objects</a></li>
      <li><a href="#exploring-corpus-texts">Exploring corpus texts</a></li>
      </ul></li>
      <li><a href="#extracting-features-from-a-corpus">Extracting Features from a Corpus</a><ul class="nav nav-pills nav-stacked"><li><a href="#tokenizing-texts">Tokenizing texts</a></li>
      <li><a href="#constructing-a-document-frequency-matrix">Constructing a document-frequency matrix</a></li>
      </ul></li>
      <li><a href="#further-examples">Further Examples</a><ul class="nav nav-pills nav-stacked"><li><a href="#similarities-between-texts">Similarities between texts</a></li>
      <li><a href="#scaling-document-positions">Scaling document positions</a></li>
      <li><a href="#topic-models">Topic models</a></li>
      </ul></li>
      </ul></div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Kenneth Benoit.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer></div>

  </body></html>
