---
title: "事例: 2017年総選挙に関するツイート"
author: Kohei Watanabe and Akitaka Matsuo
output: 
  html_document:
    toc: true
---

```{r, echo=FALSE, results = 'asis'}
cat('<link href="../../../ja.css" rel="text/css">')
```

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "##"
)
```

## パッケージの読み込み {#load-package}

```{r, message = FALSE}
library(quanteda)
```


## データをダウンロード {#download}

本コーパスは，2017年総選挙の際に収集されたツイートから構成されている．ツイートは，TwitterのStrem APIから、キーワード"選挙"を使い，10月20日から10月31日の期間にダウンロードした．インターネット上で収集されたテキストは，英数字の全半角が統一されていないので，`stri_trans_nfkc()`によって表記を標準化すると良い．

```{r, message=FALSE}
devtools::install_github("quanteda/quanteda.corpora")
corp <- quanteda.corpora::download(url = 'https://www.dropbox.com/s/co12wpj08pzqz71/data_corpus_election2017tweets.rds?dl=1')
texts(corp) <- stringi::stri_trans_nfkc(texts(corp)) # 表記を標準化
```


## 投稿の数と期間を取得 {#number-of-tweets}

```{r}
ndoc(corp)
range(docvars(corp, 'created_at'))
```

# 前処理 {#pre-processing}

## トークン化：語の分割と結合 {#tokenization}

ツイートのトークン化では，ハッシュタグの後に続く改行を保持するために`remove_separator = FALSE`とし，次の`tokens_remove()`で，語の位置関係を維持しながら，改行，空白，'#'と'@'以外の記号を削除する．日本語のハッシュタグは，’#’とそれの続く語が分離されてしまうので，それらを`tokens_compound()`で文書行列を作成する前に結合する．

```{r}

toks <- tokens(corp, remove_separator = FALSE, remove_url = TRUE)
toks <- tokens_select(toks, '^[\\w#@]+$', valuetype = 'regex', padding = TRUE)

min_count <- 10

# 漢字
kanji_col <- tokens_keep(toks, '^[一-龠]+$', valuetype = 'regex', padding = TRUE) %>% 
             textstat_collocations(min_count = min_count)
toks <- tokens_compound(toks, kanji_col[kanji_col$z > 3,], concatenator = '')

# カタカナ
kana_col <- tokens_keep(toks, '^[ァ-ヶー]+$', valuetype = 'regex', padding = TRUE) %>% 
            textstat_collocations(min_count = min_count)
toks <- tokens_compound(toks, kana_col[kana_col$z > 3,], concatenator = '')

# 漢字，カタカナおよび数字
any_col <- tokens_select(toks, '^[0-9ァ-ヶー一-龠]+$', valuetype = 'regex', padding = TRUE) %>% 
           textstat_collocations(min_count = min_count)
toks <- tokens_compound(toks, any_col[any_col$z > 3,], concatenator = '')

# ハッシュと語の結合
toks <- tokens_compound(toks, phrase('# *'), concatenator = '') 

tweet_dfm <- dfm(toks)
```

# 分析 {#analysis}

## タグの共起ネットワーク {#network-tag}

ここでは，`dfm_select()`によってハッシュタグを選択しているが，そこに多くに含まれる'#選挙'や'#衆院選'などのハッシュタグは，クラスターを明確にするために削除している．

```{r}
tag_fcm <- 
    tweet_dfm %>% 
    dfm_select('#*') %>% 
    dfm_remove(c('*選挙*', '*衆院選*', '*衆議院*', '*投票*'), min_nchar = 2) %>% 
    dfm_trim(min_count = 10) %>% 
    fcm()
feat <- names(topfeatures(tag_fcm, 100))
textplot_network(fcm_select(tag_fcm,  feat), min_freq = 0.8)
```

## 語の共起ネットワーク {#network-word}

ツイートのメッセージを分析するためには，`dfm_remove()`でハッシュタグやユーザー名を削除する．ここでは，平仮名だけからなる特徴は文法的な要素であることが多く，話題を理解するのに役に立たないので削除している．

```{r}
msg_fcm <- 
    tweet_dfm %>% 
    dfm_remove(c('#*', '@*')) %>% 
    dfm_remove('^[ぁ-ん]+$', 'regex', min_nchar = 2) %>% 
    dfm_trim(min_count = 10) %>% 
    dfm_toupper() %>% 
    fcm()
feat <- names(topfeatures(msg_fcm, 50))
textplot_network(fcm_select(msg_fcm,  feat), min_freq = 0.3)
```

