<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Replication: word embedding (gloVe/word2vec) • quanteda</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../../bootstrap-toc.css">
<script src="../../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../../pkgdown.css" rel="stylesheet">
<script src="../../../pkgdown.js"></script><!-- docsearch --><script src="../../../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../../../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><link href="../../../extra.css" rel="stylesheet">
<script src="../../../extra.js"></script><meta property="og:title" content="Replication: word embedding (gloVe/word2vec)">
<meta property="og:description" content="quanteda">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-144616-24"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-144616-24');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../../index.html">quanteda</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">3.3.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Quick Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/quickstart.html">Quick Start Guide</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_es.html">Guía de Inicio Rápido</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_cn.html">快速入门指南</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_ja.html">クイック・スタートガイド</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_hi.html">त्वरित आरंभ </a>
    </li>
  </ul>
</li>
<li>
  <a href="../../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Features
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/comparison.html">Feature comparison</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/design.html">Package design</a>
    </li>
    <li>
      <a href="../../../news/index.html">Changelog</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/examples/phrase.html">Multi-word expressions</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/plotting.html">Textual data visualization</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/lsa.html">Latent Semantic Analysis (LSA)</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/chinese.html">Chinese text analysis</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/twitter.html">Social media analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Replications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/replication/digital-humanities.html">Text Analysis with R for Students of Literature</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/replication/text2vec.html">Word embedding (word2vec)</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/replication/qss.html">Quantitative Social Science Ch. 5.1</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/quanteda/quanteda" class="external-link">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Replication: word embedding
(gloVe/word2vec)</h1>
                        <h4 data-toc-skip class="author">Kenneth Benoit,
Haiyan Wang and Kohei Watanabe</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/quanteda/quanteda/blob/HEAD/vignettes/pkgdown/replication/text2vec.Rmd" class="external-link"><code>vignettes/pkgdown/replication/text2vec.Rmd</code></a></small>
      <div class="hidden name"><code>text2vec.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://quanteda.io">"quanteda"</a></span><span class="op">)</span></span></code></pre></div>
<p>This is intended to show how <strong>quanteda</strong> can be used
with the <a href="http://text2vec.org" class="external-link"><strong>text2vec</strong></a>
package in order to replicate its <a href="http://text2vec.org/glove.html" class="external-link">gloVe example</a>.</p>
<div class="section level2">
<h2 id="download-the-corpus">Download the corpus<a class="anchor" aria-label="anchor" href="#download-the-corpus"></a>
</h2>
<p>Download a corpus comprising the texts used in the <a href="http://text2vec.org/glove.html" class="external-link"><strong>text2vec</strong>
vignette</a>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">wiki_corp</span> <span class="op">&lt;-</span> <span class="fu">quanteda.corpora</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/quanteda.corpora/man/download.html" class="external-link">download</a></span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://www.dropbox.com/s/9mubqwpgls3qi9t/data_corpus_wiki.rds?dl=1"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="select-features">Select features<a class="anchor" aria-label="anchor" href="#select-features"></a>
</h2>
<p>First, we tokenize the corpus, and then get the names of the features
that occur five times or more. Trimming the features before constructing
the fcm:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">wiki_toks</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/tokens.html">tokens</a></span><span class="op">(</span><span class="va">wiki_corp</span><span class="op">)</span></span>
<span><span class="va">feats</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/dfm.html">dfm</a></span><span class="op">(</span><span class="va">wiki_toks</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="../../../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="../../../reference/dfm_trim.html">dfm_trim</a></span><span class="op">(</span>min_termfreq <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="op"><a href="../../../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="../../../reference/featnames.html">featnames</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Creating a dfm from a tokens input...</span></span></code></pre>
<pre><code><span><span class="co">##  ...lowercasing</span></span></code></pre>
<pre><code><span><span class="co">##  ...found 1 document, 253,854 features</span></span></code></pre>
<pre><code><span><span class="co">##  ...complete, elapsed time: 0.837 seconds.</span></span></code></pre>
<pre><code><span><span class="co">## Finished constructing a 1 x 253,854 sparse dfm.</span></span></code></pre>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># leave the pads so that non-adjacent words will not become adjacent</span></span>
<span><span class="va">wiki_toks</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/tokens_select.html">tokens_select</a></span><span class="op">(</span><span class="va">wiki_toks</span>, <span class="va">feats</span>, padding <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="construct-the-feature-co-occurrence-matrix">Construct the feature co-occurrence matrix<a class="anchor" aria-label="anchor" href="#construct-the-feature-co-occurrence-matrix"></a>
</h2>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">wiki_fcm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/fcm.html">fcm</a></span><span class="op">(</span><span class="va">wiki_toks</span>, context <span class="op">=</span> <span class="st">"window"</span>, count <span class="op">=</span> <span class="st">"weighted"</span>, weights <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span>, tri <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="fit-word-embedding-model">Fit word embedding model<a class="anchor" aria-label="anchor" href="#fit-word-embedding-model"></a>
</h2>
<p>Fit the <a href="https://nlp.stanford.edu/pubs/glove.pdf" class="external-link">GloVe
model</a> using <a href="http://text2vec.org" class="external-link"><strong>rsparse</strong></a>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="http://text2vec.org" class="external-link">"text2vec"</a></span><span class="op">)</span></span></code></pre></div>
<p>GloVe is an unsupervised learning algorithm for obtaining vector
representations for words. Training is performed on aggregated global
word-word co-occurrence statistics from a corpus, and the resulting
representations showcase interesting linear substructures of the word
vector space.</p>
<p>GloVe encodes the ratios of word-word co-occurrence probabilities,
which is thought to represent some crude form of meaning associated with
the abstract concept of the word, as vector difference. The training
objective of GloVe is to learn word vectors such that their dot product
equals the logarithm of the words’ probability of co-occurrence.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glove</span> <span class="op">&lt;-</span> <span class="va"><a href="https://rdrr.io/pkg/text2vec/man/GloVe.html" class="external-link">GlobalVectors</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>rank <span class="op">=</span> <span class="fl">50</span>, x_max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">wv_main</span> <span class="op">&lt;-</span> <span class="va">glove</span><span class="op">$</span><span class="fu">fit_transform</span><span class="op">(</span><span class="va">wiki_fcm</span>, n_iter <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                               convergence_tol <span class="op">=</span> <span class="fl">0.01</span>, n_threads <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## INFO  [12:58:18.615] epoch 1, loss 0.1618</span></span>
<span><span class="co">## INFO  [12:58:27.239] epoch 2, loss 0.1235</span></span>
<span><span class="co">## INFO  [12:58:36.037] epoch 3, loss 0.1075</span></span>
<span><span class="co">## INFO  [12:58:44.948] epoch 4, loss 0.0994</span></span>
<span><span class="co">## INFO  [12:58:54.064] epoch 5, loss 0.0944</span></span>
<span><span class="co">## INFO  [12:59:02.937] epoch 6, loss 0.0910</span></span>
<span><span class="co">## INFO  [12:59:11.737] epoch 7, loss 0.0884</span></span>
<span><span class="co">## INFO  [12:59:20.336] epoch 8, loss 0.0863</span></span>
<span><span class="co">## INFO  [12:59:28.992] epoch 9, loss 0.0846</span></span>
<span><span class="co">## INFO  [12:59:37.752] epoch 10, loss 0.0832</span></span></code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">wv_main</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 71290    50</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="averaging-learned-word-vectors">Averaging learned word vectors<a class="anchor" aria-label="anchor" href="#averaging-learned-word-vectors"></a>
</h2>
<p>The two vectors are main and context. According to the Glove paper,
averaging the two word vectors results in more accurate
representation.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">wv_context</span> <span class="op">&lt;-</span> <span class="va">glove</span><span class="op">$</span><span class="va">components</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">wv_context</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1]    50 71290</span></span></code></pre>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">word_vectors</span> <span class="op">&lt;-</span> <span class="va">wv_main</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">wv_context</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="examining-term-representations">Examining term representations<a class="anchor" aria-label="anchor" href="#examining-term-representations"></a>
</h2>
<p>Now we can find the closest word vectors for
<code>paris - france + germany</code></p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">berlin</span> <span class="op">&lt;-</span> <span class="va">word_vectors</span><span class="op">[</span><span class="st">"paris"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span> <span class="op">-</span></span>
<span>  <span class="va">word_vectors</span><span class="op">[</span><span class="st">"france"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span> <span class="op">+</span></span>
<span>  <span class="va">word_vectors</span><span class="op">[</span><span class="st">"germany"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://quanteda.io">"quanteda.textstats"</a></span><span class="op">)</span></span>
<span><span class="va">cos_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/textstat_simil.html">textstat_simil</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="../../../reference/as.dfm.html">as.dfm</a></span><span class="op">(</span><span class="va">word_vectors</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="../../../reference/as.dfm.html">as.dfm</a></span><span class="op">(</span><span class="va">berlin</span><span class="op">)</span>,</span>
<span>                          method <span class="op">=</span> <span class="st">"cosine"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="va">cos_sim</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     paris    berlin    vienna   germany      near </span></span>
<span><span class="co">## 0.7965647 0.7746740 0.6929871 0.6632698 0.6599919</span></span></code></pre>
<p>Here is another example for
<code>london = paris - france + uk + england</code></p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">london</span> <span class="op">&lt;-</span>  <span class="va">word_vectors</span><span class="op">[</span><span class="st">"paris"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span> <span class="op">-</span></span>
<span>    <span class="va">word_vectors</span><span class="op">[</span><span class="st">"france"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span> <span class="op">+</span></span>
<span>    <span class="va">word_vectors</span><span class="op">[</span><span class="st">"uk"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span> <span class="op">+</span></span>
<span>    <span class="va">word_vectors</span><span class="op">[</span><span class="st">"england"</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span></span>
<span><span class="va">cos_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/textstat_simil.html">textstat_simil</a></span><span class="op">(</span><span class="fu"><a href="../../../reference/as.dfm.html">as.dfm</a></span><span class="op">(</span><span class="va">word_vectors</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="../../../reference/as.dfm.html">as.dfm</a></span><span class="op">(</span><span class="va">london</span><span class="op">)</span>,</span>
<span>                          margin <span class="op">=</span> <span class="st">"documents"</span>, method <span class="op">=</span> <span class="st">"cosine"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="va">cos_sim</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    london        uk      york   england        at </span></span>
<span><span class="co">## 0.7936029 0.7675136 0.7650075 0.7410029 0.7255965</span></span></code></pre>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Kenneth Benoit, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng, Stefan Müller, Akitaka Matsuo, William Lowe, European Research Council.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: '9b4ef7fd791dc6075154d3ebd7b12acf',
    indexName: 'quanteda',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
