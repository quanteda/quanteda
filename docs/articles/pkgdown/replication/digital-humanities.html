<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Replication: Text Analysis with R for Students of Literature • quanteda</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../../pkgdown.css" rel="stylesheet">
<script src="../../../jquery.sticky-kit.min.js"></script><script src="../../../pkgdown.js"></script><!-- docsearch --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
<link href="../../../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><link href="../../../extra.css" rel="stylesheet">
<script src="../../../extra.js"></script><meta property="og:title" content="Replication: Text Analysis with R for Students of Literature">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-144616-24"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-144616-24');
</script>
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../../index.html">quanteda</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">1.3.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Quick Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/quickstart.html">Quick Start Guide</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_es.html">Guía de Inicio Rápido</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_cn.html">快速入门指南</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_ja.html">クイック・スタートガイド</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Features
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/comparison.html">Feature comparison</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/design.html">Package design</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/examples/phrase.html">Multi-word expressions</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/plotting.html">Textual data visualization</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/lsa.html">Latent Semantic Analysis (LSA)</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/chinese.html">Chinese text analysis</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/twitter.html">Social media analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Replications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/replication/digital-humanities.html">Text Analysis with R for Students of Literature</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/replication/text2vec.html">Word embedding (word2vec)</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/replication/qss.html">Quantitative Social Science Ch. 5.1</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/quanteda/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Replication: Text Analysis with R for Students of Literature</h1>
                        <h4 class="author">Kenneth Benoit, Stefan Müller, and Paul Nulty</h4>
            
      
      
      <div class="hidden name"><code>digital-humanities.Rmd</code></div>

    </div>

    
    
<p>In this vignette we show how the <strong>quanteda</strong> package can be used to replicate the analysis from Matthew Jockers’ book <a href="http://doi.org/10.1007/978-3-319-03164-4"><em>Text Analysis with R for Students of Literature</em></a> (London: Springer, 2014). Most of the Jockers book consists of loading, transforming, and analyzing quantities derived from text and data from text. Because <strong>quanteda</strong> has built in most of the code to perform these data transformations and analyses, it makes it possible to replicate the results from the book with far less code. Throughout this vignette, we name objects based on Jockers’ book, but follow the <strong>quanteda</strong> <a href="https://github.com/quanetda/quanteda/wiki/Style-guide">style guide</a>.</p>
<p>In what follows, each section corresponds to the respective chapter in the book.</p>
<div id="r-basics" class="section level1">
<h1 class="hasAnchor">
<a href="#r-basics" class="anchor"></a>1 R Basics</h1>
<p>Our closest equivalent is simply:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"quanteda"</span>)
<span class="kw">install.packages</span>(<span class="st">"readtext"</span>)</code></pre></div>
<p>But if you are reading this vignette, than chances are that you have already completed this step.</p>
</div>
<div id="first-foray" class="section level1">
<h1 class="hasAnchor">
<a href="#first-foray" class="anchor"></a>2 First Foray</h1>
<div id="loading-the-first-text-file" class="section level2">
<h2 class="hasAnchor">
<a href="#loading-the-first-text-file" class="anchor"></a>2.1 Loading the first text file</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(quanteda)</code></pre></div>
<p>We can load the text from <em>Moby Dick</em> using the <strong>readtext</strong> package, directly from the <a href="https://www.gutenberg.org/ebooks/2701">Project Gutenberg website</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(readtext)
data_char_mobydick &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/texts.html">texts</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/readtext/topics/readtext">readtext</a></span>(<span class="st">"http://www.gutenberg.org/cache/epub/2701/pg2701.txt"</span>))
<span class="kw">names</span>(data_char_mobydick) &lt;-<span class="st"> "mobydick"</span></code></pre></div>
<p>The <code><a href="http://www.rdocumentation.org/packages/readtext/topics/readtext">readtext()</a></code> function from the <strong>readtext</strong> package loads the text files into a <code>data.frame</code> object. We can access the text from a <code>data.frame</code> object (and also, as we will see, a <code>corpus</code> class object), using the <code><a href="../../../reference/texts.html">texts()</a></code> or the <code><a href="../../../reference/View.html">View()</a></code> method. Here we will display just the first 75 characters, to prevent a massive dump of the text of the entire novel. We do this using the <code><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub()</a></code> function from the <strong>stringi</strong> package, which shows the 1st through the 75th characters of the texts of our new object <code>data_char_mobydick</code>. Because we have not assigned the return from this command to any object, it invokes a print method for character objects, and is displayed on the screen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(stringi)
<span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub</a></span>(data_char_mobydick, <span class="dv">1</span>, <span class="dv">75</span>)</code></pre></div>
<pre><code>## [1] "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville\n"</code></pre>
</div>
<div id="separate-content-from-metadata" class="section level2">
<h2 class="hasAnchor">
<a href="#separate-content-from-metadata" class="anchor"></a>2.2 Separate content from metadata</h2>
<p>The Gutenburg edition of the text contains some metadata before and after the text of the novel. The code below uses the <code>regexec</code> and <code>substring</code> functions to separate this from the text.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># extract the header information</span>
(start_v &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_locate">stri_locate_first_fixed</a></span>(data_char_mobydick, <span class="st">"CHAPTER 1. Loomings."</span>)[<span class="dv">1</span>])</code></pre></div>
<pre><code>## [1] 23018</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(end_v &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_locate">stri_locate_last_fixed</a></span>(data_char_mobydick, <span class="st">"orphan."</span>)[<span class="dv">1</span>])</code></pre></div>
<pre><code>## [1] 1216393</code></pre>
<p>Here, we found the character index of the beginning and end of the novel, rather than counting the lines as in the book, but the result will be very similar. If we want to verify that “orpan.” is the end of the novel, we can use the <code><a href="../../../reference/kwic.html">kwic()</a></code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># verify that "orphan" is the end of the novel</span>
<span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(data_char_mobydick, <span class="st">"orphan"</span>)</code></pre></div>
<pre><code>##                                                            
##  [mobydick, 255352] children, only found another | orphan |
##                              
##  . End of Project Gutenberg's</code></pre>
<p>If we want to count the number of lines, we can do so by counting the newlines in the text.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_count">stri_count_fixed</a></span>(data_char_mobydick, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</code></pre></div>
<pre><code>## [1] 22107</code></pre>
<p>To measure just the number lines in the novel itself, without the metadata, we can subset the text from the start and end of the novel part, as identified above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub</a></span>(data_char_mobydick, <span class="dt">from =</span> start_v, <span class="dt">to =</span> end_v) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_count">stri_count_fixed</a></span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</code></pre></div>
<pre><code>## [1] 21206</code></pre>
<p>To trim the non-book content, we use <code><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub()</a></code> to extract the text between the beginning and ending indexes found above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">novel_v &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub</a></span>(data_char_mobydick, start_v, end_v)
<span class="kw">length</span>(novel_v)</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub</a></span>(novel_v, <span class="dv">1</span>, <span class="dv">94</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">cat</span>()</code></pre></div>
<pre><code>## CHAPTER 1. Loomings.
## 
## 
## Call me Ishmael. Some years ago--never mind how long precisely--having</code></pre>
</div>
<div id="reprocessing-the-content" class="section level2">
<h2 class="hasAnchor">
<a href="#reprocessing-the-content" class="anchor"></a>2.3 Reprocessing the content</h2>
<p>We begin processing the text by converting to lower case. <strong>quanteda</strong>’s <code>*_tolower()</code> functions work like the built-in <code>tolower()</code>, with an extra option to preserve upper-case acronyms when detected. For <code>character</code> objects, we use <code><a href="../../../reference/char_tolower.html">char_tolower()</a></code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># lowercase text</span>
novel_lower_v &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/char_tolower.html">char_tolower</a></span>(novel_v)</code></pre></div>
<p><strong>quanteda</strong>’s <code><a href="../../../reference/tokens.html">tokens()</a></code> function splits the text into words, with many options available for which characters should be preserved, and which should be used to define word boundaries. The default behaviour works similarly to splitting on the regular expression for non-word characters (<code>\W</code> as in the book), but it much smarter. For instance, it does not treat apostrophes as word boundaries, meaning that <code>'s</code> and <code>'t</code> are not treated as whole words from possessive forms and contractions.</p>
<p>We will skip straight to getting the character vector of tokens:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">moby_word_v &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/tokens.html">tokens</a></span>(novel_lower_v, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.character</span>()
(total_length &lt;-<span class="st"> </span><span class="kw">length</span>(moby_word_v))</code></pre></div>
<pre><code>## [1] 210000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">moby_word_v[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]</code></pre></div>
<pre><code>##  [1] "chapter"  "1"        "loomings" "call"     "me"       "ishmael" 
##  [7] "some"     "years"    "ago"      "never"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">moby_word_v[<span class="dv">99986</span>] </code></pre></div>
<pre><code>## [1] "in"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">moby_word_v[<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>)]</code></pre></div>
<pre><code>## [1] "call"    "me"      "ishmael"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># check positions of "whale"</span>
<span class="kw">which</span>(moby_word_v <span class="op">==</span><span class="st"> "whale"</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>## [1] 2030 2060 2203 2415 4048 4211</code></pre>
</div>
<div id="beginning-the-analysis" class="section level2">
<h2 class="hasAnchor">
<a href="#beginning-the-analysis" class="anchor"></a>2.4 Beginning the analysis</h2>
<p>The code below uses the tokenized text to the occurrence of the word <em>whale</em>. To include the possessive form <em>whale’s</em>, we may sum the counts of both forms, count the keyword-in-context matches by regular expression or glob. A <em>glob</em> is a simple wildcard matching pattern common on Unix systems – asterisks match zero or more characters.</p>
<p>Note that the counts below do not match those in the book, due to differences in how the book has split on any non-word character, while <strong>quanteda</strong>’s tokenizer splits on a more comprehensive set of “word boundaries”. <strong>quanteda</strong>’s <code><a href="../../../reference/tokens.html">tokens()</a></code> function by default does not remove punctuation or numbers (both defined as “non-word” characters) by default. To more closely match the counts in the book, we have removed punctuation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(moby_word_v[<span class="kw">which</span>(moby_word_v <span class="op">==</span><span class="st"> "whale"</span>)])</code></pre></div>
<pre><code>## [1] 908</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># total occurrences of "whale" including possessive</span>
<span class="kw">length</span>(moby_word_v[<span class="kw">which</span>(moby_word_v <span class="op">==</span><span class="st"> "whale"</span>)]) <span class="op">+</span><span class="st"> </span><span class="kw">length</span>(moby_word_v[<span class="kw">which</span>(moby_word_v <span class="op">==</span><span class="st"> "whale's"</span>)])</code></pre></div>
<pre><code>## [1] 1028</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># same thing using kwic()</span>
<span class="kw">nrow</span>(<span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_lower_v, <span class="st">"whale"</span>))</code></pre></div>
<pre><code>## [1] 908</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nrow</span>(<span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_lower_v, <span class="st">"whale*"</span>)) <span class="co"># includes words like "whalemen"</span></code></pre></div>
<pre><code>## [1] 1565</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(total_whale_hits &lt;-<span class="st"> </span><span class="kw">nrow</span>(<span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_lower_v, <span class="dt">pattern =</span> <span class="st">"^whale('s){0,1}$"</span>, <span class="dt">valuetype =</span> <span class="st">"regex"</span>)))</code></pre></div>
<pre><code>## [1] 1028</code></pre>
<p>What fraction of the total words (excluding punctuation) in the novel are “whale”?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">total_whale_hits <span class="op">/</span><span class="st"> </span><span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(novel_lower_v, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>)  </code></pre></div>
<pre><code>##       text1 
## 0.004895238</code></pre>
<p>With <code><a href="../../../reference/ntoken.html">ntype()</a></code> we can calculate the size of the vocabulary – includes possessive forms, but excludes punctuation, symbols and numbers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># total unique words</span>
<span class="kw">length</span>(<span class="kw">unique</span>(moby_word_v))</code></pre></div>
<pre><code>## [1] 18524</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/ntoken.html">ntype</a></span>(<span class="kw"><a href="../../../reference/char_tolower.html">char_tolower</a></span>(novel_v), <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## text1 
## 18524</code></pre>
<p>To quickly sort the word types by their frequency, we can use the <code><a href="../../../reference/dfm.html">dfm()</a></code> command to create a matrix of counts of each word type – a document-frequency matrix. In this case there is only one document, the entire book.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ten most frequent words</span>
moby_dfm &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(novel_lower_v, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>)
<span class="kw">head</span>(moby_dfm, <span class="dt">nfeature =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>## Warning in head.dfm(moby_dfm, nfeature = 10): Argument nfeature not used.</code></pre>
<pre><code>## Document-feature matrix of: 1 document, 18,524 features (0% sparse).</code></pre>
<p>Getting the list of the most frequent 10 terms is easy, using <code><a href="../../../reference/textstat_frequency.html">textstat_frequency()</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/textstat_frequency.html">textstat_frequency</a></span>(moby_dfm, <span class="dt">n =</span> <span class="dv">10</span>) </code></pre></div>
<pre><code>##    feature frequency rank docfreq group
## 1      the     14173    1       1   all
## 2       of      6446    2       1   all
## 3      and      6311    3       1   all
## 4        a      4605    4       1   all
## 5       to      4511    5       1   all
## 6       in      4071    6       1   all
## 7     that      2950    7       1   all
## 8      his      2495    8       1   all
## 9       it      2394    9       1   all
## 10       i      1976   10       1   all</code></pre>
<p>Finally, if we wish to plot the most frequent (50) terms, we can supply the results of <code><a href="../../../reference/textstat_frequency.html">textstat_frequency()</a></code> to <code><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot()</a></code> to plot their frequency by their rank:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot frequency of 50 most frequent terms </span>
<span class="kw">library</span>(ggplot2)
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/theme_get">theme_set</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggtheme">theme_minimal</a></span>())
<span class="kw"><a href="../../../reference/textstat_frequency.html">textstat_frequency</a></span>(moby_dfm, <span class="dt">n =</span> <span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> rank, <span class="dt">y =</span> frequency)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_point">geom_point</a></span>() <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Frequency rank"</span>, <span class="dt">y =</span> <span class="st">"Term frequency"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-17-1.png" width="768"></p>
<p>For direct comparison with the next chapter, we also create the sorted list of the most frequently found words using this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sorted_moby_freqs_t &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/topfeatures.html">topfeatures</a></span>(moby_dfm, <span class="dt">n =</span> <span class="kw"><a href="../../../reference/ndoc.html">nfeature</a></span>(moby_dfm))</code></pre></div>
<pre><code>## Warning: 'nfeature' is deprecated.
## Use 'nfeat' instead.
## See help("Deprecated")</code></pre>
</div>
</div>
<div id="accessing-and-comparing-word-frequency-data" class="section level1">
<h1 class="hasAnchor">
<a href="#accessing-and-comparing-word-frequency-data" class="anchor"></a>3 Accessing and Comparing Word Frequency Data</h1>
<div id="accessing-word-data" class="section level2">
<h2 class="hasAnchor">
<a href="#accessing-word-data" class="anchor"></a>3.1 Accessing Word Data</h2>
<p>We can query the document-frequency matrix to retrieve word frequencies, as with a normal matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># frequencies of "he" and "she" - these are matrixes, not numerics</span>
sorted_moby_freqs_t[<span class="kw">c</span>(<span class="st">"he"</span>, <span class="st">"she"</span>, <span class="st">"him"</span>, <span class="st">"her"</span>)]</code></pre></div>
<pre><code>##   he  she  him  her 
## 1758  112 1058  330</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># another method: indexing the dfm</span>
moby_dfm[, <span class="kw">c</span>(<span class="st">"he"</span>, <span class="st">"she"</span>, <span class="st">"him"</span>, <span class="st">"her"</span>)]</code></pre></div>
<pre><code>## Document-feature matrix of: 1 document, 4 features (0% sparse).
## 1 x 4 sparse Matrix of class "dfm"
##        features
## docs      he she  him her
##   text1 1758 112 1058 330</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sorted_moby_freqs_t[<span class="dv">1</span>]</code></pre></div>
<pre><code>##   the 
## 14173</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sorted_moby_freqs_t[<span class="st">"the"</span>]</code></pre></div>
<pre><code>##   the 
## 14173</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># term frequency ratios</span>
sorted_moby_freqs_t[<span class="st">"him"</span>] <span class="op">/</span><span class="st"> </span>sorted_moby_freqs_t[<span class="st">"her"</span>]</code></pre></div>
<pre><code>##      him 
## 3.206061</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sorted_moby_freqs_t[<span class="st">"he"</span>] <span class="op">/</span><span class="st"> </span>sorted_moby_freqs_t[<span class="st">"she"</span>]</code></pre></div>
<pre><code>##       he 
## 15.69643</code></pre>
<p>Total number of tokens:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(moby_dfm)</code></pre></div>
<pre><code>##  text1 
## 210000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(sorted_moby_freqs_t)</code></pre></div>
<pre><code>## [1] 210000</code></pre>
</div>
<div id="recycling" class="section level2">
<h2 class="hasAnchor">
<a href="#recycling" class="anchor"></a>3.2 Recycling</h2>
<p>Relative term frequencies:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sorted_moby_rel_freqs_t &lt;-<span class="st"> </span>sorted_moby_freqs_t <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(sorted_moby_freqs_t) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>
sorted_moby_rel_freqs_t[<span class="st">"the"</span>]</code></pre></div>
<pre><code>##      the 
## 6.749048</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># by weighting the dfm directly</span>
moby_dfm_pct &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_weight.html">dfm_weight</a></span>(moby_dfm, <span class="dt">scheme =</span> <span class="st">"prop"</span>) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>
moby_dfm_pct[, <span class="st">"the"</span>]</code></pre></div>
<pre><code>## Document-feature matrix of: 1 document, 1 feature (0% sparse).
## 1 x 1 sparse Matrix of class "dfm"
##        features
## docs         the
##   text1 6.749048</code></pre>
<p>Plotting the most frequent terms, replicating the plot from the book:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(sorted_moby_rel_freqs_t[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>], <span class="dt">type =</span> <span class="st">"b"</span>,
     <span class="dt">xlab =</span> <span class="st">"Top Ten Words"</span>, <span class="dt">ylab =</span> <span class="st">"Percentage of Full Text"</span>, <span class="dt">xaxt =</span> <span class="st">"n"</span>)
<span class="kw">axis</span>(<span class="dv">1</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">labels =</span> <span class="kw">names</span>(sorted_moby_rel_freqs_t[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]))</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-22-1.png" width="700"></p>
<p>Plotting the most frequent terms using <strong>ggplot2</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/textstat_frequency.html">textstat_frequency</a></span>(moby_dfm_pct, <span class="dt">n =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> <span class="kw">reorder</span>(feature, <span class="op">-</span>rank), <span class="dt">y =</span> frequency)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_bar">geom_bar</a></span>(<span class="dt">stat =</span> <span class="st">"identity"</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/coord_flip">coord_flip</a></span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">""</span>, <span class="dt">y =</span> <span class="st">"Term Frequency as a Percentage"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
</div>
</div>
<div id="token-distribution-analysis" class="section level1">
<h1 class="hasAnchor">
<a href="#token-distribution-analysis" class="anchor"></a>4 Token Distribution Analysis</h1>
<div id="dispersion-plots" class="section level2">
<h2 class="hasAnchor">
<a href="#dispersion-plots" class="anchor"></a>4.1 Dispersion plots</h2>
<p>A dispersion plot allows us to visualize the occurrences of particular terms throughout the text. The object returned by the <code>kwic</code> function can be plotted to display a dispersion plot. The <strong>quanteda</strong> <code>textplot_</code> objects are based on <strong>ggplot2</strong>, so you can easily change the plot, for example by adding custom title.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># using words from tokenized corpus for dispersion</span>
<span class="kw"><a href="../../../reference/textplot_xray.html">textplot_xray</a></span>(<span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_v, <span class="st">"whale"</span>)) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">ggtitle</a></span>(<span class="st">"Lexical dispersion"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-24-1.png" width="768"></p>
<p>To produce multiple dispersion plots for comparison, you can simply send more than one <code><a href="../../../reference/kwic.html">kwic()</a></code> output to <code><a href="../../../reference/textplot_xray.html">textplot_xray()</a></code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/textplot_xray.html">textplot_xray</a></span>(
     <span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_v, <span class="st">"whale"</span>),
     <span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_v, <span class="st">"Ahab"</span>)
) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">ggtitle</a></span>(<span class="st">"Lexical dispersion"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-25-1.png" width="768"></p>
</div>
<div id="searching-with-regular-expression" class="section level2">
<h2 class="hasAnchor">
<a href="#searching-with-regular-expression" class="anchor"></a>4.2 Searching with regular expression</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># identify the chapter break locations</span>
chap_positions_v &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(novel_v, <span class="kw"><a href="../../../reference/phrase.html">phrase</a></span>(<span class="kw">c</span>(<span class="st">"CHAPTER </span><span class="ch">\\</span><span class="st">d"</span>)), <span class="dt">valuetype =</span> <span class="st">"regex"</span>)<span class="op">$</span>from
<span class="kw">head</span>(chap_positions_v)</code></pre></div>
<pre><code>## [1]     1  2581  4287 11236 13169 14043</code></pre>
</div>
<div id="identifying-chapter-breaks" class="section level2">
<h2 class="hasAnchor">
<a href="#identifying-chapter-breaks" class="anchor"></a>4.2 Identifying chapter breaks</h2>
<p>Splitting the text into chapters means that we will have a collection of documents, which makes this a good time to make a <code>corpus</code> object to hold the texts. Initially, we make a single-document corpus, and then use the <code><a href="../../../reference/corpus_segment.html">char_segment()</a></code> function to split this by the string which specifies the chapter breaks.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapters_corp &lt;-<span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../../reference/corpus.html">corpus</a></span>(data_char_mobydick) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw"><a href="../../../reference/corpus_segment.html">corpus_segment</a></span>(<span class="dt">pattern =</span> <span class="st">"CHAPTER</span><span class="ch">\\</span><span class="st">s</span><span class="ch">\\</span><span class="st">d+.*</span><span class="ch">\\</span><span class="st">n"</span>, <span class="dt">valuetype =</span> <span class="st">"regex"</span>)
<span class="kw">summary</span>(chapters_corp, <span class="dv">10</span>)</code></pre></div>
<pre><code>## Corpus consisting of 136 documents, showing 10 documents:
## 
##         Text Types Tokens Sentences                       pattern
##   mobydick.1   917   2575       101        CHAPTER 1. Loomings.\n
##   mobydick.2   651   1700        60  CHAPTER 2. The Carpet-Bag.\n
##   mobydick.3  1744   6943       264 CHAPTER 3. The Spouter-Inn.\n
##   mobydick.4   681   1927        54 CHAPTER 4. The Counterpane.\n
##   mobydick.5   405    869        29       CHAPTER 5. Breakfast.\n
##   mobydick.6   466    942        44      CHAPTER 6. The Street.\n
##   mobydick.7   519   1082        40      CHAPTER 7. The Chapel.\n
##   mobydick.8   478   1080        29      CHAPTER 8. The Pulpit.\n
##   mobydick.9  1260   4284       166      CHAPTER 9. The Sermon.\n
##  mobydick.10   658   1804        66 CHAPTER 10. A Bosom Friend.\n
## 
## Source: /home/kohei/packages/quanteda/vignettes/pkgdown/replication/* on x86_64 by kohei
## Created: Tue Jun  5 10:29:41 2018
## Notes: corpus_segment.corpus(., pattern = "CHAPTER\\s\\d+.*\\n", valuetype = "regex")</code></pre>
<p>The titles are automatically extracted into the <code>pattern</code> document variables, and the text of each chapter becomes the text of each new document unit. To tidy this up, we can remove the trailing <code>\n</code> character, using <code><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_trim">stri_trim_right()</a></code>, since the <code>\n</code> is a member of the “whitespace” group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(chapters_corp, <span class="st">"pattern"</span>) &lt;-<span class="st"> </span>stringi<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_trim">stri_trim_right</a></span>(<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(chapters_corp, <span class="st">"pattern"</span>))
<span class="kw">summary</span>(chapters_corp, <span class="dt">n =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>## Corpus consisting of 136 documents, showing 3 documents:
## 
##        Text Types Tokens Sentences                     pattern
##  mobydick.1   917   2575       101        CHAPTER 1. Loomings.
##  mobydick.2   651   1700        60  CHAPTER 2. The Carpet-Bag.
##  mobydick.3  1744   6943       264 CHAPTER 3. The Spouter-Inn.
## 
## Source: /home/kohei/packages/quanteda/vignettes/pkgdown/replication/* on x86_64 by kohei
## Created: Tue Jun  5 10:29:41 2018
## Notes: corpus_segment.corpus(., pattern = "CHAPTER\\s\\d+.*\\n", valuetype = "regex")</code></pre>
<p>For better reference, let’s also rename the document labels with these chapter headings:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/docnames.html">docnames</a></span>(chapters_corp) &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(chapters_corp, <span class="st">"pattern"</span>)</code></pre></div>
<div id="barplots-of-whale-and-ahab" class="section level3">
<h3 class="hasAnchor">
<a href="#barplots-of-whale-and-ahab" class="anchor"></a>4.4.5 barplots of whale and ahab</h3>
<p>With the corpus split into chapters, we can use the <code><a href="../../../reference/dfm.html">dfm()</a></code> function to create a matrix of counts of each word in each chapter – a document-frequency matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create a dfm</span>
chap_dfm &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(chapters_corp)

<span class="co"># extract row with count for "whale"/"ahab" in each chapter</span>
<span class="co"># and convert to data frame for plotting</span>
whales_ahabs_df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(chap_dfm[, <span class="kw">c</span>(<span class="st">"whale"</span>, <span class="st">"ahab"</span>)])</code></pre></div>
<pre><code>## Warning: 'as.data.frame.dfm' is deprecated.
## Use 'convert(x, to "data.frame")' instead.
## See help("Deprecated")</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">whales_ahabs_df<span class="op">$</span>chapter &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(whales_ahabs_df)

<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="dt">data =</span> whales_ahabs_df, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> chapter, <span class="dt">y =</span> whale)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_bar">geom_bar</a></span>(<span class="dt">stat =</span> <span class="st">"identity"</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Chapter"</span>, 
         <span class="dt">y =</span> <span class="st">"Frequency"</span>,
         <span class="dt">title =</span> <span class="st">'Occurrence of "whale"'</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-30-1.png" width="768"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="dt">data =</span> whales_ahabs_df, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> chapter, <span class="dt">y =</span> ahab)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_bar">geom_bar</a></span>(<span class="dt">stat =</span> <span class="st">"identity"</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Chapter"</span>, 
         <span class="dt">y =</span> <span class="st">"Frequency"</span>,
         <span class="dt">title =</span> <span class="st">'Occurrence of "ahab"'</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-30-2.png" width="768"></p>
<p>The above plots are raw frequency plots. For relative frequency plots, (word count divided by the length of the chapter) we can weight the document-frequency matrix. To obtain expected word frequency per 100 words, we multiply by 100. To get a feel for what the resulting weighted dfm (document-feature matrix) looks like, you can inspect it with the <code>head</code> function, which prints the first few rows and columns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rel_dfm &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_weight.html">dfm_weight</a></span>(chap_dfm, <span class="dt">scheme =</span> <span class="st">"prop"</span>) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>
<span class="kw">head</span>(rel_dfm)</code></pre></div>
<pre><code>## Document-feature matrix of: 6 documents, 18,629 features (95.9% sparse).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># subset dfm and convert to data.frame object</span>
rel_chap_freq &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(rel_dfm[, <span class="kw">c</span>(<span class="st">"whale"</span>, <span class="st">"ahab"</span>)])</code></pre></div>
<pre><code>## Warning: 'as.data.frame.dfm' is deprecated.
## Use 'convert(x, to "data.frame")' instead.
## See help("Deprecated")</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rel_chap_freq<span class="op">$</span>chapter &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(rel_chap_freq)
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="dt">data =</span> rel_chap_freq, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> chapter, <span class="dt">y =</span> whale)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_bar">geom_bar</a></span>(<span class="dt">stat =</span> <span class="st">"identity"</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Chapter"</span>, <span class="dt">y =</span> <span class="st">"Relative frequency"</span>,
         <span class="dt">title =</span> <span class="st">'Occurrence of "whale"'</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-31-1.png" width="768"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="dt">data =</span> rel_chap_freq, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> chapter, <span class="dt">y =</span> ahab)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_bar">geom_bar</a></span>(<span class="dt">stat =</span> <span class="st">"identity"</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Chapter"</span>, <span class="dt">y =</span> <span class="st">"Relative frequency"</span>,
         <span class="dt">title =</span> <span class="st">'Occurrence of "ahab"'</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-31-2.png" width="768"></p>
</div>
</div>
</div>
<div id="correlation" class="section level1">
<h1 class="hasAnchor">
<a href="#correlation" class="anchor"></a>5 Correlation</h1>
<div id="correlation-analysis" class="section level2">
<h2 class="hasAnchor">
<a href="#correlation-analysis" class="anchor"></a>5.2 Correlation Analysis</h2>
<p>Correlation analysis (and many other similarity measures) can be constructed using fast, sparse means through the <code><a href="../../../reference/textstat_simil.html">textstat_simil()</a></code> function. Here, we select feature comparisons for just “whale” and “ahab”, and convert this into a matrix as in the book. Because correlations are sensitive to document length, we first convert this into a relative frequency using <code><a href="../../../reference/dfm_weight.html">dfm_weight()</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/dfm_weight.html">dfm_weight</a></span>(chap_dfm, <span class="dt">scheme =</span> <span class="st">"prop"</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../../reference/textstat_simil.html">textstat_simil</a></span>(<span class="dt">selection =</span> <span class="kw">c</span>(<span class="st">"whale"</span>, <span class="st">"ahab"</span>), <span class="dt">method =</span> <span class="st">"correlation"</span>, <span class="dt">margin =</span> <span class="st">"features"</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">as.matrix</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">head</span>(<span class="dv">2</span>)</code></pre></div>
<pre><code>##           whale       ahab
## call  0.1207825 -0.1057048
## me   -0.2505902  0.1624160</code></pre>
<p>With the ahab frequency and whale frequency vectors extracted from the dfm, it is easy to calculate the significance of the correlation.</p>
</div>
<div id="testing-correlation-with-randomization" class="section level2">
<h2 class="hasAnchor">
<a href="#testing-correlation-with-randomization" class="anchor"></a>5.4 Testing Correlation with Randomization</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cor_data_df &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_weight.html">dfm_weight</a></span>(chap_dfm, <span class="dt">scheme =</span> <span class="st">"prop"</span>)[, <span class="kw">c</span>(<span class="st">"ahab"</span>, <span class="st">"whale"</span>)] <span class="op">%&gt;%</span>
<span class="st">    </span>as.data.frame</code></pre></div>
<pre><code>## Warning: 'as.data.frame.dfm' is deprecated.
## Use 'convert(x, to "data.frame")' instead.
## See help("Deprecated")</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># sample 1000 replicates and create data frame</span>
n &lt;-<span class="st"> </span><span class="dv">1000</span>
samples &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">cor_sample =</span> <span class="kw">replicate</span>(n, <span class="kw">cor</span>(<span class="kw">sample</span>(cor_data_df<span class="op">$</span>whale), cor_data_df<span class="op">$</span>ahab)),
    <span class="dt">id_sample =</span> <span class="dv">1</span><span class="op">:</span>n
)

<span class="co"># plot distribution of resampled correlations</span>
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="dt">data =</span> samples, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> cor_sample, <span class="dt">y =</span> ..density..)) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_histogram">geom_histogram</a></span>(<span class="dt">colour =</span> <span class="st">"black"</span>, <span class="dt">binwidth =</span> <span class="fl">0.01</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_density">geom_density</a></span>(<span class="dt">colour =</span> <span class="st">"red"</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Correlation Coefficient"</span>, <span class="dt">y =</span> <span class="ot">NULL</span>,
         <span class="dt">title =</span> <span class="st">"Histogram of Random Correlation Coefficients with Normal Curve"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-33-1.png" width="768"></p>
</div>
</div>
<div id="measures-of-lexical-variety" class="section level1">
<h1 class="hasAnchor">
<a href="#measures-of-lexical-variety" class="anchor"></a>6 Measures of Lexical Variety</h1>
<div id="mean-word-frequency" class="section level2">
<h2 class="hasAnchor">
<a href="#mean-word-frequency" class="anchor"></a>6.2 Mean word frequency</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># length of the book in chapters</span>
<span class="kw"><a href="../../../reference/ndoc.html">ndoc</a></span>(chapters_corp)</code></pre></div>
<pre><code>## [1] 136</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># chapter names</span>
<span class="kw"><a href="../../../reference/docnames.html">docnames</a></span>(chapters_corp) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>## [1] "CHAPTER 1. Loomings."        "CHAPTER 2. The Carpet-Bag." 
## [3] "CHAPTER 3. The Spouter-Inn." "CHAPTER 4. The Counterpane."
## [5] "CHAPTER 5. Breakfast."       "CHAPTER 6. The Street."</code></pre>
<p>Calculating the mean word frequencies is easy:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># for first few chapters</span>
<span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(chapters_corp) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##        CHAPTER 1. Loomings.  CHAPTER 2. The Carpet-Bag. 
##                        2575                        1700 
## CHAPTER 3. The Spouter-Inn. CHAPTER 4. The Counterpane. 
##                        6943                        1927 
##       CHAPTER 5. Breakfast.      CHAPTER 6. The Street. 
##                         869                         942</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># average</span>
(<span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(chapters_corp) <span class="op">/</span><span class="st"> </span><span class="kw"><a href="../../../reference/ntoken.html">ntype</a></span>(chapters_corp)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##        CHAPTER 1. Loomings.  CHAPTER 2. The Carpet-Bag. 
##                    2.808070                    2.611367 
## CHAPTER 3. The Spouter-Inn. CHAPTER 4. The Counterpane. 
##                    3.981078                    2.829662 
##       CHAPTER 5. Breakfast.      CHAPTER 6. The Street. 
##                    2.145679                    2.021459</code></pre>
</div>
<div id="extracting-word-usage-means" class="section level2">
<h2 class="hasAnchor">
<a href="#extracting-word-usage-means" class="anchor"></a>6.3 Extracting Word Usage Means</h2>
<p>Since the quotient of the number of tokens and number of types is a vector, we can simply feed this to <code>plot()</code> using the pipe operator:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(chapters_corp) <span class="op">/</span><span class="st"> </span><span class="kw"><a href="../../../reference/ntoken.html">ntype</a></span>(chapters_corp)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">plot</span>(<span class="dt">type =</span> <span class="st">"h"</span>, <span class="dt">ylab =</span> <span class="st">"Mean word frequency"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-36-1.png" width="768"></p>
<p>For the scaled plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(chapters_corp) <span class="op">/</span><span class="st"> </span><span class="kw"><a href="../../../reference/ntoken.html">ntype</a></span>(chapters_corp)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">scale</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">plot</span>(<span class="dt">type =</span> <span class="st">"h"</span>, <span class="dt">ylab =</span> <span class="st">"Scaled mean word frequency"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-37-1.png" width="768"></p>
</div>
<div id="ranking-the-values" class="section level2">
<h2 class="hasAnchor">
<a href="#ranking-the-values" class="anchor"></a>6.4 Ranking the values</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean_word_use_m &lt;-<span class="st"> </span>(<span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(chapters_corp) <span class="op">/</span><span class="st"> </span><span class="kw"><a href="../../../reference/ntoken.html">ntype</a></span>(chapters_corp))
<span class="kw">sort</span>(mean_word_use_m, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>## CHAPTER 135. The Chase.--Third Day.    CHAPTER 54. The Town-Ho's Story. 
##                            4.169544                            4.150151 
##               CHAPTER 16. The Ship.         CHAPTER 3. The Spouter-Inn. 
##                            4.051861                            3.981078 
##               CHAPTER 32. Cetology.         CHAPTER 64. Stubb's Supper. 
##                            3.542857                            3.468721</code></pre>
</div>
<div id="calculating-the-ttr" class="section level2">
<h2 class="hasAnchor">
<a href="#calculating-the-ttr" class="anchor"></a>6.5 Calculating the TTR</h2>
<p>Measures of lexical diversity can be estimated using <code><a href="../../../reference/textstat_lexdiv.html">textstat_lexdiv()</a></code>. The TTR (Type-Token Ratio), a measure used in section 6.5, can be calculcated for each document of the <code>dfm</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(chapters_corp) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../../reference/textstat_lexdiv.html">textstat_lexdiv</a></span>(<span class="dt">measure =</span> <span class="st">"TTR"</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">head</span>(<span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##                       document       TTR
## 1         CHAPTER 1. Loomings. 0.3332039
## 2   CHAPTER 2. The Carpet-Bag. 0.3688235
## 3  CHAPTER 3. The Spouter-Inn. 0.2376494
## 4  CHAPTER 4. The Counterpane. 0.3435392
## 5        CHAPTER 5. Breakfast. 0.4453395
## 6       CHAPTER 6. The Street. 0.4702760
## 7       CHAPTER 7. The Chapel. 0.4528651
## 8       CHAPTER 8. The Pulpit. 0.4314815
## 9       CHAPTER 9. The Sermon. 0.2789449
## 10 CHAPTER 10. A Bosom Friend. 0.3481153</code></pre>
</div>
</div>
<div id="hapax-richness" class="section level1">
<h1 class="hasAnchor">
<a href="#hapax-richness" class="anchor"></a>7 Hapax Richness</h1>
<p>Another measure of lexical diversity is Hapax richness, defined as the number of words that occur only once divided by the total number of words. We can calculate Hapax richness very simply by using a logical operation on the document-feature matrix, to return a logical value for each term that occurs once, and then sum these to get a count.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># hapaxes per document</span>
<span class="kw">rowSums</span>(chap_dfm <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##        CHAPTER 1. Loomings.  CHAPTER 2. The Carpet-Bag. 
##                         609                         437 
## CHAPTER 3. The Spouter-Inn. CHAPTER 4. The Counterpane. 
##                        1084                         464 
##       CHAPTER 5. Breakfast.      CHAPTER 6. The Street. 
##                         276                         343</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># as a proportion</span>
hapax_proportion &lt;-<span class="st"> </span><span class="kw">rowSums</span>(chap_dfm <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="kw"><a href="../../../reference/ntoken.html">ntoken</a></span>(chap_dfm)
<span class="kw">head</span>(hapax_proportion)</code></pre></div>
<pre><code>##        CHAPTER 1. Loomings.  CHAPTER 2. The Carpet-Bag. 
##                   0.2365049                   0.2570588 
## CHAPTER 3. The Spouter-Inn. CHAPTER 4. The Counterpane. 
##                   0.1561285                   0.2407888 
##       CHAPTER 5. Breakfast.      CHAPTER 6. The Street. 
##                   0.3176064                   0.3641189</code></pre>
<p>To plot this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">barplot</span>(hapax_proportion, <span class="dt">beside =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">"grey"</span>, <span class="dt">names.arg =</span> <span class="kw">seq_len</span>(<span class="kw"><a href="../../../reference/ndoc.html">ndoc</a></span>(chap_dfm)))</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-41-1.png" width="768"></p>
</div>
<div id="do-it-kwic" class="section level1">
<h1 class="hasAnchor">
<a href="#do-it-kwic" class="anchor"></a>8 Do it KWIC</h1>
<p>For this, and the next chapter, we simply use <strong>quanteda</strong>’s excellent <code><a href="../../../reference/kwic.html">kwic()</a></code> function. To find the indexes of the token positions for “gutenberg”, for instance, we use the following, which returns a data.frame with the name <code>from</code> indicating the index position of the start of the token match:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gutenberg_kwic &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(data_char_mobydick, <span class="dt">pattern =</span> <span class="st">"gutenberg"</span>)
<span class="kw">head</span>(gutenberg_kwic<span class="op">$</span>from, <span class="dv">10</span>)</code></pre></div>
<pre><code>##  [1]      3     52    108 255375 255538 255650 255697 255891 256007 256105</code></pre>
</div>
<div id="do-it-kwic-better" class="section level1">
<h1 class="hasAnchor">
<a href="#do-it-kwic-better" class="anchor"></a>9 Do it KWIC (Better)</h1>
<p>This is going to be super easy since we don’t need to reinvent the wheel here, since <code><a href="../../../reference/kwic.html">kwic()</a></code> already does all that we need.</p>
<p>Let’s create a corpus containing <em>Moby Dick</em> but also Jane Austen’s <em>Sense and Sensibility</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_char_senseandsensibility &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/texts.html">texts</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/readtext/topics/readtext">readtext</a></span>(<span class="st">"http://www.gutenberg.org/files/161/161.txt"</span>))
litcorpus &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/corpus.html">corpus</a></span>(<span class="kw">c</span>(data_char_mobydick, <span class="dt">austen =</span> data_char_senseandsensibility))</code></pre></div>
<p>Now we can use <code><a href="../../../reference/kwic.html">kwic()</a></code> to find out where in each novel this occurred:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(dogkwic &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/kwic.html">kwic</a></span>(litcorpus, <span class="st">"dog"</span>))</code></pre></div>
<pre><code>##                                                                 
##        [mobydick, 17213]    all over like a Newfoundland | dog |
##        [mobydick, 31814]        was seen swimming like a | dog |
##        [mobydick, 59904]                       .-- Down, | dog |
##        [mobydick, 60005]          not tamely be called a | dog |
##        [mobydick, 60528]             didn't he call me a | dog |
##        [mobydick, 86935]   sacrifice of the sacred White | Dog |
##       [mobydick, 125588]            life that lives in a | dog |
##       [mobydick, 125684]   the sagacious kindness of the | dog |
##       [mobydick, 159443] " The ungracious and ungrateful | dog |
##       [mobydick, 159485]           Give way, greyhounds! | Dog |
##       [mobydick, 170812]             to the whale that a | dog |
##       [mobydick, 194020]             the Ram-- lecherous | dog |
##       [mobydick, 197596]                  .( Bunger, you | dog |
##       [mobydick, 198082]              die in pickle, you | dog |
##       [mobydick, 198711]                Ahab, and like a | dog |
##       [mobydick, 240998]       air as a sagacious ship's | dog |
##  [austen.161.txt, 78321]        fellow! such a deceitful | dog |
##                            
##  just from the water,      
##  , throwing his long arms  
##  , and kennel!"            
##  , sir.""                  
##  ? blazes! he called       
##  was by far the holiest    
##  or a horse. Indeed        
##  ? The accursed shark alone
##  !" cried Starbuck;        
##  to it!""                  
##  does to the elephant;     
##  , he begets us;           
##  , laugh out! why          
##  ; you should be preserved 
##  , strangely snuffing;"    
##  will, in drawing nigh     
##  ! It was only the</code></pre>
<p>We can plot this easily too, as a lexical dispersion plot. By specifying the scale as “absolute”, we are looking at absolute token index position rather than relative position, and therefore we see that <em>Moby Dick</em> is nearly twice as long as <em>Sense and Sensibility</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../../reference/textplot_xray.html">textplot_xray</a></span>(dogkwic, <span class="dt">scale =</span> <span class="st">"absolute"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-45-1.png" width="768"></p>
</div>
<div id="text-quality-text-variety-and-parsing-xml" class="section level1">
<h1 class="hasAnchor">
<a href="#text-quality-text-variety-and-parsing-xml" class="anchor"></a>10 Text Quality, Text Variety, and Parsing XML</h1>
</div>
<div id="clustering" class="section level1">
<h1 class="hasAnchor">
<a href="#clustering" class="anchor"></a>11 Clustering</h1>
<p>Chapter 11 describes how to detect clusters in a corpus. While the book uses the <code>XMLAuthorCorpus</code>, we describe clustering using U.S. State of the Union addresses included in the <strong>quanteda.corpora</strong> package. We trim the corpus with <code><a href="../../../reference/dfm_trim.html">dfm_trim()</a></code> by keeping only those words that occur at least five times in the corpus and in at least three speeches.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(quanteda.corpora)
pres_dfm &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(<span class="kw"><a href="../../../reference/corpus_subset.html">corpus_subset</a></span>(data_corpus_sotu, Date <span class="op">&gt;</span><span class="st"> "1980-01-01"</span>), 
               <span class="dt">stem =</span> <span class="ot">TRUE</span>, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>,
               <span class="dt">remove =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/stopwords/topics/stopwords">stopwords</a></span>(<span class="st">"english"</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../../reference/dfm_trim.html">dfm_trim</a></span>(<span class="dt">min_termfreq =</span> <span class="dv">5</span>, <span class="dt">min_docfreq =</span> <span class="dv">3</span>)

<span class="co"># hierarchical clustering - get distances on normalized dfm</span>
pres_dist_mat &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/textstat_simil.html">textstat_dist</a></span>(<span class="kw"><a href="../../../reference/dfm_weight.html">dfm_weight</a></span>(pres_dfm, <span class="st">"prop"</span>))

<span class="co"># hiarchical clustering the distance object</span>
pres_cluster &lt;-<span class="st"> </span><span class="kw">hclust</span>(pres_dist_mat)

<span class="co"># label with document names</span>
pres_cluster<span class="op">$</span>labels &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/docnames.html">docnames</a></span>(pres_dfm)

<span class="co"># plot as a dendrogram</span>
<span class="kw">plot</span>(pres_cluster, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">sub =</span> <span class="st">""</span>, <span class="dt">main =</span> <span class="st">"Euclidean Distance on Normalized Token Frequency"</span>)</code></pre></div>
<p><img src="digital-humanities_files/figure-html/unnamed-chunk-46-1.png" width="700"></p>
</div>
<div id="classification" class="section level1">
<h1 class="hasAnchor">
<a href="#classification" class="anchor"></a>12 Classification</h1>
</div>
<div id="topic-modeling" class="section level1">
<h1 class="hasAnchor">
<a href="#topic-modeling" class="anchor"></a>13 Topic Modeling</h1>
<p>Finally, Jockers’ book introduces topic modeling of a corpus and the visualisation through wordclouds. In our example, we use the State of the Union addresses again. We can easily apply functions from the <strong>topicmodels</strong> package by using <strong>quanteda</strong>’s <code><a href="../../../reference/convert.html">convert()</a></code> function. In our example, we use the Irish budget speeches from 2010 and classify 20 topics using Latent Dirichlet Allocation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfm_speeches &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(data_corpus_irishbudget2010, 
                <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>, <span class="dt">remove_numbers =</span> <span class="ot">TRUE</span>, <span class="dt">remove =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/stopwords/topics/stopwords">stopwords</a></span>(<span class="st">"english"</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="../../../reference/dfm_trim.html">dfm_trim</a></span>(<span class="dt">min_termfreq =</span> <span class="dv">4</span>, <span class="dt">max_docfreq =</span> <span class="dv">10</span>)

<span class="kw">library</span>(topicmodels)
LDA_fit_<span class="dv">20</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/convert.html">convert</a></span>(dfm_speeches, <span class="dt">to =</span> <span class="st">"topicmodels"</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/topicmodels/topics/lda">LDA</a></span>(<span class="dt">k =</span> <span class="dv">20</span>)

<span class="co"># get top five terms per topic</span>
<span class="kw"><a href="http://www.rdocumentation.org/packages/topicmodels/topics/get">get_terms</a></span>(LDA_fit_<span class="dv">20</span>, <span class="dv">5</span>)</code></pre></div>
<pre><code>##      Topic 1      Topic 2   Topic 3    Topic 4     Topic 5   Topic 6   
## [1,] "asking"     "benefit" "reduce"   "taoiseach" "levy"    "welfare" 
## [2,] "address"    "child"   "payments" "fine"      "million" "system"  
## [3,] "failed"     "banks"   "apply"    "gael"      "carbon"  "taxation"
## [4,] "leadership" "today"   "banks"    "may"       "change"  "fianna"  
## [5,] "face"       "bank"    "benefit"  "stimulus"  "welfare" "fáil"    
##      Topic 7   Topic 8        Topic 9    Topic 10       Topic 11     
## [1,] "care"    "sense"        "fianna"   "society"      "alternative"
## [2,] "welfare" "difficult"    "fáil"     "equal"        "citizenship"
## [3,] "million" "enterprising" "national" "nation"       "wealth"     
## [4,] "child"   "companies"    "irish"    "enterprising" "adjustment" 
## [5,] "system"  "society"      "support"  "going"        "breaks"     
##      Topic 12   Topic 13   Topic 14    Topic 15     Topic 16   
## [1,] "child"    "per"      "system"    "million"    "taoiseach"
## [2,] "day"      "measures" "strategy"  "support"    "kind"     
## [3,] "welfare"  "attack"   "failed"    "welfare"    "debate"   
## [4,] "much"     "benefit"  "ministers" "investment" "employees"
## [5,] "fairness" "top"      "seen"      "back"       "rate"     
##      Topic 17      Topic 18 Topic 19   Topic 20    
## [1,] "opportunity" "fianna" "measures" "necessary" 
## [2,] "real"        "fáil"   "million"  "future"    
## [3,] "taoiseach"   "side"   "spending" "scale"     
## [4,] "fianna"      "level"  "scheme"   "include"   
## [5,] "irish"       "third"  "review"   "department"</code></pre>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#r-basics">1 R Basics</a></li>
      <li>
<a href="#first-foray">2 First Foray</a><ul class="nav nav-pills nav-stacked">
<li><a href="#loading-the-first-text-file">2.1 Loading the first text file</a></li>
      <li><a href="#separate-content-from-metadata">2.2 Separate content from metadata</a></li>
      <li><a href="#reprocessing-the-content">2.3 Reprocessing the content</a></li>
      <li><a href="#beginning-the-analysis">2.4 Beginning the analysis</a></li>
      </ul>
</li>
      <li>
<a href="#accessing-and-comparing-word-frequency-data">3 Accessing and Comparing Word Frequency Data</a><ul class="nav nav-pills nav-stacked">
<li><a href="#accessing-word-data">3.1 Accessing Word Data</a></li>
      <li><a href="#recycling">3.2 Recycling</a></li>
      </ul>
</li>
      <li>
<a href="#token-distribution-analysis">4 Token Distribution Analysis</a><ul class="nav nav-pills nav-stacked">
<li><a href="#dispersion-plots">4.1 Dispersion plots</a></li>
      <li><a href="#searching-with-regular-expression">4.2 Searching with regular expression</a></li>
      <li><a href="#identifying-chapter-breaks">4.2 Identifying chapter breaks</a></li>
      </ul>
</li>
      <li>
<a href="#correlation">5 Correlation</a><ul class="nav nav-pills nav-stacked">
<li><a href="#correlation-analysis">5.2 Correlation Analysis</a></li>
      <li><a href="#testing-correlation-with-randomization">5.4 Testing Correlation with Randomization</a></li>
      </ul>
</li>
      <li>
<a href="#measures-of-lexical-variety">6 Measures of Lexical Variety</a><ul class="nav nav-pills nav-stacked">
<li><a href="#mean-word-frequency">6.2 Mean word frequency</a></li>
      <li><a href="#extracting-word-usage-means">6.3 Extracting Word Usage Means</a></li>
      <li><a href="#ranking-the-values">6.4 Ranking the values</a></li>
      <li><a href="#calculating-the-ttr">6.5 Calculating the TTR</a></li>
      </ul>
</li>
      <li><a href="#hapax-richness">7 Hapax Richness</a></li>
      <li><a href="#do-it-kwic">8 Do it KWIC</a></li>
      <li><a href="#do-it-kwic-better">9 Do it KWIC (Better)</a></li>
      <li><a href="#text-quality-text-variety-and-parsing-xml">10 Text Quality, Text Variety, and Parsing XML</a></li>
      <li><a href="#clustering">11 Clustering</a></li>
      <li><a href="#classification">12 Classification</a></li>
      <li><a href="#topic-modeling">13 Topic Modeling</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Kenneth Benoit, Kohei Watanabe, Haiyan Wang, Paul Nulty, Adam Obeng, Stefan Müller, Akitaka Matsuo, Patrick O. Perry, Jouni Kuha, Benjamin Lauderdale, William Lowe, European Research Council.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script>
  docsearch({
    
    
    apiKey: '9b4ef7fd791dc6075154d3ebd7b12acf',
    indexName: 'quanteda',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
