<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Replication of Chapter 5 of <em>Quantitative Social Science: An Introduction</em> • quanteda</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../../pkgdown.css" rel="stylesheet">
<script src="../../../jquery.sticky-kit.min.js"></script><script src="../../../pkgdown.js"></script><link href="../../../extra.css" rel="stylesheet">
<script src="../../../extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-144616-24', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../../index.html">Quanteda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Quick Start
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/quickstart.html">Quick Start Guide</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_es.html">Guía de Inicio Rápido</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_cn.html">快速入门指南</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/quickstart_ja.html">クイック・スタートガイド</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../../articles/pkgdown/comparison.html">Features</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/examples/phrase.html">Multi-word expressions</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/plotting.html">Textual data visualization</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/lsa.html">Latent Semantic Analysis (LSA)</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/chinese.html">Chinese text analysis</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/examples/twitter.html">Social media analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Replications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../../articles/pkgdown/replication/digital-humanities.html">Text Analysis with R for Students of Literature</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/replication/text2vec.html">Word embedding (word2vec)</a>
    </li>
    <li>
      <a href="../../../articles/pkgdown/replication/qss.html">Quantitative Social Science Ch. 5.1</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../../articles/design.html">Design</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/quanteda/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Replication of Chapter 5 of <em>Quantitative Social Science: An Introduction</em>
</h1>
                        <h4 class="author">Stefan Müller and Kenneth Benoit</h4>
            
          </div>

    
    
<div class="contents">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"quanteda"</span>)</code></pre></div>
<p>In this vignette we show how the <strong>quanteda</strong> package can be used to replicate the text analysis part (Chapter 5.1) from Kosuke Imai’s book <a href="http://qss.princeton.press"><em>Quantitative Social Science: An Introduction</em></a> (Princeton: Princeton University Press, 2017).</p>
<div id="download-the-corpus" class="section level2">
<h2 class="hasAnchor">
<a href="#download-the-corpus" class="anchor"></a>Download the Corpus</h2>
<p>To get the textual data, you need to install and load the <strong>qss</strong> package first that comes with the book.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"kosukeimai/qss-package"</span>, <span class="dt">build_vignettes =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="section-5-1-1-the-disputed-authorship-of-the-federalist-papers" class="section level2">
<h2 class="hasAnchor">
<a href="#section-5-1-1-the-disputed-authorship-of-the-federalist-papers" class="anchor"></a>Section 5.1.1: The Disputed Authorship of ‘The Federalist Papers’</h2>
<p>First, we use the <strong>readtext</strong> package to import the Federalist Papers as a data frame and create a <strong>quanteda</strong> corpus.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"readtext"</span>)
<span class="co"># use readtext package to import all documents as a dataframe</span>
corpus_texts &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/readtext/topics/readtext">readtext</a></span>(<span class="kw">system.file</span>(<span class="st">"extdata/federalist/"</span>, <span class="dt">package =</span> <span class="st">"qss"</span>))

<span class="co"># create docvar with number of paper</span>
corpus_texts<span class="op">$</span>paper_number &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">"No."</span>, <span class="kw">seq_len</span>(<span class="kw">nrow</span>(corpus_texts)), <span class="dt">sep =</span> <span class="st">" "</span>)

<span class="co"># transform to a quanteda corpus object</span>
corpus_raw &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/corpus.html">corpus</a></span>(corpus_texts, <span class="dt">text_field =</span> <span class="st">"text"</span>, <span class="dt">docid_field =</span> <span class="st">"paper_number"</span>)

<span class="co"># create docvar with authorship (used in Section  5.1.4)</span>
<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(corpus_raw, <span class="st">"paper_numeric"</span>) &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="kw"><a href="../../../reference/ndoc.html">ndoc</a></span>(corpus_raw))

<span class="co"># create docvar with authorship (used in Section  5.1.4)</span>
<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(corpus_raw, <span class="st">"author"</span>) &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="ot">NA</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"madison"</span>, <span class="st">"hamilton"</span>))
<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(corpus_raw, <span class="st">"author"</span>)[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span><span class="op">:</span><span class="dv">9</span>, <span class="dv">11</span><span class="op">:</span><span class="dv">13</span>, <span class="dv">15</span><span class="op">:</span><span class="dv">17</span>, <span class="dv">21</span><span class="op">:</span><span class="dv">36</span>, <span class="dv">59</span><span class="op">:</span><span class="dv">61</span>, <span class="dv">65</span><span class="op">:</span><span class="dv">85</span>)] &lt;-<span class="st"> "hamilton"</span>
<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(corpus_raw, <span class="st">"author"</span>)[<span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">37</span><span class="op">:</span><span class="dv">48</span>, <span class="dv">58</span>)] &lt;-<span class="st"> "madison"</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># inspect Paper No. 10 (output suppressed)</span>
<span class="kw"><a href="../../../reference/texts.html">texts</a></span>(corpus_raw)[<span class="dv">10</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>stringi<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_sub">stri_sub</a></span>(<span class="dv">1</span>, <span class="dv">240</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">cat</span>()</code></pre></div>
<pre><code>## AMONG the numerous advantages promised by a well-constructed Union, none 
##         deserves to be more accurately developed than its tendency to break and 
##         control the violence of faction. The friend of popular governments never 
## </code></pre>
</div>
<div id="section-5-1-2-document-term-matrix" class="section level2">
<h2 class="hasAnchor">
<a href="#section-5-1-2-document-term-matrix" class="anchor"></a>Section 5.1.2: Document-Term Matrix</h2>
<p>Next, we transform the corpus to a document-feature matrix. <code>dfm_prep</code> (used in sections 5.1.4 and 5.1.5) is a dfm in which numbers and punctuation have been removed, and in which terms have been converted to lowercase. In <code>dfm_papers</code>, the words have also been stemmed and a standard set of stopwords removed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># transform corpus to a document-feature matrix</span>
dfm_prep &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(corpus_raw, <span class="dt">remove_numbers =</span> <span class="ot">TRUE</span>, <span class="dt">tolower =</span> <span class="ot">TRUE</span>,
                <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>, <span class="dt">verbose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Creating a dfm from a corpus input...</code></pre>
<pre><code>##    ... lowercasing</code></pre>
<pre><code>##    ... found 85 documents, 8,630 features</code></pre>
<pre><code>##    ... created a 85 x 8,630 sparse dfm
##    ... complete. 
## Elapsed time: 0.482 seconds.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># remove stop words and stem words</span>
dfm_papers &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm.html">dfm</a></span>(dfm_prep, <span class="dt">stem =</span> <span class="ot">TRUE</span>, <span class="dt">remove =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/stopwords/topics/stopwords">stopwords</a></span>(<span class="st">"english"</span>))

<span class="co"># inspect</span>
dfm_papers</code></pre></div>
<pre><code>## Document-feature matrix of: 85 documents, 4,859 features (89.1% sparse).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># sort into alphabetical order of features, to match book example</span>
dfm_papers &lt;-<span class="st"> </span>dfm_papers[, <span class="kw">order</span>(<span class="kw"><a href="../../../reference/featnames.html">featnames</a></span>(dfm_papers))]

<span class="co"># inspect some documents in the dfm</span>
<span class="kw">head</span>(dfm_papers, <span class="dt">nf =</span> <span class="dv">8</span>)</code></pre></div>
<pre><code>## Document-feature matrix of: 6 documents, 8 features (97.9% sparse).
## 6 x 8 sparse Matrix of class "dfm"
##        features
## docs    1st 2d 3d 4th 5th abandon abat abb
##   No. 1   0  0  0   0   0       0    0   0
##   No. 2   0  0  0   0   0       0    0   0
##   No. 3   0  0  0   0   0       0    0   0
##   No. 4   0  0  0   0   0       0    0   0
##   No. 5   1  0  0   0   0       0    0   0
##   No. 6   0  0  0   0   0       0    0   0</code></pre>
<p>The <strong>tm</strong> package considers features such as “1st” to be numbers, whereas <strong>quanteda</strong> does not. We can remove these easily using a wildcard removal:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfm_papers &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_select.html">dfm_remove</a></span>(dfm_papers, <span class="st">"[0-9]"</span>, <span class="dt">valuetype =</span> <span class="st">"regex"</span>, <span class="dt">verbose =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## removed 5 features</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(dfm_papers, <span class="dt">nf =</span> <span class="dv">8</span>)</code></pre></div>
<pre><code>## Document-feature matrix of: 6 documents, 8 features (91.7% sparse).
## 6 x 8 sparse Matrix of class "dfm"
##        features
## docs    abandon abat abb abet abhorr abil abject abl
##   No. 1       0    0   0    0      0    0      0   1
##   No. 2       0    0   0    0      0    1      0   0
##   No. 3       0    0   0    0      0    0      0   2
##   No. 4       0    0   0    0      0    0      0   1
##   No. 5       0    0   0    0      0    0      0   0
##   No. 6       0    0   0    0      0    0      0   0</code></pre>
</div>
<div id="section-5-1-3-topic-discovery" class="section level2">
<h2 class="hasAnchor">
<a href="#section-5-1-3-topic-discovery" class="anchor"></a>Section 5.1.3: Topic Discovery</h2>
<p>We can use the <code><a href="../../../reference/textplot_wordcloud.html">textplot_wordcloud()</a></code> function to plot word clouds of the most frequent words in Papers 12 and 24.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
<span class="kw"><a href="../../../reference/textplot_wordcloud.html">textplot_wordcloud</a></span>(dfm_papers[<span class="kw">c</span>(<span class="st">"No. 12"</span>, <span class="st">"No. 24"</span>), ], 
                   <span class="dt">max.words =</span> <span class="dv">50</span>, <span class="dt">comparison =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p><img src="qss_files/figure-html/unnamed-chunk-8-1.png" width="768"></p>
<p>Since <strong>quanteda</strong> cannot do stem completion, we will skip that part.</p>
<p>Next, we identify clusters of similar essay based on term frequency-inverse document frequency (<em>tf-idf</em>) and apply the <span class="math inline">\(k\)</span>-means algorithm to the weighted dfm.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># tf-idf calculation</span>
dfm_papers_tfidf &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_tfidf.html">dfm_tfidf</a></span>(dfm_papers, <span class="dt">base =</span> <span class="dv">2</span>)

<span class="co"># 10 most important words for Paper No. 12</span>
<span class="kw"><a href="../../../reference/topfeatures.html">topfeatures</a></span>(dfm_papers_tfidf[<span class="dv">12</span>, ], <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##     revenu contraband     patrol      excis      coast      trade 
##   19.42088   19.22817   19.22817   19.12214   16.22817   15.01500 
##        per        tax       cent     gallon 
##   14.47329   13.20080   12.81878   12.81878</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 10 most important words for Paper No. 24</span>
<span class="kw"><a href="../../../reference/topfeatures.html">topfeatures</a></span>(dfm_papers_tfidf[<span class="dv">24</span>, ], <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##   garrison  dock-yard settlement      spain       armi   frontier 
##  24.524777  19.228173  16.228173  13.637564  12.770999  12.262389 
##    arsenal    western       post     nearer 
##  10.818782  10.806108  10.228173   9.648857</code></pre>
<p>We can match the clustering as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="dv">4</span>  <span class="co"># number of clusters</span>

<span class="co"># subset The Federalist papers written by Hamilton</span>

dfm_papers_tfidf_hamilton &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_subset.html">dfm_subset</a></span>(dfm_papers_tfidf, author <span class="op">==</span><span class="st"> "hamilton"</span>)

<span class="co"># run k-means</span>
km_out &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/stats/topics/kmeans">kmeans</a></span>(dfm_papers_tfidf_hamilton, <span class="dt">centers =</span> k)

km_out<span class="op">$</span>iter <span class="co"># check the convergence; number of iterations may vary</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colnames</span>(km_out<span class="op">$</span>centers) &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/featnames.html">featnames</a></span>(dfm_papers_tfidf_hamilton)

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k) { <span class="co"># loop for each cluster</span>
  <span class="kw">cat</span>(<span class="st">"CLUSTER"</span>, i, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)
  <span class="kw">cat</span>(<span class="st">"Top 10 words:</span><span class="ch">\n</span><span class="st">"</span>) <span class="co"># 10 most important terms at the centroid</span>
  <span class="kw">print</span>(<span class="kw">head</span>(<span class="kw">sort</span>(km_out<span class="op">$</span>centers[i, ], <span class="dt">decreasing =</span> <span class="ot">TRUE</span>), <span class="dt">n =</span> <span class="dv">10</span>))
  <span class="kw">cat</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)
  <span class="kw">cat</span>(<span class="st">"Federalist Papers classified: </span><span class="ch">\n</span><span class="st">"</span>) <span class="co"># extract essays classified</span>
  <span class="kw">print</span>(<span class="kw"><a href="../../../reference/docnames.html">docnames</a></span>(dfm_papers_tfidf_hamilton)[km_out<span class="op">$</span>cluster <span class="op">==</span><span class="st"> </span>i])
  <span class="kw">cat</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)
}</code></pre></div>
<pre><code>## CLUSTER 1 
## Top 10 words:
##     court     appel jurisdict    suprem      juri    tribun    cogniz 
##  69.68857  35.27513  25.46591  24.79126  22.16104  21.27125  19.12214 
##  inferior    appeal re-examin 
##  18.76875  16.21098  13.52348 
## 
## Federalist Papers classified: 
## [1] "No. 81" "No. 82"
## 
## CLUSTER 2 
## Top 10 words:
##       juri      trial      court     crimin  admiralti     equiti 
##  218.20102   84.74567   62.47940   42.06871   40.87463   38.24428 
##   chanceri common-law     probat      civil 
##   37.86574   27.04695   27.04695   26.77843 
## 
## Federalist Papers classified: 
## [1] "No. 83"
## 
## CLUSTER 3 
## Top 10 words:
##    senat     upon   presid     armi    court    claus  militia    offic 
## 3.912991 3.640413 3.100660 2.919085 2.776862 2.636133 2.428567 2.374450 
## governor  appoint 
## 2.294413 2.125990 
## 
## Federalist Papers classified: 
##  [1] "No. 1"  "No. 6"  "No. 7"  "No. 8"  "No. 9"  "No. 13" "No. 15"
##  [8] "No. 16" "No. 17" "No. 21" "No. 22" "No. 23" "No. 24" "No. 25"
## [15] "No. 26" "No. 27" "No. 28" "No. 29" "No. 30" "No. 31" "No. 32"
## [22] "No. 33" "No. 34" "No. 36" "No. 59" "No. 60" "No. 61" "No. 65"
## [29] "No. 66" "No. 67" "No. 68" "No. 69" "No. 70" "No. 71" "No. 72"
## [36] "No. 73" "No. 74" "No. 75" "No. 76" "No. 77" "No. 78" "No. 79"
## [43] "No. 80" "No. 84" "No. 85"
## 
## CLUSTER 4 
## Top 10 words:
##      trade   merchant manufactur     market    commerc      navig 
##  18.351669  18.010180  14.037686  13.637564  11.214252  10.816517 
##     revenu   landhold       navi       ship 
##   9.416185   8.545855   8.233234   8.040714 
## 
## Federalist Papers classified: 
## [1] "No. 11" "No. 12" "No. 35"</code></pre>
</div>
<div id="section-5-1-4-authorship-prediction" class="section level2">
<h2 class="hasAnchor">
<a href="#section-5-1-4-authorship-prediction" class="anchor"></a>Section 5.1.4: Authorship Prediction</h2>
<p>In a next step, we want to predict authorship for the Federalist Papers whose authorship is unknown. As the topics of the Papers differs remarkably, Imai focuses on 10 articles, prepositions and conjunctions to predicte authorship.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># term frequency per 1000 words</span>
tfm &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_weight.html">dfm_weight</a></span>(dfm_prep, <span class="st">"prop"</span>) <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>

<span class="co"># select words of interest</span>
words &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"although"</span>, <span class="st">"always"</span>, <span class="st">"commonly"</span>, <span class="st">"consequently"</span>,
           <span class="st">"considerable"</span>, <span class="st">"enough"</span>, <span class="st">"there"</span>, <span class="st">"upon"</span>, <span class="st">"while"</span>, <span class="st">"whilst"</span>)
tfm &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_select.html">dfm_select</a></span>(tfm, words, <span class="dt">valuetype =</span> <span class="st">"fixed"</span>)

<span class="co"># average among Hamilton/Madison essays</span>
tfm_ave &lt;-<span class="st"> </span><span class="kw"><a href="../../../reference/dfm_group.html">dfm_group</a></span>(<span class="kw"><a href="../../../reference/dfm_subset.html">dfm_subset</a></span>(tfm, <span class="op">!</span><span class="kw">is.na</span>(author)), <span class="st">"author"</span>) <span class="op">/</span>
<span class="st">           </span><span class="kw">as.numeric</span>(<span class="kw">table</span>(<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(tfm, <span class="st">"author"</span>)))
    
<span class="co"># bind docvars from corpus and tfm to a data frame</span>
author_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw"><a href="../../../reference/docvars.html">docvars</a></span>(corpus_raw), tfm)

<span class="co"># create numeric variable that takes value 1 for Hamilton's essays,</span>
<span class="co"># -1 for Madison's essays and NA for the essays with unknown authorship</span>
author_data<span class="op">$</span>author_numeric &lt;-<span class="st"> </span><span class="kw">ifelse</span>(author_data<span class="op">$</span>author <span class="op">==</span><span class="st"> "hamilton"</span>, <span class="dv">1</span>, 
                                     <span class="kw">ifelse</span>(author_data<span class="op">$</span>author <span class="op">==</span><span class="st"> "madison"</span>, <span class="op">-</span><span class="dv">1</span>, <span class="ot">NA</span>))

<span class="co"># use only known authors for training set</span>
author_data_known &lt;-<span class="st"> </span><span class="kw">na.omit</span>(author_data)

hm_fit &lt;-<span class="st"> </span><span class="kw">lm</span>(author_numeric <span class="op">~</span><span class="st"> </span>upon <span class="op">+</span><span class="st"> </span>there <span class="op">+</span><span class="st"> </span>consequently <span class="op">+</span><span class="st"> </span>whilst,
             <span class="dt">data =</span> author_data_known)
hm_fit</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = author_numeric ~ upon + there + consequently + whilst, 
##     data = author_data_known)
## 
## Coefficients:
##  (Intercept)          upon         there  consequently        whilst  
##      -0.2729        0.2240        0.1278       -0.5596       -0.8378</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hm_fitted &lt;-<span class="st"> </span><span class="kw">fitted</span>(hm_fit) <span class="co"># fitted values</span>
<span class="kw">sd</span>(hm_fitted)</code></pre></div>
<pre><code>## [1] 0.7175527</code></pre>
</div>
<div id="section-5-1-5-cross-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#section-5-1-5-cross-validation" class="anchor"></a>Section 5.1.5: Cross-Validation</h2>
<p>Finally, we assess how well the model fits the data by classifying each essay based on its fitted value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># proportion of correctly classified essays by Hamilton</span>
<span class="kw">mean</span>(hm_fitted[author_data_known<span class="op">$</span>author <span class="op">==</span><span class="st"> "hamilton"</span>] <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># proportion of correctly classified essays by Madison</span>
<span class="kw">mean</span>(hm_fitted[author_data_known<span class="op">$</span>author <span class="op">==</span><span class="st"> "madison"</span>] <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(author_data_known)
hm_classify &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n) <span class="co"># a container vector with missing values</span>

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
  <span class="co"># fit the model to the data after removing the ith observation</span>
  sub_fit &lt;-<span class="st"> </span><span class="kw">lm</span>(author_numeric <span class="op">~</span><span class="st"> </span>upon <span class="op">+</span><span class="st"> </span>there <span class="op">+</span><span class="st"> </span>consequently <span class="op">+</span><span class="st"> </span>whilst,
                <span class="dt">data =</span> author_data_known[<span class="op">-</span>i, ]) <span class="co"># exclude ith row</span>
  <span class="co"># predict the authorship for the ith observation</span>
  hm_classify[i] &lt;-<span class="st"> </span><span class="kw">predict</span>(sub_fit, <span class="dt">newdata =</span> author_data_known[i, ])
}

<span class="co"># proportion of correctly classified essays by Hamilton</span>
<span class="kw">mean</span>(hm_classify[author_data_known<span class="op">$</span>author <span class="op">==</span><span class="st"> "hamilton"</span>] <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># proportion of correctly classified essays by Madison</span>
<span class="kw">mean</span>(hm_classify[author_data_known<span class="op">$</span>author <span class="op">==</span><span class="st"> "madison"</span>] <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">disputed &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">49</span>, <span class="dv">50</span><span class="op">:</span><span class="dv">57</span>, <span class="dv">62</span>, <span class="dv">63</span>) <span class="co"># 11 essays with disputed authorship</span>
tf_disputed &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw"><a href="../../../reference/dfm_subset.html">dfm_subset</a></span>(tfm, <span class="kw">is.na</span>(author)))

author_data<span class="op">$</span>prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(hm_fit, <span class="dt">newdata =</span> author_data)

author_data<span class="op">$</span>prediction <span class="co"># predicted values</span></code></pre></div>
<pre><code>##  [1]  0.73682138 -0.13810334 -1.35072048 -0.03823549 -0.27285552
##  [6]  0.71537231  1.33178340  0.19414036  0.37516964 -0.20369832
## [11]  0.67584796  0.99478176  1.39348825 -1.18908379  1.20446180
## [16]  0.63999272  0.91390560 -0.38341254 -0.62471327 -0.12453888
## [21]  0.91552544  1.08097849  0.88528696  1.01192444  0.08226598
## [26]  0.72338300  1.08177034  0.71354396  1.47718825  1.53672871
## [31]  1.85572895  0.71920518  1.07664097  1.26163462  0.90800379
## [36]  1.06339810 -0.81826934 -0.56126822 -0.27285552 -0.10309170
## [41] -0.47343432 -0.17492007 -0.60654100 -0.86944061 -1.67765248
## [46] -0.91487748 -0.13268399 -0.13500254 -0.96784742 -0.06907196
## [51] -1.46790700 -0.27285552 -0.54229524 -0.54529610  0.04081584
## [56] -0.56418213 -1.18177840 -0.41902525  0.55200092  0.98676075
## [61]  0.59237415 -0.97795312 -0.21203157 -0.18295716  1.15640459
## [66]  1.12403237  0.78348571  0.11197467  1.12824159  0.70981781
## [71]  0.34751104  0.84257351  1.24182206  0.91612261  0.50276872
## [76]  1.05480578  1.05926761  0.90585578  0.54292995  0.64035410
## [81]  0.91773469  0.31189155  0.80869221  0.73649069  1.00895939</code></pre>
<p>Finally, we plot the fitted values for each Federalist paper with the <strong>ggplot2</strong> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">author_data<span class="op">$</span>author_plot &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">is.na</span>(author_data<span class="op">$</span>author), <span class="st">"unknown"</span>, <span class="kw">as.character</span>(author_data<span class="op">$</span>author))

<span class="kw">library</span>(ggplot2)
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="dt">data =</span> author_data, <span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> paper_numeric, 
                               <span class="dt">y =</span> prediction, 
                               <span class="dt">shape =</span> author_plot, 
                               <span class="dt">colour =</span> author_plot)) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_point">geom_point</a></span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_abline">geom_hline</a></span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">"dotted"</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">x =</span> <span class="st">"Federalist Papers"</span>, <span class="dt">y =</span> <span class="st">"Predicted values"</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggtheme">theme_minimal</a></span>() <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/theme">theme</a></span>(<span class="dt">legend.title=</span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/element">element_blank</a></span>())</code></pre></div>
<p><img src="qss_files/figure-html/unnamed-chunk-13-1.png" width="768"></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#download-the-corpus">Download the Corpus</a></li>
      <li><a href="#section-5-1-1-the-disputed-authorship-of-the-federalist-papers">Section 5.1.1: The Disputed Authorship of ‘The Federalist Papers’</a></li>
      <li><a href="#section-5-1-2-document-term-matrix">Section 5.1.2: Document-Term Matrix</a></li>
      <li><a href="#section-5-1-3-topic-discovery">Section 5.1.3: Topic Discovery</a></li>
      <li><a href="#section-5-1-4-authorship-prediction">Section 5.1.4: Authorship Prediction</a></li>
      <li><a href="#section-5-1-5-cross-validation">Section 5.1.5: Cross-Validation</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Kenneth Benoit.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
